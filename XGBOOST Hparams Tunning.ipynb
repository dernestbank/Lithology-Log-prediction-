{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Packages\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from xgboost import XGBRFRegressor\n",
    "\n",
    "\n",
    "from sklearn import metrics, model_selection\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# from sklearn.preprocessing import Imputer\n",
    "\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "# imputer = SimpleImputer(missing_values=np.nan, strategy='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package sklearn.model_selection in sklearn:\n",
      "\n",
      "NAME\n",
      "    sklearn.model_selection\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    _search\n",
      "    _split\n",
      "    _validation\n",
      "    tests (package)\n",
      "\n",
      "CLASSES\n",
      "    builtins.object\n",
      "        sklearn.model_selection._search.ParameterGrid\n",
      "        sklearn.model_selection._search.ParameterSampler\n",
      "        sklearn.model_selection._split.BaseCrossValidator\n",
      "            sklearn.model_selection._split.LeaveOneGroupOut\n",
      "            sklearn.model_selection._split.LeaveOneOut\n",
      "            sklearn.model_selection._split.LeavePGroupsOut\n",
      "            sklearn.model_selection._split.LeavePOut\n",
      "            sklearn.model_selection._split.PredefinedSplit\n",
      "    sklearn.model_selection._search.BaseSearchCV(sklearn.base.MetaEstimatorMixin, sklearn.base.BaseEstimator)\n",
      "        sklearn.model_selection._search.GridSearchCV\n",
      "        sklearn.model_selection._search.RandomizedSearchCV\n",
      "    sklearn.model_selection._split.BaseShuffleSplit(builtins.object)\n",
      "        sklearn.model_selection._split.ShuffleSplit\n",
      "            sklearn.model_selection._split.GroupShuffleSplit\n",
      "        sklearn.model_selection._split.StratifiedShuffleSplit\n",
      "    sklearn.model_selection._split._BaseKFold(sklearn.model_selection._split.BaseCrossValidator)\n",
      "        sklearn.model_selection._split.GroupKFold\n",
      "        sklearn.model_selection._split.KFold\n",
      "        sklearn.model_selection._split.StratifiedKFold\n",
      "        sklearn.model_selection._split.TimeSeriesSplit\n",
      "    sklearn.model_selection._split._RepeatedSplits(builtins.object)\n",
      "        sklearn.model_selection._split.RepeatedKFold\n",
      "        sklearn.model_selection._split.RepeatedStratifiedKFold\n",
      "    \n",
      "    class BaseCrossValidator(builtins.object)\n",
      "     |  Base class for all cross-validators\n",
      "     |  \n",
      "     |  Implementations must define `_iter_test_masks` or `_iter_test_indices`.\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  get_n_splits(self, X=None, y=None, groups=None)\n",
      "     |      Returns the number of splitting iterations in the cross-validator\n",
      "     |  \n",
      "     |  split(self, X, y=None, groups=None)\n",
      "     |      Generate indices to split data into training and test set.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like of shape (n_samples, n_features)\n",
      "     |          Training data, where n_samples is the number of samples\n",
      "     |          and n_features is the number of features.\n",
      "     |      \n",
      "     |      y : array-like of shape (n_samples,)\n",
      "     |          The target variable for supervised learning problems.\n",
      "     |      \n",
      "     |      groups : array-like of shape (n_samples,), default=None\n",
      "     |          Group labels for the samples used while splitting the dataset into\n",
      "     |          train/test set.\n",
      "     |      \n",
      "     |      Yields\n",
      "     |      ------\n",
      "     |      train : ndarray\n",
      "     |          The training set indices for that split.\n",
      "     |      \n",
      "     |      test : ndarray\n",
      "     |          The testing set indices for that split.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset({'get_n_splits'})\n",
      "    \n",
      "    class GridSearchCV(BaseSearchCV)\n",
      "     |  GridSearchCV(estimator, param_grid, *, scoring=None, n_jobs=None, iid='deprecated', refit=True, cv=None, verbose=0, pre_dispatch='2*n_jobs', error_score=nan, return_train_score=False)\n",
      "     |  \n",
      "     |  Exhaustive search over specified parameter values for an estimator.\n",
      "     |  \n",
      "     |  Important members are fit, predict.\n",
      "     |  \n",
      "     |  GridSearchCV implements a \"fit\" and a \"score\" method.\n",
      "     |  It also implements \"predict\", \"predict_proba\", \"decision_function\",\n",
      "     |  \"transform\" and \"inverse_transform\" if they are implemented in the\n",
      "     |  estimator used.\n",
      "     |  \n",
      "     |  The parameters of the estimator used to apply these methods are optimized\n",
      "     |  by cross-validated grid-search over a parameter grid.\n",
      "     |  \n",
      "     |  Read more in the :ref:`User Guide <grid_search>`.\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  estimator : estimator object.\n",
      "     |      This is assumed to implement the scikit-learn estimator interface.\n",
      "     |      Either estimator needs to provide a ``score`` function,\n",
      "     |      or ``scoring`` must be passed.\n",
      "     |  \n",
      "     |  param_grid : dict or list of dictionaries\n",
      "     |      Dictionary with parameters names (`str`) as keys and lists of\n",
      "     |      parameter settings to try as values, or a list of such\n",
      "     |      dictionaries, in which case the grids spanned by each dictionary\n",
      "     |      in the list are explored. This enables searching over any sequence\n",
      "     |      of parameter settings.\n",
      "     |  \n",
      "     |  scoring : str, callable, list/tuple or dict, default=None\n",
      "     |      A single str (see :ref:`scoring_parameter`) or a callable\n",
      "     |      (see :ref:`scoring`) to evaluate the predictions on the test set.\n",
      "     |  \n",
      "     |      For evaluating multiple metrics, either give a list of (unique) strings\n",
      "     |      or a dict with names as keys and callables as values.\n",
      "     |  \n",
      "     |      NOTE that when using custom scorers, each scorer should return a single\n",
      "     |      value. Metric functions returning a list/array of values can be wrapped\n",
      "     |      into multiple scorers that return one value each.\n",
      "     |  \n",
      "     |      See :ref:`multimetric_grid_search` for an example.\n",
      "     |  \n",
      "     |      If None, the estimator's score method is used.\n",
      "     |  \n",
      "     |  n_jobs : int, default=None\n",
      "     |      Number of jobs to run in parallel.\n",
      "     |      ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
      "     |      ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
      "     |      for more details.\n",
      "     |  \n",
      "     |      .. versionchanged:: v0.20\n",
      "     |         `n_jobs` default changed from 1 to None\n",
      "     |  \n",
      "     |  pre_dispatch : int, or str, default=n_jobs\n",
      "     |      Controls the number of jobs that get dispatched during parallel\n",
      "     |      execution. Reducing this number can be useful to avoid an\n",
      "     |      explosion of memory consumption when more jobs get dispatched\n",
      "     |      than CPUs can process. This parameter can be:\n",
      "     |  \n",
      "     |          - None, in which case all the jobs are immediately\n",
      "     |            created and spawned. Use this for lightweight and\n",
      "     |            fast-running jobs, to avoid delays due to on-demand\n",
      "     |            spawning of the jobs\n",
      "     |  \n",
      "     |          - An int, giving the exact number of total jobs that are\n",
      "     |            spawned\n",
      "     |  \n",
      "     |          - A str, giving an expression as a function of n_jobs,\n",
      "     |            as in '2*n_jobs'\n",
      "     |  \n",
      "     |  iid : bool, default=False\n",
      "     |      If True, return the average score across folds, weighted by the number\n",
      "     |      of samples in each test set. In this case, the data is assumed to be\n",
      "     |      identically distributed across the folds, and the loss minimized is\n",
      "     |      the total loss per sample, and not the mean loss across the folds.\n",
      "     |  \n",
      "     |      .. deprecated:: 0.22\n",
      "     |          Parameter ``iid`` is deprecated in 0.22 and will be removed in 0.24\n",
      "     |  \n",
      "     |  cv : int, cross-validation generator or an iterable, default=None\n",
      "     |      Determines the cross-validation splitting strategy.\n",
      "     |      Possible inputs for cv are:\n",
      "     |  \n",
      "     |      - None, to use the default 5-fold cross validation,\n",
      "     |      - integer, to specify the number of folds in a `(Stratified)KFold`,\n",
      "     |      - :term:`CV splitter`,\n",
      "     |      - An iterable yielding (train, test) splits as arrays of indices.\n",
      "     |  \n",
      "     |      For integer/None inputs, if the estimator is a classifier and ``y`` is\n",
      "     |      either binary or multiclass, :class:`StratifiedKFold` is used. In all\n",
      "     |      other cases, :class:`KFold` is used.\n",
      "     |  \n",
      "     |      Refer :ref:`User Guide <cross_validation>` for the various\n",
      "     |      cross-validation strategies that can be used here.\n",
      "     |  \n",
      "     |      .. versionchanged:: 0.22\n",
      "     |          ``cv`` default value if None changed from 3-fold to 5-fold.\n",
      "     |  \n",
      "     |  refit : bool, str, or callable, default=True\n",
      "     |      Refit an estimator using the best found parameters on the whole\n",
      "     |      dataset.\n",
      "     |  \n",
      "     |      For multiple metric evaluation, this needs to be a `str` denoting the\n",
      "     |      scorer that would be used to find the best parameters for refitting\n",
      "     |      the estimator at the end.\n",
      "     |  \n",
      "     |      Where there are considerations other than maximum score in\n",
      "     |      choosing a best estimator, ``refit`` can be set to a function which\n",
      "     |      returns the selected ``best_index_`` given ``cv_results_``. In that\n",
      "     |      case, the ``best_estimator_`` and ``best_params_`` will be set\n",
      "     |      according to the returned ``best_index_`` while the ``best_score_``\n",
      "     |      attribute will not be available.\n",
      "     |  \n",
      "     |      The refitted estimator is made available at the ``best_estimator_``\n",
      "     |      attribute and permits using ``predict`` directly on this\n",
      "     |      ``GridSearchCV`` instance.\n",
      "     |  \n",
      "     |      Also for multiple metric evaluation, the attributes ``best_index_``,\n",
      "     |      ``best_score_`` and ``best_params_`` will only be available if\n",
      "     |      ``refit`` is set and all of them will be determined w.r.t this specific\n",
      "     |      scorer.\n",
      "     |  \n",
      "     |      See ``scoring`` parameter to know more about multiple metric\n",
      "     |      evaluation.\n",
      "     |  \n",
      "     |      .. versionchanged:: 0.20\n",
      "     |          Support for callable added.\n",
      "     |  \n",
      "     |  verbose : integer\n",
      "     |      Controls the verbosity: the higher, the more messages.\n",
      "     |  \n",
      "     |  error_score : 'raise' or numeric, default=np.nan\n",
      "     |      Value to assign to the score if an error occurs in estimator fitting.\n",
      "     |      If set to 'raise', the error is raised. If a numeric value is given,\n",
      "     |      FitFailedWarning is raised. This parameter does not affect the refit\n",
      "     |      step, which will always raise the error.\n",
      "     |  \n",
      "     |  return_train_score : bool, default=False\n",
      "     |      If ``False``, the ``cv_results_`` attribute will not include training\n",
      "     |      scores.\n",
      "     |      Computing training scores is used to get insights on how different\n",
      "     |      parameter settings impact the overfitting/underfitting trade-off.\n",
      "     |      However computing the scores on the training set can be computationally\n",
      "     |      expensive and is not strictly required to select the parameters that\n",
      "     |      yield the best generalization performance.\n",
      "     |  \n",
      "     |      .. versionadded:: 0.19\n",
      "     |  \n",
      "     |      .. versionchanged:: 0.21\n",
      "     |          Default value was changed from ``True`` to ``False``\n",
      "     |  \n",
      "     |  \n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  >>> from sklearn import svm, datasets\n",
      "     |  >>> from sklearn.model_selection import GridSearchCV\n",
      "     |  >>> iris = datasets.load_iris()\n",
      "     |  >>> parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}\n",
      "     |  >>> svc = svm.SVC()\n",
      "     |  >>> clf = GridSearchCV(svc, parameters)\n",
      "     |  >>> clf.fit(iris.data, iris.target)\n",
      "     |  GridSearchCV(estimator=SVC(),\n",
      "     |               param_grid={'C': [1, 10], 'kernel': ('linear', 'rbf')})\n",
      "     |  >>> sorted(clf.cv_results_.keys())\n",
      "     |  ['mean_fit_time', 'mean_score_time', 'mean_test_score',...\n",
      "     |   'param_C', 'param_kernel', 'params',...\n",
      "     |   'rank_test_score', 'split0_test_score',...\n",
      "     |   'split2_test_score', ...\n",
      "     |   'std_fit_time', 'std_score_time', 'std_test_score']\n",
      "     |  \n",
      "     |  Attributes\n",
      "     |  ----------\n",
      "     |  cv_results_ : dict of numpy (masked) ndarrays\n",
      "     |      A dict with keys as column headers and values as columns, that can be\n",
      "     |      imported into a pandas ``DataFrame``.\n",
      "     |  \n",
      "     |      For instance the below given table\n",
      "     |  \n",
      "     |      +------------+-----------+------------+-----------------+---+---------+\n",
      "     |      |param_kernel|param_gamma|param_degree|split0_test_score|...|rank_t...|\n",
      "     |      +============+===========+============+=================+===+=========+\n",
      "     |      |  'poly'    |     --    |      2     |       0.80      |...|    2    |\n",
      "     |      +------------+-----------+------------+-----------------+---+---------+\n",
      "     |      |  'poly'    |     --    |      3     |       0.70      |...|    4    |\n",
      "     |      +------------+-----------+------------+-----------------+---+---------+\n",
      "     |      |  'rbf'     |     0.1   |     --     |       0.80      |...|    3    |\n",
      "     |      +------------+-----------+------------+-----------------+---+---------+\n",
      "     |      |  'rbf'     |     0.2   |     --     |       0.93      |...|    1    |\n",
      "     |      +------------+-----------+------------+-----------------+---+---------+\n",
      "     |  \n",
      "     |      will be represented by a ``cv_results_`` dict of::\n",
      "     |  \n",
      "     |          {\n",
      "     |          'param_kernel': masked_array(data = ['poly', 'poly', 'rbf', 'rbf'],\n",
      "     |                                       mask = [False False False False]...)\n",
      "     |          'param_gamma': masked_array(data = [-- -- 0.1 0.2],\n",
      "     |                                      mask = [ True  True False False]...),\n",
      "     |          'param_degree': masked_array(data = [2.0 3.0 -- --],\n",
      "     |                                       mask = [False False  True  True]...),\n",
      "     |          'split0_test_score'  : [0.80, 0.70, 0.80, 0.93],\n",
      "     |          'split1_test_score'  : [0.82, 0.50, 0.70, 0.78],\n",
      "     |          'mean_test_score'    : [0.81, 0.60, 0.75, 0.85],\n",
      "     |          'std_test_score'     : [0.01, 0.10, 0.05, 0.08],\n",
      "     |          'rank_test_score'    : [2, 4, 3, 1],\n",
      "     |          'split0_train_score' : [0.80, 0.92, 0.70, 0.93],\n",
      "     |          'split1_train_score' : [0.82, 0.55, 0.70, 0.87],\n",
      "     |          'mean_train_score'   : [0.81, 0.74, 0.70, 0.90],\n",
      "     |          'std_train_score'    : [0.01, 0.19, 0.00, 0.03],\n",
      "     |          'mean_fit_time'      : [0.73, 0.63, 0.43, 0.49],\n",
      "     |          'std_fit_time'       : [0.01, 0.02, 0.01, 0.01],\n",
      "     |          'mean_score_time'    : [0.01, 0.06, 0.04, 0.04],\n",
      "     |          'std_score_time'     : [0.00, 0.00, 0.00, 0.01],\n",
      "     |          'params'             : [{'kernel': 'poly', 'degree': 2}, ...],\n",
      "     |          }\n",
      "     |  \n",
      "     |      NOTE\n",
      "     |  \n",
      "     |      The key ``'params'`` is used to store a list of parameter\n",
      "     |      settings dicts for all the parameter candidates.\n",
      "     |  \n",
      "     |      The ``mean_fit_time``, ``std_fit_time``, ``mean_score_time`` and\n",
      "     |      ``std_score_time`` are all in seconds.\n",
      "     |  \n",
      "     |      For multi-metric evaluation, the scores for all the scorers are\n",
      "     |      available in the ``cv_results_`` dict at the keys ending with that\n",
      "     |      scorer's name (``'_<scorer_name>'``) instead of ``'_score'`` shown\n",
      "     |      above. ('split0_test_precision', 'mean_train_precision' etc.)\n",
      "     |  \n",
      "     |  best_estimator_ : estimator\n",
      "     |      Estimator that was chosen by the search, i.e. estimator\n",
      "     |      which gave highest score (or smallest loss if specified)\n",
      "     |      on the left out data. Not available if ``refit=False``.\n",
      "     |  \n",
      "     |      See ``refit`` parameter for more information on allowed values.\n",
      "     |  \n",
      "     |  best_score_ : float\n",
      "     |      Mean cross-validated score of the best_estimator\n",
      "     |  \n",
      "     |      For multi-metric evaluation, this is present only if ``refit`` is\n",
      "     |      specified.\n",
      "     |  \n",
      "     |      This attribute is not available if ``refit`` is a function.\n",
      "     |  \n",
      "     |  best_params_ : dict\n",
      "     |      Parameter setting that gave the best results on the hold out data.\n",
      "     |  \n",
      "     |      For multi-metric evaluation, this is present only if ``refit`` is\n",
      "     |      specified.\n",
      "     |  \n",
      "     |  best_index_ : int\n",
      "     |      The index (of the ``cv_results_`` arrays) which corresponds to the best\n",
      "     |      candidate parameter setting.\n",
      "     |  \n",
      "     |      The dict at ``search.cv_results_['params'][search.best_index_]`` gives\n",
      "     |      the parameter setting for the best model, that gives the highest\n",
      "     |      mean score (``search.best_score_``).\n",
      "     |  \n",
      "     |      For multi-metric evaluation, this is present only if ``refit`` is\n",
      "     |      specified.\n",
      "     |  \n",
      "     |  scorer_ : function or a dict\n",
      "     |      Scorer function used on the held out data to choose the best\n",
      "     |      parameters for the model.\n",
      "     |  \n",
      "     |      For multi-metric evaluation, this attribute holds the validated\n",
      "     |      ``scoring`` dict which maps the scorer key to the scorer callable.\n",
      "     |  \n",
      "     |  n_splits_ : int\n",
      "     |      The number of cross-validation splits (folds/iterations).\n",
      "     |  \n",
      "     |  refit_time_ : float\n",
      "     |      Seconds used for refitting the best model on the whole dataset.\n",
      "     |  \n",
      "     |      This is present only if ``refit`` is not False.\n",
      "     |  \n",
      "     |      .. versionadded:: 0.20\n",
      "     |  \n",
      "     |  Notes\n",
      "     |  -----\n",
      "     |  The parameters selected are those that maximize the score of the left out\n",
      "     |  data, unless an explicit score is passed in which case it is used instead.\n",
      "     |  \n",
      "     |  If `n_jobs` was set to a value higher than one, the data is copied for each\n",
      "     |  point in the grid (and not `n_jobs` times). This is done for efficiency\n",
      "     |  reasons if individual jobs take very little time, but may raise errors if\n",
      "     |  the dataset is large and not enough memory is available.  A workaround in\n",
      "     |  this case is to set `pre_dispatch`. Then, the memory is copied only\n",
      "     |  `pre_dispatch` many times. A reasonable value for `pre_dispatch` is `2 *\n",
      "     |  n_jobs`.\n",
      "     |  \n",
      "     |  See Also\n",
      "     |  ---------\n",
      "     |  :class:`ParameterGrid`:\n",
      "     |      generates all the combinations of a hyperparameter grid.\n",
      "     |  \n",
      "     |  :func:`sklearn.model_selection.train_test_split`:\n",
      "     |      utility function to split the data into a development set usable\n",
      "     |      for fitting a GridSearchCV instance and an evaluation set for\n",
      "     |      its final evaluation.\n",
      "     |  \n",
      "     |  :func:`sklearn.metrics.make_scorer`:\n",
      "     |      Make a scorer from a performance metric or loss function.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      GridSearchCV\n",
      "     |      BaseSearchCV\n",
      "     |      sklearn.base.MetaEstimatorMixin\n",
      "     |      sklearn.base.BaseEstimator\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, estimator, param_grid, *, scoring=None, n_jobs=None, iid='deprecated', refit=True, cv=None, verbose=0, pre_dispatch='2*n_jobs', error_score=nan, return_train_score=False)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from BaseSearchCV:\n",
      "     |  \n",
      "     |  decision_function(self, X)\n",
      "     |      Call decision_function on the estimator with the best found parameters.\n",
      "     |      \n",
      "     |      Only available if ``refit=True`` and the underlying estimator supports\n",
      "     |      ``decision_function``.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : indexable, length n_samples\n",
      "     |          Must fulfill the input assumptions of the\n",
      "     |          underlying estimator.\n",
      "     |  \n",
      "     |  fit(self, X, y=None, *, groups=None, **fit_params)\n",
      "     |      Run fit with all sets of parameters.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      \n",
      "     |      X : array-like of shape (n_samples, n_features)\n",
      "     |          Training vector, where n_samples is the number of samples and\n",
      "     |          n_features is the number of features.\n",
      "     |      \n",
      "     |      y : array-like of shape (n_samples, n_output)             or (n_samples,), default=None\n",
      "     |          Target relative to X for classification or regression;\n",
      "     |          None for unsupervised learning.\n",
      "     |      \n",
      "     |      groups : array-like of shape (n_samples,), default=None\n",
      "     |          Group labels for the samples used while splitting the dataset into\n",
      "     |          train/test set. Only used in conjunction with a \"Group\" :term:`cv`\n",
      "     |          instance (e.g., :class:`~sklearn.model_selection.GroupKFold`).\n",
      "     |      \n",
      "     |      **fit_params : dict of str -> object\n",
      "     |          Parameters passed to the ``fit`` method of the estimator\n",
      "     |  \n",
      "     |  inverse_transform(self, Xt)\n",
      "     |      Call inverse_transform on the estimator with the best found params.\n",
      "     |      \n",
      "     |      Only available if the underlying estimator implements\n",
      "     |      ``inverse_transform`` and ``refit=True``.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      Xt : indexable, length n_samples\n",
      "     |          Must fulfill the input assumptions of the\n",
      "     |          underlying estimator.\n",
      "     |  \n",
      "     |  predict(self, X)\n",
      "     |      Call predict on the estimator with the best found parameters.\n",
      "     |      \n",
      "     |      Only available if ``refit=True`` and the underlying estimator supports\n",
      "     |      ``predict``.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : indexable, length n_samples\n",
      "     |          Must fulfill the input assumptions of the\n",
      "     |          underlying estimator.\n",
      "     |  \n",
      "     |  predict_log_proba(self, X)\n",
      "     |      Call predict_log_proba on the estimator with the best found parameters.\n",
      "     |      \n",
      "     |      Only available if ``refit=True`` and the underlying estimator supports\n",
      "     |      ``predict_log_proba``.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : indexable, length n_samples\n",
      "     |          Must fulfill the input assumptions of the\n",
      "     |          underlying estimator.\n",
      "     |  \n",
      "     |  predict_proba(self, X)\n",
      "     |      Call predict_proba on the estimator with the best found parameters.\n",
      "     |      \n",
      "     |      Only available if ``refit=True`` and the underlying estimator supports\n",
      "     |      ``predict_proba``.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : indexable, length n_samples\n",
      "     |          Must fulfill the input assumptions of the\n",
      "     |          underlying estimator.\n",
      "     |  \n",
      "     |  score(self, X, y=None)\n",
      "     |      Returns the score on the given data, if the estimator has been refit.\n",
      "     |      \n",
      "     |      This uses the score defined by ``scoring`` where provided, and the\n",
      "     |      ``best_estimator_.score`` method otherwise.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like of shape (n_samples, n_features)\n",
      "     |          Input data, where n_samples is the number of samples and\n",
      "     |          n_features is the number of features.\n",
      "     |      \n",
      "     |      y : array-like of shape (n_samples, n_output)             or (n_samples,), default=None\n",
      "     |          Target relative to X for classification or regression;\n",
      "     |          None for unsupervised learning.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      score : float\n",
      "     |  \n",
      "     |  transform(self, X)\n",
      "     |      Call transform on the estimator with the best found parameters.\n",
      "     |      \n",
      "     |      Only available if the underlying estimator supports ``transform`` and\n",
      "     |      ``refit=True``.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : indexable, length n_samples\n",
      "     |          Must fulfill the input assumptions of the\n",
      "     |          underlying estimator.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from BaseSearchCV:\n",
      "     |  \n",
      "     |  classes_\n",
      "     |  \n",
      "     |  n_features_in_\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from sklearn.base.MetaEstimatorMixin:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.BaseEstimator:\n",
      "     |  \n",
      "     |  __getstate__(self)\n",
      "     |  \n",
      "     |  __repr__(self, N_CHAR_MAX=700)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |  \n",
      "     |  get_params(self, deep=True)\n",
      "     |      Get parameters for this estimator.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      deep : bool, default=True\n",
      "     |          If True, will return the parameters for this estimator and\n",
      "     |          contained subobjects that are estimators.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      params : mapping of string to any\n",
      "     |          Parameter names mapped to their values.\n",
      "     |  \n",
      "     |  set_params(self, **params)\n",
      "     |      Set the parameters of this estimator.\n",
      "     |      \n",
      "     |      The method works on simple estimators as well as on nested objects\n",
      "     |      (such as pipelines). The latter have parameters of the form\n",
      "     |      ``<component>__<parameter>`` so that it's possible to update each\n",
      "     |      component of a nested object.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      **params : dict\n",
      "     |          Estimator parameters.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          Estimator instance.\n",
      "    \n",
      "    class GroupKFold(_BaseKFold)\n",
      "     |  GroupKFold(n_splits=5)\n",
      "     |  \n",
      "     |  K-fold iterator variant with non-overlapping groups.\n",
      "     |  \n",
      "     |  The same group will not appear in two different folds (the number of\n",
      "     |  distinct groups has to be at least equal to the number of folds).\n",
      "     |  \n",
      "     |  The folds are approximately balanced in the sense that the number of\n",
      "     |  distinct groups is approximately the same in each fold.\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  n_splits : int, default=5\n",
      "     |      Number of folds. Must be at least 2.\n",
      "     |  \n",
      "     |      .. versionchanged:: 0.22\n",
      "     |          ``n_splits`` default value changed from 3 to 5.\n",
      "     |  \n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  >>> import numpy as np\n",
      "     |  >>> from sklearn.model_selection import GroupKFold\n",
      "     |  >>> X = np.array([[1, 2], [3, 4], [5, 6], [7, 8]])\n",
      "     |  >>> y = np.array([1, 2, 3, 4])\n",
      "     |  >>> groups = np.array([0, 0, 2, 2])\n",
      "     |  >>> group_kfold = GroupKFold(n_splits=2)\n",
      "     |  >>> group_kfold.get_n_splits(X, y, groups)\n",
      "     |  2\n",
      "     |  >>> print(group_kfold)\n",
      "     |  GroupKFold(n_splits=2)\n",
      "     |  >>> for train_index, test_index in group_kfold.split(X, y, groups):\n",
      "     |  ...     print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
      "     |  ...     X_train, X_test = X[train_index], X[test_index]\n",
      "     |  ...     y_train, y_test = y[train_index], y[test_index]\n",
      "     |  ...     print(X_train, X_test, y_train, y_test)\n",
      "     |  ...\n",
      "     |  TRAIN: [0 1] TEST: [2 3]\n",
      "     |  [[1 2]\n",
      "     |   [3 4]] [[5 6]\n",
      "     |   [7 8]] [1 2] [3 4]\n",
      "     |  TRAIN: [2 3] TEST: [0 1]\n",
      "     |  [[5 6]\n",
      "     |   [7 8]] [[1 2]\n",
      "     |   [3 4]] [3 4] [1 2]\n",
      "     |  \n",
      "     |  See also\n",
      "     |  --------\n",
      "     |  LeaveOneGroupOut\n",
      "     |      For splitting the data according to explicit domain-specific\n",
      "     |      stratification of the dataset.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      GroupKFold\n",
      "     |      _BaseKFold\n",
      "     |      BaseCrossValidator\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, n_splits=5)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  split(self, X, y=None, groups=None)\n",
      "     |      Generate indices to split data into training and test set.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like of shape (n_samples, n_features)\n",
      "     |          Training data, where n_samples is the number of samples\n",
      "     |          and n_features is the number of features.\n",
      "     |      \n",
      "     |      y : array-like of shape (n_samples,), default=None\n",
      "     |          The target variable for supervised learning problems.\n",
      "     |      \n",
      "     |      groups : array-like of shape (n_samples,)\n",
      "     |          Group labels for the samples used while splitting the dataset into\n",
      "     |          train/test set.\n",
      "     |      \n",
      "     |      Yields\n",
      "     |      ------\n",
      "     |      train : ndarray\n",
      "     |          The training set indices for that split.\n",
      "     |      \n",
      "     |      test : ndarray\n",
      "     |          The testing set indices for that split.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from _BaseKFold:\n",
      "     |  \n",
      "     |  get_n_splits(self, X=None, y=None, groups=None)\n",
      "     |      Returns the number of splitting iterations in the cross-validator\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : object\n",
      "     |          Always ignored, exists for compatibility.\n",
      "     |      \n",
      "     |      y : object\n",
      "     |          Always ignored, exists for compatibility.\n",
      "     |      \n",
      "     |      groups : object\n",
      "     |          Always ignored, exists for compatibility.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      n_splits : int\n",
      "     |          Returns the number of splitting iterations in the cross-validator.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from BaseCrossValidator:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from BaseCrossValidator:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class GroupShuffleSplit(ShuffleSplit)\n",
      "     |  GroupShuffleSplit(n_splits=5, *, test_size=None, train_size=None, random_state=None)\n",
      "     |  \n",
      "     |  Shuffle-Group(s)-Out cross-validation iterator\n",
      "     |  \n",
      "     |  Provides randomized train/test indices to split data according to a\n",
      "     |  third-party provided group. This group information can be used to encode\n",
      "     |  arbitrary domain specific stratifications of the samples as integers.\n",
      "     |  \n",
      "     |  For instance the groups could be the year of collection of the samples\n",
      "     |  and thus allow for cross-validation against time-based splits.\n",
      "     |  \n",
      "     |  The difference between LeavePGroupsOut and GroupShuffleSplit is that\n",
      "     |  the former generates splits using all subsets of size ``p`` unique groups,\n",
      "     |  whereas GroupShuffleSplit generates a user-determined number of random\n",
      "     |  test splits, each with a user-determined fraction of unique groups.\n",
      "     |  \n",
      "     |  For example, a less computationally intensive alternative to\n",
      "     |  ``LeavePGroupsOut(p=10)`` would be\n",
      "     |  ``GroupShuffleSplit(test_size=10, n_splits=100)``.\n",
      "     |  \n",
      "     |  Note: The parameters ``test_size`` and ``train_size`` refer to groups, and\n",
      "     |  not to samples, as in ShuffleSplit.\n",
      "     |  \n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  n_splits : int, default=5\n",
      "     |      Number of re-shuffling & splitting iterations.\n",
      "     |  \n",
      "     |  test_size : float, int, default=0.2\n",
      "     |      If float, should be between 0.0 and 1.0 and represent the proportion\n",
      "     |      of groups to include in the test split (rounded up). If int,\n",
      "     |      represents the absolute number of test groups. If None, the value is\n",
      "     |      set to the complement of the train size.\n",
      "     |      The default will change in version 0.21. It will remain 0.2 only\n",
      "     |      if ``train_size`` is unspecified, otherwise it will complement\n",
      "     |      the specified ``train_size``.\n",
      "     |  \n",
      "     |  train_size : float or int, default=None\n",
      "     |      If float, should be between 0.0 and 1.0 and represent the\n",
      "     |      proportion of the groups to include in the train split. If\n",
      "     |      int, represents the absolute number of train groups. If None,\n",
      "     |      the value is automatically set to the complement of the test size.\n",
      "     |  \n",
      "     |  random_state : int or RandomState instance, default=None\n",
      "     |      Controls the randomness of the training and testing indices produced.\n",
      "     |      Pass an int for reproducible output across multiple function calls.\n",
      "     |      See :term:`Glossary <random_state>`.\n",
      "     |  \n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  >>> import numpy as np\n",
      "     |  >>> from sklearn.model_selection import GroupShuffleSplit\n",
      "     |  >>> X = np.ones(shape=(8, 2))\n",
      "     |  >>> y = np.ones(shape=(8, 1))\n",
      "     |  >>> groups = np.array([1, 1, 2, 2, 2, 3, 3, 3])\n",
      "     |  >>> print(groups.shape)\n",
      "     |  (8,)\n",
      "     |  >>> gss = GroupShuffleSplit(n_splits=2, train_size=.7, random_state=42)\n",
      "     |  >>> gss.get_n_splits()\n",
      "     |  2\n",
      "     |  >>> for train_idx, test_idx in gss.split(X, y, groups):\n",
      "     |  ...     print(\"TRAIN:\", train_idx, \"TEST:\", test_idx)\n",
      "     |  TRAIN: [2 3 4 5 6 7] TEST: [0 1]\n",
      "     |  TRAIN: [0 1 5 6 7] TEST: [2 3 4]\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      GroupShuffleSplit\n",
      "     |      ShuffleSplit\n",
      "     |      BaseShuffleSplit\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, n_splits=5, *, test_size=None, train_size=None, random_state=None)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  split(self, X, y=None, groups=None)\n",
      "     |      Generate indices to split data into training and test set.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like of shape (n_samples, n_features)\n",
      "     |          Training data, where n_samples is the number of samples\n",
      "     |          and n_features is the number of features.\n",
      "     |      \n",
      "     |      y : array-like of shape (n_samples,), default=None\n",
      "     |          The target variable for supervised learning problems.\n",
      "     |      \n",
      "     |      groups : array-like of shape (n_samples,)\n",
      "     |          Group labels for the samples used while splitting the dataset into\n",
      "     |          train/test set.\n",
      "     |      \n",
      "     |      Yields\n",
      "     |      ------\n",
      "     |      train : ndarray\n",
      "     |          The training set indices for that split.\n",
      "     |      \n",
      "     |      test : ndarray\n",
      "     |          The testing set indices for that split.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Randomized CV splitters may return different results for each call of\n",
      "     |      split. You can make the results identical by setting `random_state`\n",
      "     |      to an integer.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from BaseShuffleSplit:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  get_n_splits(self, X=None, y=None, groups=None)\n",
      "     |      Returns the number of splitting iterations in the cross-validator\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : object\n",
      "     |          Always ignored, exists for compatibility.\n",
      "     |      \n",
      "     |      y : object\n",
      "     |          Always ignored, exists for compatibility.\n",
      "     |      \n",
      "     |      groups : object\n",
      "     |          Always ignored, exists for compatibility.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      n_splits : int\n",
      "     |          Returns the number of splitting iterations in the cross-validator.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from BaseShuffleSplit:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class KFold(_BaseKFold)\n",
      "     |  KFold(n_splits=5, *, shuffle=False, random_state=None)\n",
      "     |  \n",
      "     |  K-Folds cross-validator\n",
      "     |  \n",
      "     |  Provides train/test indices to split data in train/test sets. Split\n",
      "     |  dataset into k consecutive folds (without shuffling by default).\n",
      "     |  \n",
      "     |  Each fold is then used once as a validation while the k - 1 remaining\n",
      "     |  folds form the training set.\n",
      "     |  \n",
      "     |  Read more in the :ref:`User Guide <cross_validation>`.\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  n_splits : int, default=5\n",
      "     |      Number of folds. Must be at least 2.\n",
      "     |  \n",
      "     |      .. versionchanged:: 0.22\n",
      "     |          ``n_splits`` default value changed from 3 to 5.\n",
      "     |  \n",
      "     |  shuffle : bool, default=False\n",
      "     |      Whether to shuffle the data before splitting into batches.\n",
      "     |      Note that the samples within each split will not be shuffled.\n",
      "     |  \n",
      "     |  random_state : int or RandomState instance, default=None\n",
      "     |      When `shuffle` is True, `random_state` affects the ordering of the\n",
      "     |      indices, which controls the randomness of each fold. Otherwise, this\n",
      "     |      parameter has no effect.\n",
      "     |      Pass an int for reproducible output across multiple function calls.\n",
      "     |      See :term:`Glossary <random_state>`.\n",
      "     |  \n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  >>> import numpy as np\n",
      "     |  >>> from sklearn.model_selection import KFold\n",
      "     |  >>> X = np.array([[1, 2], [3, 4], [1, 2], [3, 4]])\n",
      "     |  >>> y = np.array([1, 2, 3, 4])\n",
      "     |  >>> kf = KFold(n_splits=2)\n",
      "     |  >>> kf.get_n_splits(X)\n",
      "     |  2\n",
      "     |  >>> print(kf)\n",
      "     |  KFold(n_splits=2, random_state=None, shuffle=False)\n",
      "     |  >>> for train_index, test_index in kf.split(X):\n",
      "     |  ...     print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
      "     |  ...     X_train, X_test = X[train_index], X[test_index]\n",
      "     |  ...     y_train, y_test = y[train_index], y[test_index]\n",
      "     |  TRAIN: [2 3] TEST: [0 1]\n",
      "     |  TRAIN: [0 1] TEST: [2 3]\n",
      "     |  \n",
      "     |  Notes\n",
      "     |  -----\n",
      "     |  The first ``n_samples % n_splits`` folds have size\n",
      "     |  ``n_samples // n_splits + 1``, other folds have size\n",
      "     |  ``n_samples // n_splits``, where ``n_samples`` is the number of samples.\n",
      "     |  \n",
      "     |  Randomized CV splitters may return different results for each call of\n",
      "     |  split. You can make the results identical by setting `random_state`\n",
      "     |  to an integer.\n",
      "     |  \n",
      "     |  See also\n",
      "     |  --------\n",
      "     |  StratifiedKFold\n",
      "     |      Takes group information into account to avoid building folds with\n",
      "     |      imbalanced class distributions (for binary or multiclass\n",
      "     |      classification tasks).\n",
      "     |  \n",
      "     |  GroupKFold: K-fold iterator variant with non-overlapping groups.\n",
      "     |  \n",
      "     |  RepeatedKFold: Repeats K-Fold n times.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      KFold\n",
      "     |      _BaseKFold\n",
      "     |      BaseCrossValidator\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, n_splits=5, *, shuffle=False, random_state=None)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from _BaseKFold:\n",
      "     |  \n",
      "     |  get_n_splits(self, X=None, y=None, groups=None)\n",
      "     |      Returns the number of splitting iterations in the cross-validator\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : object\n",
      "     |          Always ignored, exists for compatibility.\n",
      "     |      \n",
      "     |      y : object\n",
      "     |          Always ignored, exists for compatibility.\n",
      "     |      \n",
      "     |      groups : object\n",
      "     |          Always ignored, exists for compatibility.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      n_splits : int\n",
      "     |          Returns the number of splitting iterations in the cross-validator.\n",
      "     |  \n",
      "     |  split(self, X, y=None, groups=None)\n",
      "     |      Generate indices to split data into training and test set.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like of shape (n_samples, n_features)\n",
      "     |          Training data, where n_samples is the number of samples\n",
      "     |          and n_features is the number of features.\n",
      "     |      \n",
      "     |      y : array-like of shape (n_samples,), default=None\n",
      "     |          The target variable for supervised learning problems.\n",
      "     |      \n",
      "     |      groups : array-like of shape (n_samples,), default=None\n",
      "     |          Group labels for the samples used while splitting the dataset into\n",
      "     |          train/test set.\n",
      "     |      \n",
      "     |      Yields\n",
      "     |      ------\n",
      "     |      train : ndarray\n",
      "     |          The training set indices for that split.\n",
      "     |      \n",
      "     |      test : ndarray\n",
      "     |          The testing set indices for that split.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from BaseCrossValidator:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from BaseCrossValidator:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class LeaveOneGroupOut(BaseCrossValidator)\n",
      "     |  Leave One Group Out cross-validator\n",
      "     |  \n",
      "     |  Provides train/test indices to split data according to a third-party\n",
      "     |  provided group. This group information can be used to encode arbitrary\n",
      "     |  domain specific stratifications of the samples as integers.\n",
      "     |  \n",
      "     |  For instance the groups could be the year of collection of the samples\n",
      "     |  and thus allow for cross-validation against time-based splits.\n",
      "     |  \n",
      "     |  Read more in the :ref:`User Guide <cross_validation>`.\n",
      "     |  \n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  >>> import numpy as np\n",
      "     |  >>> from sklearn.model_selection import LeaveOneGroupOut\n",
      "     |  >>> X = np.array([[1, 2], [3, 4], [5, 6], [7, 8]])\n",
      "     |  >>> y = np.array([1, 2, 1, 2])\n",
      "     |  >>> groups = np.array([1, 1, 2, 2])\n",
      "     |  >>> logo = LeaveOneGroupOut()\n",
      "     |  >>> logo.get_n_splits(X, y, groups)\n",
      "     |  2\n",
      "     |  >>> logo.get_n_splits(groups=groups)  # 'groups' is always required\n",
      "     |  2\n",
      "     |  >>> print(logo)\n",
      "     |  LeaveOneGroupOut()\n",
      "     |  >>> for train_index, test_index in logo.split(X, y, groups):\n",
      "     |  ...     print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
      "     |  ...     X_train, X_test = X[train_index], X[test_index]\n",
      "     |  ...     y_train, y_test = y[train_index], y[test_index]\n",
      "     |  ...     print(X_train, X_test, y_train, y_test)\n",
      "     |  TRAIN: [2 3] TEST: [0 1]\n",
      "     |  [[5 6]\n",
      "     |   [7 8]] [[1 2]\n",
      "     |   [3 4]] [1 2] [1 2]\n",
      "     |  TRAIN: [0 1] TEST: [2 3]\n",
      "     |  [[1 2]\n",
      "     |   [3 4]] [[5 6]\n",
      "     |   [7 8]] [1 2] [1 2]\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      LeaveOneGroupOut\n",
      "     |      BaseCrossValidator\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  get_n_splits(self, X=None, y=None, groups=None)\n",
      "     |      Returns the number of splitting iterations in the cross-validator\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : object\n",
      "     |          Always ignored, exists for compatibility.\n",
      "     |      \n",
      "     |      y : object\n",
      "     |          Always ignored, exists for compatibility.\n",
      "     |      \n",
      "     |      groups : array-like of shape (n_samples,)\n",
      "     |          Group labels for the samples used while splitting the dataset into\n",
      "     |          train/test set. This 'groups' parameter must always be specified to\n",
      "     |          calculate the number of splits, though the other parameters can be\n",
      "     |          omitted.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      n_splits : int\n",
      "     |          Returns the number of splitting iterations in the cross-validator.\n",
      "     |  \n",
      "     |  split(self, X, y=None, groups=None)\n",
      "     |      Generate indices to split data into training and test set.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like of shape (n_samples, n_features)\n",
      "     |          Training data, where n_samples is the number of samples\n",
      "     |          and n_features is the number of features.\n",
      "     |      \n",
      "     |      y : array-like of shape (n_samples,), default=None\n",
      "     |          The target variable for supervised learning problems.\n",
      "     |      \n",
      "     |      groups : array-like of shape (n_samples,)\n",
      "     |          Group labels for the samples used while splitting the dataset into\n",
      "     |          train/test set.\n",
      "     |      \n",
      "     |      Yields\n",
      "     |      ------\n",
      "     |      train : ndarray\n",
      "     |          The training set indices for that split.\n",
      "     |      \n",
      "     |      test : ndarray\n",
      "     |          The testing set indices for that split.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from BaseCrossValidator:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from BaseCrossValidator:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class LeaveOneOut(BaseCrossValidator)\n",
      "     |  Leave-One-Out cross-validator\n",
      "     |  \n",
      "     |  Provides train/test indices to split data in train/test sets. Each\n",
      "     |  sample is used once as a test set (singleton) while the remaining\n",
      "     |  samples form the training set.\n",
      "     |  \n",
      "     |  Note: ``LeaveOneOut()`` is equivalent to ``KFold(n_splits=n)`` and\n",
      "     |  ``LeavePOut(p=1)`` where ``n`` is the number of samples.\n",
      "     |  \n",
      "     |  Due to the high number of test sets (which is the same as the\n",
      "     |  number of samples) this cross-validation method can be very costly.\n",
      "     |  For large datasets one should favor :class:`KFold`, :class:`ShuffleSplit`\n",
      "     |  or :class:`StratifiedKFold`.\n",
      "     |  \n",
      "     |  Read more in the :ref:`User Guide <cross_validation>`.\n",
      "     |  \n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  >>> import numpy as np\n",
      "     |  >>> from sklearn.model_selection import LeaveOneOut\n",
      "     |  >>> X = np.array([[1, 2], [3, 4]])\n",
      "     |  >>> y = np.array([1, 2])\n",
      "     |  >>> loo = LeaveOneOut()\n",
      "     |  >>> loo.get_n_splits(X)\n",
      "     |  2\n",
      "     |  >>> print(loo)\n",
      "     |  LeaveOneOut()\n",
      "     |  >>> for train_index, test_index in loo.split(X):\n",
      "     |  ...     print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
      "     |  ...     X_train, X_test = X[train_index], X[test_index]\n",
      "     |  ...     y_train, y_test = y[train_index], y[test_index]\n",
      "     |  ...     print(X_train, X_test, y_train, y_test)\n",
      "     |  TRAIN: [1] TEST: [0]\n",
      "     |  [[3 4]] [[1 2]] [2] [1]\n",
      "     |  TRAIN: [0] TEST: [1]\n",
      "     |  [[1 2]] [[3 4]] [1] [2]\n",
      "     |  \n",
      "     |  See also\n",
      "     |  --------\n",
      "     |  LeaveOneGroupOut\n",
      "     |      For splitting the data according to explicit, domain-specific\n",
      "     |      stratification of the dataset.\n",
      "     |  \n",
      "     |  GroupKFold: K-fold iterator variant with non-overlapping groups.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      LeaveOneOut\n",
      "     |      BaseCrossValidator\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  get_n_splits(self, X, y=None, groups=None)\n",
      "     |      Returns the number of splitting iterations in the cross-validator\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like of shape (n_samples, n_features)\n",
      "     |          Training data, where n_samples is the number of samples\n",
      "     |          and n_features is the number of features.\n",
      "     |      \n",
      "     |      y : object\n",
      "     |          Always ignored, exists for compatibility.\n",
      "     |      \n",
      "     |      groups : object\n",
      "     |          Always ignored, exists for compatibility.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      n_splits : int\n",
      "     |          Returns the number of splitting iterations in the cross-validator.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from BaseCrossValidator:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  split(self, X, y=None, groups=None)\n",
      "     |      Generate indices to split data into training and test set.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like of shape (n_samples, n_features)\n",
      "     |          Training data, where n_samples is the number of samples\n",
      "     |          and n_features is the number of features.\n",
      "     |      \n",
      "     |      y : array-like of shape (n_samples,)\n",
      "     |          The target variable for supervised learning problems.\n",
      "     |      \n",
      "     |      groups : array-like of shape (n_samples,), default=None\n",
      "     |          Group labels for the samples used while splitting the dataset into\n",
      "     |          train/test set.\n",
      "     |      \n",
      "     |      Yields\n",
      "     |      ------\n",
      "     |      train : ndarray\n",
      "     |          The training set indices for that split.\n",
      "     |      \n",
      "     |      test : ndarray\n",
      "     |          The testing set indices for that split.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from BaseCrossValidator:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class LeavePGroupsOut(BaseCrossValidator)\n",
      "     |  LeavePGroupsOut(n_groups)\n",
      "     |  \n",
      "     |  Leave P Group(s) Out cross-validator\n",
      "     |  \n",
      "     |  Provides train/test indices to split data according to a third-party\n",
      "     |  provided group. This group information can be used to encode arbitrary\n",
      "     |  domain specific stratifications of the samples as integers.\n",
      "     |  \n",
      "     |  For instance the groups could be the year of collection of the samples\n",
      "     |  and thus allow for cross-validation against time-based splits.\n",
      "     |  \n",
      "     |  The difference between LeavePGroupsOut and LeaveOneGroupOut is that\n",
      "     |  the former builds the test sets with all the samples assigned to\n",
      "     |  ``p`` different values of the groups while the latter uses samples\n",
      "     |  all assigned the same groups.\n",
      "     |  \n",
      "     |  Read more in the :ref:`User Guide <cross_validation>`.\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  n_groups : int\n",
      "     |      Number of groups (``p``) to leave out in the test split.\n",
      "     |  \n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  >>> import numpy as np\n",
      "     |  >>> from sklearn.model_selection import LeavePGroupsOut\n",
      "     |  >>> X = np.array([[1, 2], [3, 4], [5, 6]])\n",
      "     |  >>> y = np.array([1, 2, 1])\n",
      "     |  >>> groups = np.array([1, 2, 3])\n",
      "     |  >>> lpgo = LeavePGroupsOut(n_groups=2)\n",
      "     |  >>> lpgo.get_n_splits(X, y, groups)\n",
      "     |  3\n",
      "     |  >>> lpgo.get_n_splits(groups=groups)  # 'groups' is always required\n",
      "     |  3\n",
      "     |  >>> print(lpgo)\n",
      "     |  LeavePGroupsOut(n_groups=2)\n",
      "     |  >>> for train_index, test_index in lpgo.split(X, y, groups):\n",
      "     |  ...     print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
      "     |  ...     X_train, X_test = X[train_index], X[test_index]\n",
      "     |  ...     y_train, y_test = y[train_index], y[test_index]\n",
      "     |  ...     print(X_train, X_test, y_train, y_test)\n",
      "     |  TRAIN: [2] TEST: [0 1]\n",
      "     |  [[5 6]] [[1 2]\n",
      "     |   [3 4]] [1] [1 2]\n",
      "     |  TRAIN: [1] TEST: [0 2]\n",
      "     |  [[3 4]] [[1 2]\n",
      "     |   [5 6]] [2] [1 1]\n",
      "     |  TRAIN: [0] TEST: [1 2]\n",
      "     |  [[1 2]] [[3 4]\n",
      "     |   [5 6]] [1] [2 1]\n",
      "     |  \n",
      "     |  See also\n",
      "     |  --------\n",
      "     |  GroupKFold: K-fold iterator variant with non-overlapping groups.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      LeavePGroupsOut\n",
      "     |      BaseCrossValidator\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, n_groups)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  get_n_splits(self, X=None, y=None, groups=None)\n",
      "     |      Returns the number of splitting iterations in the cross-validator\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : object\n",
      "     |          Always ignored, exists for compatibility.\n",
      "     |      \n",
      "     |      y : object\n",
      "     |          Always ignored, exists for compatibility.\n",
      "     |      \n",
      "     |      groups : array-like of shape (n_samples,)\n",
      "     |          Group labels for the samples used while splitting the dataset into\n",
      "     |          train/test set. This 'groups' parameter must always be specified to\n",
      "     |          calculate the number of splits, though the other parameters can be\n",
      "     |          omitted.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      n_splits : int\n",
      "     |          Returns the number of splitting iterations in the cross-validator.\n",
      "     |  \n",
      "     |  split(self, X, y=None, groups=None)\n",
      "     |      Generate indices to split data into training and test set.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like of shape (n_samples, n_features)\n",
      "     |          Training data, where n_samples is the number of samples\n",
      "     |          and n_features is the number of features.\n",
      "     |      \n",
      "     |      y : array-like of shape (n_samples,), default=None\n",
      "     |          The target variable for supervised learning problems.\n",
      "     |      \n",
      "     |      groups : array-like of shape (n_samples,)\n",
      "     |          Group labels for the samples used while splitting the dataset into\n",
      "     |          train/test set.\n",
      "     |      \n",
      "     |      Yields\n",
      "     |      ------\n",
      "     |      train : ndarray\n",
      "     |          The training set indices for that split.\n",
      "     |      \n",
      "     |      test : ndarray\n",
      "     |          The testing set indices for that split.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from BaseCrossValidator:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from BaseCrossValidator:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class LeavePOut(BaseCrossValidator)\n",
      "     |  LeavePOut(p)\n",
      "     |  \n",
      "     |  Leave-P-Out cross-validator\n",
      "     |  \n",
      "     |  Provides train/test indices to split data in train/test sets. This results\n",
      "     |  in testing on all distinct samples of size p, while the remaining n - p\n",
      "     |  samples form the training set in each iteration.\n",
      "     |  \n",
      "     |  Note: ``LeavePOut(p)`` is NOT equivalent to\n",
      "     |  ``KFold(n_splits=n_samples // p)`` which creates non-overlapping test sets.\n",
      "     |  \n",
      "     |  Due to the high number of iterations which grows combinatorically with the\n",
      "     |  number of samples this cross-validation method can be very costly. For\n",
      "     |  large datasets one should favor :class:`KFold`, :class:`StratifiedKFold`\n",
      "     |  or :class:`ShuffleSplit`.\n",
      "     |  \n",
      "     |  Read more in the :ref:`User Guide <cross_validation>`.\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  p : int\n",
      "     |      Size of the test sets. Must be strictly less than the number of\n",
      "     |      samples.\n",
      "     |  \n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  >>> import numpy as np\n",
      "     |  >>> from sklearn.model_selection import LeavePOut\n",
      "     |  >>> X = np.array([[1, 2], [3, 4], [5, 6], [7, 8]])\n",
      "     |  >>> y = np.array([1, 2, 3, 4])\n",
      "     |  >>> lpo = LeavePOut(2)\n",
      "     |  >>> lpo.get_n_splits(X)\n",
      "     |  6\n",
      "     |  >>> print(lpo)\n",
      "     |  LeavePOut(p=2)\n",
      "     |  >>> for train_index, test_index in lpo.split(X):\n",
      "     |  ...     print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
      "     |  ...     X_train, X_test = X[train_index], X[test_index]\n",
      "     |  ...     y_train, y_test = y[train_index], y[test_index]\n",
      "     |  TRAIN: [2 3] TEST: [0 1]\n",
      "     |  TRAIN: [1 3] TEST: [0 2]\n",
      "     |  TRAIN: [1 2] TEST: [0 3]\n",
      "     |  TRAIN: [0 3] TEST: [1 2]\n",
      "     |  TRAIN: [0 2] TEST: [1 3]\n",
      "     |  TRAIN: [0 1] TEST: [2 3]\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      LeavePOut\n",
      "     |      BaseCrossValidator\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, p)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  get_n_splits(self, X, y=None, groups=None)\n",
      "     |      Returns the number of splitting iterations in the cross-validator\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like of shape (n_samples, n_features)\n",
      "     |          Training data, where n_samples is the number of samples\n",
      "     |          and n_features is the number of features.\n",
      "     |      \n",
      "     |      y : object\n",
      "     |          Always ignored, exists for compatibility.\n",
      "     |      \n",
      "     |      groups : object\n",
      "     |          Always ignored, exists for compatibility.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from BaseCrossValidator:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  split(self, X, y=None, groups=None)\n",
      "     |      Generate indices to split data into training and test set.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like of shape (n_samples, n_features)\n",
      "     |          Training data, where n_samples is the number of samples\n",
      "     |          and n_features is the number of features.\n",
      "     |      \n",
      "     |      y : array-like of shape (n_samples,)\n",
      "     |          The target variable for supervised learning problems.\n",
      "     |      \n",
      "     |      groups : array-like of shape (n_samples,), default=None\n",
      "     |          Group labels for the samples used while splitting the dataset into\n",
      "     |          train/test set.\n",
      "     |      \n",
      "     |      Yields\n",
      "     |      ------\n",
      "     |      train : ndarray\n",
      "     |          The training set indices for that split.\n",
      "     |      \n",
      "     |      test : ndarray\n",
      "     |          The testing set indices for that split.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from BaseCrossValidator:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class ParameterGrid(builtins.object)\n",
      "     |  ParameterGrid(param_grid)\n",
      "     |  \n",
      "     |  Grid of parameters with a discrete number of values for each.\n",
      "     |  \n",
      "     |  Can be used to iterate over parameter value combinations with the\n",
      "     |  Python built-in function iter.\n",
      "     |  \n",
      "     |  Read more in the :ref:`User Guide <grid_search>`.\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  param_grid : dict of str to sequence, or sequence of such\n",
      "     |      The parameter grid to explore, as a dictionary mapping estimator\n",
      "     |      parameters to sequences of allowed values.\n",
      "     |  \n",
      "     |      An empty dict signifies default parameters.\n",
      "     |  \n",
      "     |      A sequence of dicts signifies a sequence of grids to search, and is\n",
      "     |      useful to avoid exploring parameter combinations that make no sense\n",
      "     |      or have no effect. See the examples below.\n",
      "     |  \n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  >>> from sklearn.model_selection import ParameterGrid\n",
      "     |  >>> param_grid = {'a': [1, 2], 'b': [True, False]}\n",
      "     |  >>> list(ParameterGrid(param_grid)) == (\n",
      "     |  ...    [{'a': 1, 'b': True}, {'a': 1, 'b': False},\n",
      "     |  ...     {'a': 2, 'b': True}, {'a': 2, 'b': False}])\n",
      "     |  True\n",
      "     |  \n",
      "     |  >>> grid = [{'kernel': ['linear']}, {'kernel': ['rbf'], 'gamma': [1, 10]}]\n",
      "     |  >>> list(ParameterGrid(grid)) == [{'kernel': 'linear'},\n",
      "     |  ...                               {'kernel': 'rbf', 'gamma': 1},\n",
      "     |  ...                               {'kernel': 'rbf', 'gamma': 10}]\n",
      "     |  True\n",
      "     |  >>> ParameterGrid(grid)[1] == {'kernel': 'rbf', 'gamma': 1}\n",
      "     |  True\n",
      "     |  \n",
      "     |  See also\n",
      "     |  --------\n",
      "     |  :class:`GridSearchCV`:\n",
      "     |      Uses :class:`ParameterGrid` to perform a full parallelized parameter\n",
      "     |      search.\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __getitem__(self, ind)\n",
      "     |      Get the parameters that would be ``ind``th in iteration\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      ind : int\n",
      "     |          The iteration index\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      params : dict of str to any\n",
      "     |          Equal to list(self)[ind]\n",
      "     |  \n",
      "     |  __init__(self, param_grid)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |      Iterate over the points in the grid.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      params : iterator over dict of str to any\n",
      "     |          Yields dictionaries mapping each estimator parameter to one of its\n",
      "     |          allowed values.\n",
      "     |  \n",
      "     |  __len__(self)\n",
      "     |      Number of points on the grid.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class ParameterSampler(builtins.object)\n",
      "     |  ParameterSampler(param_distributions, n_iter, *, random_state=None)\n",
      "     |  \n",
      "     |  Generator on parameters sampled from given distributions.\n",
      "     |  \n",
      "     |  Non-deterministic iterable over random candidate combinations for hyper-\n",
      "     |  parameter search. If all parameters are presented as a list,\n",
      "     |  sampling without replacement is performed. If at least one parameter\n",
      "     |  is given as a distribution, sampling with replacement is used.\n",
      "     |  It is highly recommended to use continuous distributions for continuous\n",
      "     |  parameters.\n",
      "     |  \n",
      "     |  Read more in the :ref:`User Guide <grid_search>`.\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  param_distributions : dict\n",
      "     |      Dictionary with parameters names (`str`) as keys and distributions\n",
      "     |      or lists of parameters to try. Distributions must provide a ``rvs``\n",
      "     |      method for sampling (such as those from scipy.stats.distributions).\n",
      "     |      If a list is given, it is sampled uniformly.\n",
      "     |      If a list of dicts is given, first a dict is sampled uniformly, and\n",
      "     |      then a parameter is sampled using that dict as above.\n",
      "     |  \n",
      "     |  n_iter : integer\n",
      "     |      Number of parameter settings that are produced.\n",
      "     |  \n",
      "     |  random_state : int or RandomState instance, default=None\n",
      "     |      Pseudo random number generator state used for random uniform sampling\n",
      "     |      from lists of possible values instead of scipy.stats distributions.\n",
      "     |      Pass an int for reproducible output across multiple\n",
      "     |      function calls.\n",
      "     |      See :term:`Glossary <random_state>`.\n",
      "     |  \n",
      "     |  Returns\n",
      "     |  -------\n",
      "     |  params : dict of str to any\n",
      "     |      **Yields** dictionaries mapping each estimator parameter to\n",
      "     |      as sampled value.\n",
      "     |  \n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  >>> from sklearn.model_selection import ParameterSampler\n",
      "     |  >>> from scipy.stats.distributions import expon\n",
      "     |  >>> import numpy as np\n",
      "     |  >>> rng = np.random.RandomState(0)\n",
      "     |  >>> param_grid = {'a':[1, 2], 'b': expon()}\n",
      "     |  >>> param_list = list(ParameterSampler(param_grid, n_iter=4,\n",
      "     |  ...                                    random_state=rng))\n",
      "     |  >>> rounded_list = [dict((k, round(v, 6)) for (k, v) in d.items())\n",
      "     |  ...                 for d in param_list]\n",
      "     |  >>> rounded_list == [{'b': 0.89856, 'a': 1},\n",
      "     |  ...                  {'b': 0.923223, 'a': 1},\n",
      "     |  ...                  {'b': 1.878964, 'a': 2},\n",
      "     |  ...                  {'b': 1.038159, 'a': 2}]\n",
      "     |  True\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, param_distributions, n_iter, *, random_state=None)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |  \n",
      "     |  __len__(self)\n",
      "     |      Number of points that will be sampled.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class PredefinedSplit(BaseCrossValidator)\n",
      "     |  PredefinedSplit(test_fold)\n",
      "     |  \n",
      "     |  Predefined split cross-validator\n",
      "     |  \n",
      "     |  Provides train/test indices to split data into train/test sets using a\n",
      "     |  predefined scheme specified by the user with the ``test_fold`` parameter.\n",
      "     |  \n",
      "     |  Read more in the :ref:`User Guide <cross_validation>`.\n",
      "     |  \n",
      "     |  .. versionadded:: 0.16\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  test_fold : array-like of shape (n_samples,)\n",
      "     |      The entry ``test_fold[i]`` represents the index of the test set that\n",
      "     |      sample ``i`` belongs to. It is possible to exclude sample ``i`` from\n",
      "     |      any test set (i.e. include sample ``i`` in every training set) by\n",
      "     |      setting ``test_fold[i]`` equal to -1.\n",
      "     |  \n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  >>> import numpy as np\n",
      "     |  >>> from sklearn.model_selection import PredefinedSplit\n",
      "     |  >>> X = np.array([[1, 2], [3, 4], [1, 2], [3, 4]])\n",
      "     |  >>> y = np.array([0, 0, 1, 1])\n",
      "     |  >>> test_fold = [0, 1, -1, 1]\n",
      "     |  >>> ps = PredefinedSplit(test_fold)\n",
      "     |  >>> ps.get_n_splits()\n",
      "     |  2\n",
      "     |  >>> print(ps)\n",
      "     |  PredefinedSplit(test_fold=array([ 0,  1, -1,  1]))\n",
      "     |  >>> for train_index, test_index in ps.split():\n",
      "     |  ...     print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
      "     |  ...     X_train, X_test = X[train_index], X[test_index]\n",
      "     |  ...     y_train, y_test = y[train_index], y[test_index]\n",
      "     |  TRAIN: [1 2 3] TEST: [0]\n",
      "     |  TRAIN: [0 2] TEST: [1 3]\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      PredefinedSplit\n",
      "     |      BaseCrossValidator\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, test_fold)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  get_n_splits(self, X=None, y=None, groups=None)\n",
      "     |      Returns the number of splitting iterations in the cross-validator\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : object\n",
      "     |          Always ignored, exists for compatibility.\n",
      "     |      \n",
      "     |      y : object\n",
      "     |          Always ignored, exists for compatibility.\n",
      "     |      \n",
      "     |      groups : object\n",
      "     |          Always ignored, exists for compatibility.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      n_splits : int\n",
      "     |          Returns the number of splitting iterations in the cross-validator.\n",
      "     |  \n",
      "     |  split(self, X=None, y=None, groups=None)\n",
      "     |      Generate indices to split data into training and test set.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : object\n",
      "     |          Always ignored, exists for compatibility.\n",
      "     |      \n",
      "     |      y : object\n",
      "     |          Always ignored, exists for compatibility.\n",
      "     |      \n",
      "     |      groups : object\n",
      "     |          Always ignored, exists for compatibility.\n",
      "     |      \n",
      "     |      Yields\n",
      "     |      ------\n",
      "     |      train : ndarray\n",
      "     |          The training set indices for that split.\n",
      "     |      \n",
      "     |      test : ndarray\n",
      "     |          The testing set indices for that split.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from BaseCrossValidator:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from BaseCrossValidator:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class RandomizedSearchCV(BaseSearchCV)\n",
      "     |  RandomizedSearchCV(estimator, param_distributions, *, n_iter=10, scoring=None, n_jobs=None, iid='deprecated', refit=True, cv=None, verbose=0, pre_dispatch='2*n_jobs', random_state=None, error_score=nan, return_train_score=False)\n",
      "     |  \n",
      "     |  Randomized search on hyper parameters.\n",
      "     |  \n",
      "     |  RandomizedSearchCV implements a \"fit\" and a \"score\" method.\n",
      "     |  It also implements \"predict\", \"predict_proba\", \"decision_function\",\n",
      "     |  \"transform\" and \"inverse_transform\" if they are implemented in the\n",
      "     |  estimator used.\n",
      "     |  \n",
      "     |  The parameters of the estimator used to apply these methods are optimized\n",
      "     |  by cross-validated search over parameter settings.\n",
      "     |  \n",
      "     |  In contrast to GridSearchCV, not all parameter values are tried out, but\n",
      "     |  rather a fixed number of parameter settings is sampled from the specified\n",
      "     |  distributions. The number of parameter settings that are tried is\n",
      "     |  given by n_iter.\n",
      "     |  \n",
      "     |  If all parameters are presented as a list,\n",
      "     |  sampling without replacement is performed. If at least one parameter\n",
      "     |  is given as a distribution, sampling with replacement is used.\n",
      "     |  It is highly recommended to use continuous distributions for continuous\n",
      "     |  parameters.\n",
      "     |  \n",
      "     |  Read more in the :ref:`User Guide <randomized_parameter_search>`.\n",
      "     |  \n",
      "     |  .. versionadded:: 0.14\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  estimator : estimator object.\n",
      "     |      A object of that type is instantiated for each grid point.\n",
      "     |      This is assumed to implement the scikit-learn estimator interface.\n",
      "     |      Either estimator needs to provide a ``score`` function,\n",
      "     |      or ``scoring`` must be passed.\n",
      "     |  \n",
      "     |  param_distributions : dict or list of dicts\n",
      "     |      Dictionary with parameters names (`str`) as keys and distributions\n",
      "     |      or lists of parameters to try. Distributions must provide a ``rvs``\n",
      "     |      method for sampling (such as those from scipy.stats.distributions).\n",
      "     |      If a list is given, it is sampled uniformly.\n",
      "     |      If a list of dicts is given, first a dict is sampled uniformly, and\n",
      "     |      then a parameter is sampled using that dict as above.\n",
      "     |  \n",
      "     |  n_iter : int, default=10\n",
      "     |      Number of parameter settings that are sampled. n_iter trades\n",
      "     |      off runtime vs quality of the solution.\n",
      "     |  \n",
      "     |  scoring : str, callable, list/tuple or dict, default=None\n",
      "     |      A single str (see :ref:`scoring_parameter`) or a callable\n",
      "     |      (see :ref:`scoring`) to evaluate the predictions on the test set.\n",
      "     |  \n",
      "     |      For evaluating multiple metrics, either give a list of (unique) strings\n",
      "     |      or a dict with names as keys and callables as values.\n",
      "     |  \n",
      "     |      NOTE that when using custom scorers, each scorer should return a single\n",
      "     |      value. Metric functions returning a list/array of values can be wrapped\n",
      "     |      into multiple scorers that return one value each.\n",
      "     |  \n",
      "     |      See :ref:`multimetric_grid_search` for an example.\n",
      "     |  \n",
      "     |      If None, the estimator's score method is used.\n",
      "     |  \n",
      "     |  n_jobs : int, default=None\n",
      "     |      Number of jobs to run in parallel.\n",
      "     |      ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
      "     |      ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
      "     |      for more details.\n",
      "     |  \n",
      "     |      .. versionchanged:: v0.20\n",
      "     |         `n_jobs` default changed from 1 to None\n",
      "     |  \n",
      "     |  pre_dispatch : int, or str, default=None\n",
      "     |      Controls the number of jobs that get dispatched during parallel\n",
      "     |      execution. Reducing this number can be useful to avoid an\n",
      "     |      explosion of memory consumption when more jobs get dispatched\n",
      "     |      than CPUs can process. This parameter can be:\n",
      "     |  \n",
      "     |          - None, in which case all the jobs are immediately\n",
      "     |            created and spawned. Use this for lightweight and\n",
      "     |            fast-running jobs, to avoid delays due to on-demand\n",
      "     |            spawning of the jobs\n",
      "     |  \n",
      "     |          - An int, giving the exact number of total jobs that are\n",
      "     |            spawned\n",
      "     |  \n",
      "     |          - A str, giving an expression as a function of n_jobs,\n",
      "     |            as in '2*n_jobs'\n",
      "     |  \n",
      "     |  iid : bool, default=False\n",
      "     |      If True, return the average score across folds, weighted by the number\n",
      "     |      of samples in each test set. In this case, the data is assumed to be\n",
      "     |      identically distributed across the folds, and the loss minimized is\n",
      "     |      the total loss per sample, and not the mean loss across the folds.\n",
      "     |  \n",
      "     |      .. deprecated:: 0.22\n",
      "     |          Parameter ``iid`` is deprecated in 0.22 and will be removed in 0.24\n",
      "     |  \n",
      "     |  cv : int, cross-validation generator or an iterable, default=None\n",
      "     |      Determines the cross-validation splitting strategy.\n",
      "     |      Possible inputs for cv are:\n",
      "     |  \n",
      "     |      - None, to use the default 5-fold cross validation,\n",
      "     |      - integer, to specify the number of folds in a `(Stratified)KFold`,\n",
      "     |      - :term:`CV splitter`,\n",
      "     |      - An iterable yielding (train, test) splits as arrays of indices.\n",
      "     |  \n",
      "     |      For integer/None inputs, if the estimator is a classifier and ``y`` is\n",
      "     |      either binary or multiclass, :class:`StratifiedKFold` is used. In all\n",
      "     |      other cases, :class:`KFold` is used.\n",
      "     |  \n",
      "     |      Refer :ref:`User Guide <cross_validation>` for the various\n",
      "     |      cross-validation strategies that can be used here.\n",
      "     |  \n",
      "     |      .. versionchanged:: 0.22\n",
      "     |          ``cv`` default value if None changed from 3-fold to 5-fold.\n",
      "     |  \n",
      "     |  refit : bool, str, or callable, default=True\n",
      "     |      Refit an estimator using the best found parameters on the whole\n",
      "     |      dataset.\n",
      "     |  \n",
      "     |      For multiple metric evaluation, this needs to be a `str` denoting the\n",
      "     |      scorer that would be used to find the best parameters for refitting\n",
      "     |      the estimator at the end.\n",
      "     |  \n",
      "     |      Where there are considerations other than maximum score in\n",
      "     |      choosing a best estimator, ``refit`` can be set to a function which\n",
      "     |      returns the selected ``best_index_`` given the ``cv_results``. In that\n",
      "     |      case, the ``best_estimator_`` and ``best_params_`` will be set\n",
      "     |      according to the returned ``best_index_`` while the ``best_score_``\n",
      "     |      attribute will not be available.\n",
      "     |  \n",
      "     |      The refitted estimator is made available at the ``best_estimator_``\n",
      "     |      attribute and permits using ``predict`` directly on this\n",
      "     |      ``RandomizedSearchCV`` instance.\n",
      "     |  \n",
      "     |      Also for multiple metric evaluation, the attributes ``best_index_``,\n",
      "     |      ``best_score_`` and ``best_params_`` will only be available if\n",
      "     |      ``refit`` is set and all of them will be determined w.r.t this specific\n",
      "     |      scorer.\n",
      "     |  \n",
      "     |      See ``scoring`` parameter to know more about multiple metric\n",
      "     |      evaluation.\n",
      "     |  \n",
      "     |      .. versionchanged:: 0.20\n",
      "     |          Support for callable added.\n",
      "     |  \n",
      "     |  verbose : integer\n",
      "     |      Controls the verbosity: the higher, the more messages.\n",
      "     |  \n",
      "     |  random_state : int or RandomState instance, default=None\n",
      "     |      Pseudo random number generator state used for random uniform sampling\n",
      "     |      from lists of possible values instead of scipy.stats distributions.\n",
      "     |      Pass an int for reproducible output across multiple\n",
      "     |      function calls.\n",
      "     |      See :term:`Glossary <random_state>`.\n",
      "     |  \n",
      "     |  error_score : 'raise' or numeric, default=np.nan\n",
      "     |      Value to assign to the score if an error occurs in estimator fitting.\n",
      "     |      If set to 'raise', the error is raised. If a numeric value is given,\n",
      "     |      FitFailedWarning is raised. This parameter does not affect the refit\n",
      "     |      step, which will always raise the error.\n",
      "     |  \n",
      "     |  return_train_score : bool, default=False\n",
      "     |      If ``False``, the ``cv_results_`` attribute will not include training\n",
      "     |      scores.\n",
      "     |      Computing training scores is used to get insights on how different\n",
      "     |      parameter settings impact the overfitting/underfitting trade-off.\n",
      "     |      However computing the scores on the training set can be computationally\n",
      "     |      expensive and is not strictly required to select the parameters that\n",
      "     |      yield the best generalization performance.\n",
      "     |  \n",
      "     |      .. versionadded:: 0.19\n",
      "     |  \n",
      "     |      .. versionchanged:: 0.21\n",
      "     |          Default value was changed from ``True`` to ``False``\n",
      "     |  \n",
      "     |  Attributes\n",
      "     |  ----------\n",
      "     |  cv_results_ : dict of numpy (masked) ndarrays\n",
      "     |      A dict with keys as column headers and values as columns, that can be\n",
      "     |      imported into a pandas ``DataFrame``.\n",
      "     |  \n",
      "     |      For instance the below given table\n",
      "     |  \n",
      "     |      +--------------+-------------+-------------------+---+---------------+\n",
      "     |      | param_kernel | param_gamma | split0_test_score |...|rank_test_score|\n",
      "     |      +==============+=============+===================+===+===============+\n",
      "     |      |    'rbf'     |     0.1     |       0.80        |...|       2       |\n",
      "     |      +--------------+-------------+-------------------+---+---------------+\n",
      "     |      |    'rbf'     |     0.2     |       0.90        |...|       1       |\n",
      "     |      +--------------+-------------+-------------------+---+---------------+\n",
      "     |      |    'rbf'     |     0.3     |       0.70        |...|       1       |\n",
      "     |      +--------------+-------------+-------------------+---+---------------+\n",
      "     |  \n",
      "     |      will be represented by a ``cv_results_`` dict of::\n",
      "     |  \n",
      "     |          {\n",
      "     |          'param_kernel' : masked_array(data = ['rbf', 'rbf', 'rbf'],\n",
      "     |                                        mask = False),\n",
      "     |          'param_gamma'  : masked_array(data = [0.1 0.2 0.3], mask = False),\n",
      "     |          'split0_test_score'  : [0.80, 0.90, 0.70],\n",
      "     |          'split1_test_score'  : [0.82, 0.50, 0.70],\n",
      "     |          'mean_test_score'    : [0.81, 0.70, 0.70],\n",
      "     |          'std_test_score'     : [0.01, 0.20, 0.00],\n",
      "     |          'rank_test_score'    : [3, 1, 1],\n",
      "     |          'split0_train_score' : [0.80, 0.92, 0.70],\n",
      "     |          'split1_train_score' : [0.82, 0.55, 0.70],\n",
      "     |          'mean_train_score'   : [0.81, 0.74, 0.70],\n",
      "     |          'std_train_score'    : [0.01, 0.19, 0.00],\n",
      "     |          'mean_fit_time'      : [0.73, 0.63, 0.43],\n",
      "     |          'std_fit_time'       : [0.01, 0.02, 0.01],\n",
      "     |          'mean_score_time'    : [0.01, 0.06, 0.04],\n",
      "     |          'std_score_time'     : [0.00, 0.00, 0.00],\n",
      "     |          'params'             : [{'kernel' : 'rbf', 'gamma' : 0.1}, ...],\n",
      "     |          }\n",
      "     |  \n",
      "     |      NOTE\n",
      "     |  \n",
      "     |      The key ``'params'`` is used to store a list of parameter\n",
      "     |      settings dicts for all the parameter candidates.\n",
      "     |  \n",
      "     |      The ``mean_fit_time``, ``std_fit_time``, ``mean_score_time`` and\n",
      "     |      ``std_score_time`` are all in seconds.\n",
      "     |  \n",
      "     |      For multi-metric evaluation, the scores for all the scorers are\n",
      "     |      available in the ``cv_results_`` dict at the keys ending with that\n",
      "     |      scorer's name (``'_<scorer_name>'``) instead of ``'_score'`` shown\n",
      "     |      above. ('split0_test_precision', 'mean_train_precision' etc.)\n",
      "     |  \n",
      "     |  best_estimator_ : estimator\n",
      "     |      Estimator that was chosen by the search, i.e. estimator\n",
      "     |      which gave highest score (or smallest loss if specified)\n",
      "     |      on the left out data. Not available if ``refit=False``.\n",
      "     |  \n",
      "     |      For multi-metric evaluation, this attribute is present only if\n",
      "     |      ``refit`` is specified.\n",
      "     |  \n",
      "     |      See ``refit`` parameter for more information on allowed values.\n",
      "     |  \n",
      "     |  best_score_ : float\n",
      "     |      Mean cross-validated score of the best_estimator.\n",
      "     |  \n",
      "     |      For multi-metric evaluation, this is not available if ``refit`` is\n",
      "     |      ``False``. See ``refit`` parameter for more information.\n",
      "     |  \n",
      "     |      This attribute is not available if ``refit`` is a function.\n",
      "     |  \n",
      "     |  best_params_ : dict\n",
      "     |      Parameter setting that gave the best results on the hold out data.\n",
      "     |  \n",
      "     |      For multi-metric evaluation, this is not available if ``refit`` is\n",
      "     |      ``False``. See ``refit`` parameter for more information.\n",
      "     |  \n",
      "     |  best_index_ : int\n",
      "     |      The index (of the ``cv_results_`` arrays) which corresponds to the best\n",
      "     |      candidate parameter setting.\n",
      "     |  \n",
      "     |      The dict at ``search.cv_results_['params'][search.best_index_]`` gives\n",
      "     |      the parameter setting for the best model, that gives the highest\n",
      "     |      mean score (``search.best_score_``).\n",
      "     |  \n",
      "     |      For multi-metric evaluation, this is not available if ``refit`` is\n",
      "     |      ``False``. See ``refit`` parameter for more information.\n",
      "     |  \n",
      "     |  scorer_ : function or a dict\n",
      "     |      Scorer function used on the held out data to choose the best\n",
      "     |      parameters for the model.\n",
      "     |  \n",
      "     |      For multi-metric evaluation, this attribute holds the validated\n",
      "     |      ``scoring`` dict which maps the scorer key to the scorer callable.\n",
      "     |  \n",
      "     |  n_splits_ : int\n",
      "     |      The number of cross-validation splits (folds/iterations).\n",
      "     |  \n",
      "     |  refit_time_ : float\n",
      "     |      Seconds used for refitting the best model on the whole dataset.\n",
      "     |  \n",
      "     |      This is present only if ``refit`` is not False.\n",
      "     |  \n",
      "     |      .. versionadded:: 0.20\n",
      "     |  \n",
      "     |  Notes\n",
      "     |  -----\n",
      "     |  The parameters selected are those that maximize the score of the held-out\n",
      "     |  data, according to the scoring parameter.\n",
      "     |  \n",
      "     |  If `n_jobs` was set to a value higher than one, the data is copied for each\n",
      "     |  parameter setting(and not `n_jobs` times). This is done for efficiency\n",
      "     |  reasons if individual jobs take very little time, but may raise errors if\n",
      "     |  the dataset is large and not enough memory is available.  A workaround in\n",
      "     |  this case is to set `pre_dispatch`. Then, the memory is copied only\n",
      "     |  `pre_dispatch` many times. A reasonable value for `pre_dispatch` is `2 *\n",
      "     |  n_jobs`.\n",
      "     |  \n",
      "     |  See Also\n",
      "     |  --------\n",
      "     |  :class:`GridSearchCV`:\n",
      "     |      Does exhaustive search over a grid of parameters.\n",
      "     |  \n",
      "     |  :class:`ParameterSampler`:\n",
      "     |      A generator over parameter settings, constructed from\n",
      "     |      param_distributions.\n",
      "     |  \n",
      "     |  \n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  >>> from sklearn.datasets import load_iris\n",
      "     |  >>> from sklearn.linear_model import LogisticRegression\n",
      "     |  >>> from sklearn.model_selection import RandomizedSearchCV\n",
      "     |  >>> from scipy.stats import uniform\n",
      "     |  >>> iris = load_iris()\n",
      "     |  >>> logistic = LogisticRegression(solver='saga', tol=1e-2, max_iter=200,\n",
      "     |  ...                               random_state=0)\n",
      "     |  >>> distributions = dict(C=uniform(loc=0, scale=4),\n",
      "     |  ...                      penalty=['l2', 'l1'])\n",
      "     |  >>> clf = RandomizedSearchCV(logistic, distributions, random_state=0)\n",
      "     |  >>> search = clf.fit(iris.data, iris.target)\n",
      "     |  >>> search.best_params_\n",
      "     |  {'C': 2..., 'penalty': 'l1'}\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      RandomizedSearchCV\n",
      "     |      BaseSearchCV\n",
      "     |      sklearn.base.MetaEstimatorMixin\n",
      "     |      sklearn.base.BaseEstimator\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, estimator, param_distributions, *, n_iter=10, scoring=None, n_jobs=None, iid='deprecated', refit=True, cv=None, verbose=0, pre_dispatch='2*n_jobs', random_state=None, error_score=nan, return_train_score=False)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from BaseSearchCV:\n",
      "     |  \n",
      "     |  decision_function(self, X)\n",
      "     |      Call decision_function on the estimator with the best found parameters.\n",
      "     |      \n",
      "     |      Only available if ``refit=True`` and the underlying estimator supports\n",
      "     |      ``decision_function``.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : indexable, length n_samples\n",
      "     |          Must fulfill the input assumptions of the\n",
      "     |          underlying estimator.\n",
      "     |  \n",
      "     |  fit(self, X, y=None, *, groups=None, **fit_params)\n",
      "     |      Run fit with all sets of parameters.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      \n",
      "     |      X : array-like of shape (n_samples, n_features)\n",
      "     |          Training vector, where n_samples is the number of samples and\n",
      "     |          n_features is the number of features.\n",
      "     |      \n",
      "     |      y : array-like of shape (n_samples, n_output)             or (n_samples,), default=None\n",
      "     |          Target relative to X for classification or regression;\n",
      "     |          None for unsupervised learning.\n",
      "     |      \n",
      "     |      groups : array-like of shape (n_samples,), default=None\n",
      "     |          Group labels for the samples used while splitting the dataset into\n",
      "     |          train/test set. Only used in conjunction with a \"Group\" :term:`cv`\n",
      "     |          instance (e.g., :class:`~sklearn.model_selection.GroupKFold`).\n",
      "     |      \n",
      "     |      **fit_params : dict of str -> object\n",
      "     |          Parameters passed to the ``fit`` method of the estimator\n",
      "     |  \n",
      "     |  inverse_transform(self, Xt)\n",
      "     |      Call inverse_transform on the estimator with the best found params.\n",
      "     |      \n",
      "     |      Only available if the underlying estimator implements\n",
      "     |      ``inverse_transform`` and ``refit=True``.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      Xt : indexable, length n_samples\n",
      "     |          Must fulfill the input assumptions of the\n",
      "     |          underlying estimator.\n",
      "     |  \n",
      "     |  predict(self, X)\n",
      "     |      Call predict on the estimator with the best found parameters.\n",
      "     |      \n",
      "     |      Only available if ``refit=True`` and the underlying estimator supports\n",
      "     |      ``predict``.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : indexable, length n_samples\n",
      "     |          Must fulfill the input assumptions of the\n",
      "     |          underlying estimator.\n",
      "     |  \n",
      "     |  predict_log_proba(self, X)\n",
      "     |      Call predict_log_proba on the estimator with the best found parameters.\n",
      "     |      \n",
      "     |      Only available if ``refit=True`` and the underlying estimator supports\n",
      "     |      ``predict_log_proba``.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : indexable, length n_samples\n",
      "     |          Must fulfill the input assumptions of the\n",
      "     |          underlying estimator.\n",
      "     |  \n",
      "     |  predict_proba(self, X)\n",
      "     |      Call predict_proba on the estimator with the best found parameters.\n",
      "     |      \n",
      "     |      Only available if ``refit=True`` and the underlying estimator supports\n",
      "     |      ``predict_proba``.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : indexable, length n_samples\n",
      "     |          Must fulfill the input assumptions of the\n",
      "     |          underlying estimator.\n",
      "     |  \n",
      "     |  score(self, X, y=None)\n",
      "     |      Returns the score on the given data, if the estimator has been refit.\n",
      "     |      \n",
      "     |      This uses the score defined by ``scoring`` where provided, and the\n",
      "     |      ``best_estimator_.score`` method otherwise.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like of shape (n_samples, n_features)\n",
      "     |          Input data, where n_samples is the number of samples and\n",
      "     |          n_features is the number of features.\n",
      "     |      \n",
      "     |      y : array-like of shape (n_samples, n_output)             or (n_samples,), default=None\n",
      "     |          Target relative to X for classification or regression;\n",
      "     |          None for unsupervised learning.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      score : float\n",
      "     |  \n",
      "     |  transform(self, X)\n",
      "     |      Call transform on the estimator with the best found parameters.\n",
      "     |      \n",
      "     |      Only available if the underlying estimator supports ``transform`` and\n",
      "     |      ``refit=True``.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : indexable, length n_samples\n",
      "     |          Must fulfill the input assumptions of the\n",
      "     |          underlying estimator.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from BaseSearchCV:\n",
      "     |  \n",
      "     |  classes_\n",
      "     |  \n",
      "     |  n_features_in_\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from sklearn.base.MetaEstimatorMixin:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.BaseEstimator:\n",
      "     |  \n",
      "     |  __getstate__(self)\n",
      "     |  \n",
      "     |  __repr__(self, N_CHAR_MAX=700)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |  \n",
      "     |  get_params(self, deep=True)\n",
      "     |      Get parameters for this estimator.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      deep : bool, default=True\n",
      "     |          If True, will return the parameters for this estimator and\n",
      "     |          contained subobjects that are estimators.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      params : mapping of string to any\n",
      "     |          Parameter names mapped to their values.\n",
      "     |  \n",
      "     |  set_params(self, **params)\n",
      "     |      Set the parameters of this estimator.\n",
      "     |      \n",
      "     |      The method works on simple estimators as well as on nested objects\n",
      "     |      (such as pipelines). The latter have parameters of the form\n",
      "     |      ``<component>__<parameter>`` so that it's possible to update each\n",
      "     |      component of a nested object.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      **params : dict\n",
      "     |          Estimator parameters.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          Estimator instance.\n",
      "    \n",
      "    class RepeatedKFold(_RepeatedSplits)\n",
      "     |  RepeatedKFold(*, n_splits=5, n_repeats=10, random_state=None)\n",
      "     |  \n",
      "     |  Repeated K-Fold cross validator.\n",
      "     |  \n",
      "     |  Repeats K-Fold n times with different randomization in each repetition.\n",
      "     |  \n",
      "     |  Read more in the :ref:`User Guide <cross_validation>`.\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  n_splits : int, default=5\n",
      "     |      Number of folds. Must be at least 2.\n",
      "     |  \n",
      "     |  n_repeats : int, default=10\n",
      "     |      Number of times cross-validator needs to be repeated.\n",
      "     |  \n",
      "     |  random_state : int or RandomState instance, default=None\n",
      "     |      Controls the randomness of each repeated cross-validation instance.\n",
      "     |      Pass an int for reproducible output across multiple function calls.\n",
      "     |      See :term:`Glossary <random_state>`.\n",
      "     |  \n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  >>> import numpy as np\n",
      "     |  >>> from sklearn.model_selection import RepeatedKFold\n",
      "     |  >>> X = np.array([[1, 2], [3, 4], [1, 2], [3, 4]])\n",
      "     |  >>> y = np.array([0, 0, 1, 1])\n",
      "     |  >>> rkf = RepeatedKFold(n_splits=2, n_repeats=2, random_state=2652124)\n",
      "     |  >>> for train_index, test_index in rkf.split(X):\n",
      "     |  ...     print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
      "     |  ...     X_train, X_test = X[train_index], X[test_index]\n",
      "     |  ...     y_train, y_test = y[train_index], y[test_index]\n",
      "     |  ...\n",
      "     |  TRAIN: [0 1] TEST: [2 3]\n",
      "     |  TRAIN: [2 3] TEST: [0 1]\n",
      "     |  TRAIN: [1 2] TEST: [0 3]\n",
      "     |  TRAIN: [0 3] TEST: [1 2]\n",
      "     |  \n",
      "     |  Notes\n",
      "     |  -----\n",
      "     |  Randomized CV splitters may return different results for each call of\n",
      "     |  split. You can make the results identical by setting `random_state`\n",
      "     |  to an integer.\n",
      "     |  \n",
      "     |  See also\n",
      "     |  --------\n",
      "     |  RepeatedStratifiedKFold: Repeats Stratified K-Fold n times.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      RepeatedKFold\n",
      "     |      _RepeatedSplits\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, *, n_splits=5, n_repeats=10, random_state=None)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from _RepeatedSplits:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  get_n_splits(self, X=None, y=None, groups=None)\n",
      "     |      Returns the number of splitting iterations in the cross-validator\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : object\n",
      "     |          Always ignored, exists for compatibility.\n",
      "     |          ``np.zeros(n_samples)`` may be used as a placeholder.\n",
      "     |      \n",
      "     |      y : object\n",
      "     |          Always ignored, exists for compatibility.\n",
      "     |          ``np.zeros(n_samples)`` may be used as a placeholder.\n",
      "     |      \n",
      "     |      groups : array-like of shape (n_samples,), default=None\n",
      "     |          Group labels for the samples used while splitting the dataset into\n",
      "     |          train/test set.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      n_splits : int\n",
      "     |          Returns the number of splitting iterations in the cross-validator.\n",
      "     |  \n",
      "     |  split(self, X, y=None, groups=None)\n",
      "     |      Generates indices to split data into training and test set.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like, shape (n_samples, n_features)\n",
      "     |          Training data, where n_samples is the number of samples\n",
      "     |          and n_features is the number of features.\n",
      "     |      \n",
      "     |      y : array-like of length n_samples\n",
      "     |          The target variable for supervised learning problems.\n",
      "     |      \n",
      "     |      groups : array-like of shape (n_samples,), default=None\n",
      "     |          Group labels for the samples used while splitting the dataset into\n",
      "     |          train/test set.\n",
      "     |      \n",
      "     |      Yields\n",
      "     |      ------\n",
      "     |      train : ndarray\n",
      "     |          The training set indices for that split.\n",
      "     |      \n",
      "     |      test : ndarray\n",
      "     |          The testing set indices for that split.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from _RepeatedSplits:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class RepeatedStratifiedKFold(_RepeatedSplits)\n",
      "     |  RepeatedStratifiedKFold(*, n_splits=5, n_repeats=10, random_state=None)\n",
      "     |  \n",
      "     |  Repeated Stratified K-Fold cross validator.\n",
      "     |  \n",
      "     |  Repeats Stratified K-Fold n times with different randomization in each\n",
      "     |  repetition.\n",
      "     |  \n",
      "     |  Read more in the :ref:`User Guide <cross_validation>`.\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  n_splits : int, default=5\n",
      "     |      Number of folds. Must be at least 2.\n",
      "     |  \n",
      "     |  n_repeats : int, default=10\n",
      "     |      Number of times cross-validator needs to be repeated.\n",
      "     |  \n",
      "     |  random_state : int or RandomState instance, default=None\n",
      "     |      Controls the generation of the random states for each repetition.\n",
      "     |      Pass an int for reproducible output across multiple function calls.\n",
      "     |      See :term:`Glossary <random_state>`.\n",
      "     |  \n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  >>> import numpy as np\n",
      "     |  >>> from sklearn.model_selection import RepeatedStratifiedKFold\n",
      "     |  >>> X = np.array([[1, 2], [3, 4], [1, 2], [3, 4]])\n",
      "     |  >>> y = np.array([0, 0, 1, 1])\n",
      "     |  >>> rskf = RepeatedStratifiedKFold(n_splits=2, n_repeats=2,\n",
      "     |  ...     random_state=36851234)\n",
      "     |  >>> for train_index, test_index in rskf.split(X, y):\n",
      "     |  ...     print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
      "     |  ...     X_train, X_test = X[train_index], X[test_index]\n",
      "     |  ...     y_train, y_test = y[train_index], y[test_index]\n",
      "     |  ...\n",
      "     |  TRAIN: [1 2] TEST: [0 3]\n",
      "     |  TRAIN: [0 3] TEST: [1 2]\n",
      "     |  TRAIN: [1 3] TEST: [0 2]\n",
      "     |  TRAIN: [0 2] TEST: [1 3]\n",
      "     |  \n",
      "     |  Notes\n",
      "     |  -----\n",
      "     |  Randomized CV splitters may return different results for each call of\n",
      "     |  split. You can make the results identical by setting `random_state`\n",
      "     |  to an integer.\n",
      "     |  \n",
      "     |  See also\n",
      "     |  --------\n",
      "     |  RepeatedKFold: Repeats K-Fold n times.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      RepeatedStratifiedKFold\n",
      "     |      _RepeatedSplits\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, *, n_splits=5, n_repeats=10, random_state=None)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from _RepeatedSplits:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  get_n_splits(self, X=None, y=None, groups=None)\n",
      "     |      Returns the number of splitting iterations in the cross-validator\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : object\n",
      "     |          Always ignored, exists for compatibility.\n",
      "     |          ``np.zeros(n_samples)`` may be used as a placeholder.\n",
      "     |      \n",
      "     |      y : object\n",
      "     |          Always ignored, exists for compatibility.\n",
      "     |          ``np.zeros(n_samples)`` may be used as a placeholder.\n",
      "     |      \n",
      "     |      groups : array-like of shape (n_samples,), default=None\n",
      "     |          Group labels for the samples used while splitting the dataset into\n",
      "     |          train/test set.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      n_splits : int\n",
      "     |          Returns the number of splitting iterations in the cross-validator.\n",
      "     |  \n",
      "     |  split(self, X, y=None, groups=None)\n",
      "     |      Generates indices to split data into training and test set.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like, shape (n_samples, n_features)\n",
      "     |          Training data, where n_samples is the number of samples\n",
      "     |          and n_features is the number of features.\n",
      "     |      \n",
      "     |      y : array-like of length n_samples\n",
      "     |          The target variable for supervised learning problems.\n",
      "     |      \n",
      "     |      groups : array-like of shape (n_samples,), default=None\n",
      "     |          Group labels for the samples used while splitting the dataset into\n",
      "     |          train/test set.\n",
      "     |      \n",
      "     |      Yields\n",
      "     |      ------\n",
      "     |      train : ndarray\n",
      "     |          The training set indices for that split.\n",
      "     |      \n",
      "     |      test : ndarray\n",
      "     |          The testing set indices for that split.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from _RepeatedSplits:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class ShuffleSplit(BaseShuffleSplit)\n",
      "     |  ShuffleSplit(n_splits=10, *, test_size=None, train_size=None, random_state=None)\n",
      "     |  \n",
      "     |  Random permutation cross-validator\n",
      "     |  \n",
      "     |  Yields indices to split data into training and test sets.\n",
      "     |  \n",
      "     |  Note: contrary to other cross-validation strategies, random splits\n",
      "     |  do not guarantee that all folds will be different, although this is\n",
      "     |  still very likely for sizeable datasets.\n",
      "     |  \n",
      "     |  Read more in the :ref:`User Guide <cross_validation>`.\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  n_splits : int, default=10\n",
      "     |      Number of re-shuffling & splitting iterations.\n",
      "     |  \n",
      "     |  test_size : float or int, default=None\n",
      "     |      If float, should be between 0.0 and 1.0 and represent the proportion\n",
      "     |      of the dataset to include in the test split. If int, represents the\n",
      "     |      absolute number of test samples. If None, the value is set to the\n",
      "     |      complement of the train size. If ``train_size`` is also None, it will\n",
      "     |      be set to 0.1.\n",
      "     |  \n",
      "     |  train_size : float or int, default=None\n",
      "     |      If float, should be between 0.0 and 1.0 and represent the\n",
      "     |      proportion of the dataset to include in the train split. If\n",
      "     |      int, represents the absolute number of train samples. If None,\n",
      "     |      the value is automatically set to the complement of the test size.\n",
      "     |  \n",
      "     |  random_state : int or RandomState instance, default=None\n",
      "     |      Controls the randomness of the training and testing indices produced.\n",
      "     |      Pass an int for reproducible output across multiple function calls.\n",
      "     |      See :term:`Glossary <random_state>`.\n",
      "     |  \n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  >>> import numpy as np\n",
      "     |  >>> from sklearn.model_selection import ShuffleSplit\n",
      "     |  >>> X = np.array([[1, 2], [3, 4], [5, 6], [7, 8], [3, 4], [5, 6]])\n",
      "     |  >>> y = np.array([1, 2, 1, 2, 1, 2])\n",
      "     |  >>> rs = ShuffleSplit(n_splits=5, test_size=.25, random_state=0)\n",
      "     |  >>> rs.get_n_splits(X)\n",
      "     |  5\n",
      "     |  >>> print(rs)\n",
      "     |  ShuffleSplit(n_splits=5, random_state=0, test_size=0.25, train_size=None)\n",
      "     |  >>> for train_index, test_index in rs.split(X):\n",
      "     |  ...     print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
      "     |  TRAIN: [1 3 0 4] TEST: [5 2]\n",
      "     |  TRAIN: [4 0 2 5] TEST: [1 3]\n",
      "     |  TRAIN: [1 2 4 0] TEST: [3 5]\n",
      "     |  TRAIN: [3 4 1 0] TEST: [5 2]\n",
      "     |  TRAIN: [3 5 1 0] TEST: [2 4]\n",
      "     |  >>> rs = ShuffleSplit(n_splits=5, train_size=0.5, test_size=.25,\n",
      "     |  ...                   random_state=0)\n",
      "     |  >>> for train_index, test_index in rs.split(X):\n",
      "     |  ...     print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
      "     |  TRAIN: [1 3 0] TEST: [5 2]\n",
      "     |  TRAIN: [4 0 2] TEST: [1 3]\n",
      "     |  TRAIN: [1 2 4] TEST: [3 5]\n",
      "     |  TRAIN: [3 4 1] TEST: [5 2]\n",
      "     |  TRAIN: [3 5 1] TEST: [2 4]\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      ShuffleSplit\n",
      "     |      BaseShuffleSplit\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, n_splits=10, *, test_size=None, train_size=None, random_state=None)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from BaseShuffleSplit:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  get_n_splits(self, X=None, y=None, groups=None)\n",
      "     |      Returns the number of splitting iterations in the cross-validator\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : object\n",
      "     |          Always ignored, exists for compatibility.\n",
      "     |      \n",
      "     |      y : object\n",
      "     |          Always ignored, exists for compatibility.\n",
      "     |      \n",
      "     |      groups : object\n",
      "     |          Always ignored, exists for compatibility.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      n_splits : int\n",
      "     |          Returns the number of splitting iterations in the cross-validator.\n",
      "     |  \n",
      "     |  split(self, X, y=None, groups=None)\n",
      "     |      Generate indices to split data into training and test set.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like of shape (n_samples, n_features)\n",
      "     |          Training data, where n_samples is the number of samples\n",
      "     |          and n_features is the number of features.\n",
      "     |      \n",
      "     |      y : array-like of shape (n_samples,)\n",
      "     |          The target variable for supervised learning problems.\n",
      "     |      \n",
      "     |      groups : array-like of shape (n_samples,), default=None\n",
      "     |          Group labels for the samples used while splitting the dataset into\n",
      "     |          train/test set.\n",
      "     |      \n",
      "     |      Yields\n",
      "     |      ------\n",
      "     |      train : ndarray\n",
      "     |          The training set indices for that split.\n",
      "     |      \n",
      "     |      test : ndarray\n",
      "     |          The testing set indices for that split.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Randomized CV splitters may return different results for each call of\n",
      "     |      split. You can make the results identical by setting `random_state`\n",
      "     |      to an integer.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from BaseShuffleSplit:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class StratifiedKFold(_BaseKFold)\n",
      "     |  StratifiedKFold(n_splits=5, *, shuffle=False, random_state=None)\n",
      "     |  \n",
      "     |  Stratified K-Folds cross-validator\n",
      "     |  \n",
      "     |  Provides train/test indices to split data in train/test sets.\n",
      "     |  \n",
      "     |  This cross-validation object is a variation of KFold that returns\n",
      "     |  stratified folds. The folds are made by preserving the percentage of\n",
      "     |  samples for each class.\n",
      "     |  \n",
      "     |  Read more in the :ref:`User Guide <cross_validation>`.\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  n_splits : int, default=5\n",
      "     |      Number of folds. Must be at least 2.\n",
      "     |  \n",
      "     |      .. versionchanged:: 0.22\n",
      "     |          ``n_splits`` default value changed from 3 to 5.\n",
      "     |  \n",
      "     |  shuffle : bool, default=False\n",
      "     |      Whether to shuffle each class's samples before splitting into batches.\n",
      "     |      Note that the samples within each split will not be shuffled.\n",
      "     |  \n",
      "     |  random_state : int or RandomState instance, default=None\n",
      "     |      When `shuffle` is True, `random_state` affects the ordering of the\n",
      "     |      indices, which controls the randomness of each fold for each class.\n",
      "     |      Otherwise, leave `random_state` as `None`.\n",
      "     |      Pass an int for reproducible output across multiple function calls.\n",
      "     |      See :term:`Glossary <random_state>`.\n",
      "     |  \n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  >>> import numpy as np\n",
      "     |  >>> from sklearn.model_selection import StratifiedKFold\n",
      "     |  >>> X = np.array([[1, 2], [3, 4], [1, 2], [3, 4]])\n",
      "     |  >>> y = np.array([0, 0, 1, 1])\n",
      "     |  >>> skf = StratifiedKFold(n_splits=2)\n",
      "     |  >>> skf.get_n_splits(X, y)\n",
      "     |  2\n",
      "     |  >>> print(skf)\n",
      "     |  StratifiedKFold(n_splits=2, random_state=None, shuffle=False)\n",
      "     |  >>> for train_index, test_index in skf.split(X, y):\n",
      "     |  ...     print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
      "     |  ...     X_train, X_test = X[train_index], X[test_index]\n",
      "     |  ...     y_train, y_test = y[train_index], y[test_index]\n",
      "     |  TRAIN: [1 3] TEST: [0 2]\n",
      "     |  TRAIN: [0 2] TEST: [1 3]\n",
      "     |  \n",
      "     |  Notes\n",
      "     |  -----\n",
      "     |  The implementation is designed to:\n",
      "     |  \n",
      "     |  * Generate test sets such that all contain the same distribution of\n",
      "     |    classes, or as close as possible.\n",
      "     |  * Be invariant to class label: relabelling ``y = [\"Happy\", \"Sad\"]`` to\n",
      "     |    ``y = [1, 0]`` should not change the indices generated.\n",
      "     |  * Preserve order dependencies in the dataset ordering, when\n",
      "     |    ``shuffle=False``: all samples from class k in some test set were\n",
      "     |    contiguous in y, or separated in y by samples from classes other than k.\n",
      "     |  * Generate test sets where the smallest and largest differ by at most one\n",
      "     |    sample.\n",
      "     |  \n",
      "     |  .. versionchanged:: 0.22\n",
      "     |      The previous implementation did not follow the last constraint.\n",
      "     |  \n",
      "     |  See also\n",
      "     |  --------\n",
      "     |  RepeatedStratifiedKFold: Repeats Stratified K-Fold n times.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      StratifiedKFold\n",
      "     |      _BaseKFold\n",
      "     |      BaseCrossValidator\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, n_splits=5, *, shuffle=False, random_state=None)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  split(self, X, y, groups=None)\n",
      "     |      Generate indices to split data into training and test set.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like of shape (n_samples, n_features)\n",
      "     |          Training data, where n_samples is the number of samples\n",
      "     |          and n_features is the number of features.\n",
      "     |      \n",
      "     |          Note that providing ``y`` is sufficient to generate the splits and\n",
      "     |          hence ``np.zeros(n_samples)`` may be used as a placeholder for\n",
      "     |          ``X`` instead of actual training data.\n",
      "     |      \n",
      "     |      y : array-like of shape (n_samples,)\n",
      "     |          The target variable for supervised learning problems.\n",
      "     |          Stratification is done based on the y labels.\n",
      "     |      \n",
      "     |      groups : object\n",
      "     |          Always ignored, exists for compatibility.\n",
      "     |      \n",
      "     |      Yields\n",
      "     |      ------\n",
      "     |      train : ndarray\n",
      "     |          The training set indices for that split.\n",
      "     |      \n",
      "     |      test : ndarray\n",
      "     |          The testing set indices for that split.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Randomized CV splitters may return different results for each call of\n",
      "     |      split. You can make the results identical by setting `random_state`\n",
      "     |      to an integer.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from _BaseKFold:\n",
      "     |  \n",
      "     |  get_n_splits(self, X=None, y=None, groups=None)\n",
      "     |      Returns the number of splitting iterations in the cross-validator\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : object\n",
      "     |          Always ignored, exists for compatibility.\n",
      "     |      \n",
      "     |      y : object\n",
      "     |          Always ignored, exists for compatibility.\n",
      "     |      \n",
      "     |      groups : object\n",
      "     |          Always ignored, exists for compatibility.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      n_splits : int\n",
      "     |          Returns the number of splitting iterations in the cross-validator.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from BaseCrossValidator:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from BaseCrossValidator:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class StratifiedShuffleSplit(BaseShuffleSplit)\n",
      "     |  StratifiedShuffleSplit(n_splits=10, *, test_size=None, train_size=None, random_state=None)\n",
      "     |  \n",
      "     |  Stratified ShuffleSplit cross-validator\n",
      "     |  \n",
      "     |  Provides train/test indices to split data in train/test sets.\n",
      "     |  \n",
      "     |  This cross-validation object is a merge of StratifiedKFold and\n",
      "     |  ShuffleSplit, which returns stratified randomized folds. The folds\n",
      "     |  are made by preserving the percentage of samples for each class.\n",
      "     |  \n",
      "     |  Note: like the ShuffleSplit strategy, stratified random splits\n",
      "     |  do not guarantee that all folds will be different, although this is\n",
      "     |  still very likely for sizeable datasets.\n",
      "     |  \n",
      "     |  Read more in the :ref:`User Guide <cross_validation>`.\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  n_splits : int, default=10\n",
      "     |      Number of re-shuffling & splitting iterations.\n",
      "     |  \n",
      "     |  test_size : float or int, default=None\n",
      "     |      If float, should be between 0.0 and 1.0 and represent the proportion\n",
      "     |      of the dataset to include in the test split. If int, represents the\n",
      "     |      absolute number of test samples. If None, the value is set to the\n",
      "     |      complement of the train size. If ``train_size`` is also None, it will\n",
      "     |      be set to 0.1.\n",
      "     |  \n",
      "     |  train_size : float or int, default=None\n",
      "     |      If float, should be between 0.0 and 1.0 and represent the\n",
      "     |      proportion of the dataset to include in the train split. If\n",
      "     |      int, represents the absolute number of train samples. If None,\n",
      "     |      the value is automatically set to the complement of the test size.\n",
      "     |  \n",
      "     |  random_state : int or RandomState instance, default=None\n",
      "     |      Controls the randomness of the training and testing indices produced.\n",
      "     |      Pass an int for reproducible output across multiple function calls.\n",
      "     |      See :term:`Glossary <random_state>`.\n",
      "     |  \n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  >>> import numpy as np\n",
      "     |  >>> from sklearn.model_selection import StratifiedShuffleSplit\n",
      "     |  >>> X = np.array([[1, 2], [3, 4], [1, 2], [3, 4], [1, 2], [3, 4]])\n",
      "     |  >>> y = np.array([0, 0, 0, 1, 1, 1])\n",
      "     |  >>> sss = StratifiedShuffleSplit(n_splits=5, test_size=0.5, random_state=0)\n",
      "     |  >>> sss.get_n_splits(X, y)\n",
      "     |  5\n",
      "     |  >>> print(sss)\n",
      "     |  StratifiedShuffleSplit(n_splits=5, random_state=0, ...)\n",
      "     |  >>> for train_index, test_index in sss.split(X, y):\n",
      "     |  ...     print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
      "     |  ...     X_train, X_test = X[train_index], X[test_index]\n",
      "     |  ...     y_train, y_test = y[train_index], y[test_index]\n",
      "     |  TRAIN: [5 2 3] TEST: [4 1 0]\n",
      "     |  TRAIN: [5 1 4] TEST: [0 2 3]\n",
      "     |  TRAIN: [5 0 2] TEST: [4 3 1]\n",
      "     |  TRAIN: [4 1 0] TEST: [2 3 5]\n",
      "     |  TRAIN: [0 5 1] TEST: [3 4 2]\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      StratifiedShuffleSplit\n",
      "     |      BaseShuffleSplit\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, n_splits=10, *, test_size=None, train_size=None, random_state=None)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  split(self, X, y, groups=None)\n",
      "     |      Generate indices to split data into training and test set.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like of shape (n_samples, n_features)\n",
      "     |          Training data, where n_samples is the number of samples\n",
      "     |          and n_features is the number of features.\n",
      "     |      \n",
      "     |          Note that providing ``y`` is sufficient to generate the splits and\n",
      "     |          hence ``np.zeros(n_samples)`` may be used as a placeholder for\n",
      "     |          ``X`` instead of actual training data.\n",
      "     |      \n",
      "     |      y : array-like of shape (n_samples,) or (n_samples, n_labels)\n",
      "     |          The target variable for supervised learning problems.\n",
      "     |          Stratification is done based on the y labels.\n",
      "     |      \n",
      "     |      groups : object\n",
      "     |          Always ignored, exists for compatibility.\n",
      "     |      \n",
      "     |      Yields\n",
      "     |      ------\n",
      "     |      train : ndarray\n",
      "     |          The training set indices for that split.\n",
      "     |      \n",
      "     |      test : ndarray\n",
      "     |          The testing set indices for that split.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Randomized CV splitters may return different results for each call of\n",
      "     |      split. You can make the results identical by setting `random_state`\n",
      "     |      to an integer.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from BaseShuffleSplit:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  get_n_splits(self, X=None, y=None, groups=None)\n",
      "     |      Returns the number of splitting iterations in the cross-validator\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : object\n",
      "     |          Always ignored, exists for compatibility.\n",
      "     |      \n",
      "     |      y : object\n",
      "     |          Always ignored, exists for compatibility.\n",
      "     |      \n",
      "     |      groups : object\n",
      "     |          Always ignored, exists for compatibility.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      n_splits : int\n",
      "     |          Returns the number of splitting iterations in the cross-validator.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from BaseShuffleSplit:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class TimeSeriesSplit(_BaseKFold)\n",
      "     |  TimeSeriesSplit(n_splits=5, *, max_train_size=None)\n",
      "     |  \n",
      "     |  Time Series cross-validator\n",
      "     |  \n",
      "     |  .. versionadded:: 0.18\n",
      "     |  \n",
      "     |  Provides train/test indices to split time series data samples\n",
      "     |  that are observed at fixed time intervals, in train/test sets.\n",
      "     |  In each split, test indices must be higher than before, and thus shuffling\n",
      "     |  in cross validator is inappropriate.\n",
      "     |  \n",
      "     |  This cross-validation object is a variation of :class:`KFold`.\n",
      "     |  In the kth split, it returns first k folds as train set and the\n",
      "     |  (k+1)th fold as test set.\n",
      "     |  \n",
      "     |  Note that unlike standard cross-validation methods, successive\n",
      "     |  training sets are supersets of those that come before them.\n",
      "     |  \n",
      "     |  Read more in the :ref:`User Guide <cross_validation>`.\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  n_splits : int, default=5\n",
      "     |      Number of splits. Must be at least 2.\n",
      "     |  \n",
      "     |      .. versionchanged:: 0.22\n",
      "     |          ``n_splits`` default value changed from 3 to 5.\n",
      "     |  \n",
      "     |  max_train_size : int, default=None\n",
      "     |      Maximum size for a single training set.\n",
      "     |  \n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  >>> import numpy as np\n",
      "     |  >>> from sklearn.model_selection import TimeSeriesSplit\n",
      "     |  >>> X = np.array([[1, 2], [3, 4], [1, 2], [3, 4], [1, 2], [3, 4]])\n",
      "     |  >>> y = np.array([1, 2, 3, 4, 5, 6])\n",
      "     |  >>> tscv = TimeSeriesSplit()\n",
      "     |  >>> print(tscv)\n",
      "     |  TimeSeriesSplit(max_train_size=None, n_splits=5)\n",
      "     |  >>> for train_index, test_index in tscv.split(X):\n",
      "     |  ...     print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
      "     |  ...     X_train, X_test = X[train_index], X[test_index]\n",
      "     |  ...     y_train, y_test = y[train_index], y[test_index]\n",
      "     |  TRAIN: [0] TEST: [1]\n",
      "     |  TRAIN: [0 1] TEST: [2]\n",
      "     |  TRAIN: [0 1 2] TEST: [3]\n",
      "     |  TRAIN: [0 1 2 3] TEST: [4]\n",
      "     |  TRAIN: [0 1 2 3 4] TEST: [5]\n",
      "     |  \n",
      "     |  Notes\n",
      "     |  -----\n",
      "     |  The training set has size ``i * n_samples // (n_splits + 1)\n",
      "     |  + n_samples % (n_splits + 1)`` in the ``i``th split,\n",
      "     |  with a test set of size ``n_samples//(n_splits + 1)``,\n",
      "     |  where ``n_samples`` is the number of samples.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      TimeSeriesSplit\n",
      "     |      _BaseKFold\n",
      "     |      BaseCrossValidator\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, n_splits=5, *, max_train_size=None)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  split(self, X, y=None, groups=None)\n",
      "     |      Generate indices to split data into training and test set.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like of shape (n_samples, n_features)\n",
      "     |          Training data, where n_samples is the number of samples\n",
      "     |          and n_features is the number of features.\n",
      "     |      \n",
      "     |      y : array-like of shape (n_samples,)\n",
      "     |          Always ignored, exists for compatibility.\n",
      "     |      \n",
      "     |      groups : array-like of shape (n_samples,)\n",
      "     |          Always ignored, exists for compatibility.\n",
      "     |      \n",
      "     |      Yields\n",
      "     |      ------\n",
      "     |      train : ndarray\n",
      "     |          The training set indices for that split.\n",
      "     |      \n",
      "     |      test : ndarray\n",
      "     |          The testing set indices for that split.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from _BaseKFold:\n",
      "     |  \n",
      "     |  get_n_splits(self, X=None, y=None, groups=None)\n",
      "     |      Returns the number of splitting iterations in the cross-validator\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : object\n",
      "     |          Always ignored, exists for compatibility.\n",
      "     |      \n",
      "     |      y : object\n",
      "     |          Always ignored, exists for compatibility.\n",
      "     |      \n",
      "     |      groups : object\n",
      "     |          Always ignored, exists for compatibility.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      n_splits : int\n",
      "     |          Returns the number of splitting iterations in the cross-validator.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from BaseCrossValidator:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from BaseCrossValidator:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "\n",
      "FUNCTIONS\n",
      "    check_cv(cv=5, y=None, *, classifier=False)\n",
      "        Input checker utility for building a cross-validator\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        cv : int, cross-validation generator or an iterable, default=None\n",
      "            Determines the cross-validation splitting strategy.\n",
      "            Possible inputs for cv are:\n",
      "            - None, to use the default 5-fold cross validation,\n",
      "            - integer, to specify the number of folds.\n",
      "            - :term:`CV splitter`,\n",
      "            - An iterable yielding (train, test) splits as arrays of indices.\n",
      "        \n",
      "            For integer/None inputs, if classifier is True and ``y`` is either\n",
      "            binary or multiclass, :class:`StratifiedKFold` is used. In all other\n",
      "            cases, :class:`KFold` is used.\n",
      "        \n",
      "            Refer :ref:`User Guide <cross_validation>` for the various\n",
      "            cross-validation strategies that can be used here.\n",
      "        \n",
      "            .. versionchanged:: 0.22\n",
      "                ``cv`` default value changed from 3-fold to 5-fold.\n",
      "        \n",
      "        y : array-like, default=None\n",
      "            The target variable for supervised learning problems.\n",
      "        \n",
      "        classifier : bool, default=False\n",
      "            Whether the task is a classification task, in which case\n",
      "            stratified KFold will be used.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        checked_cv : a cross-validator instance.\n",
      "            The return value is a cross-validator which generates the train/test\n",
      "            splits via the ``split`` method.\n",
      "    \n",
      "    cross_val_predict(estimator, X, y=None, *, groups=None, cv=None, n_jobs=None, verbose=0, fit_params=None, pre_dispatch='2*n_jobs', method='predict')\n",
      "        Generate cross-validated estimates for each input data point\n",
      "        \n",
      "        The data is split according to the cv parameter. Each sample belongs\n",
      "        to exactly one test set, and its prediction is computed with an\n",
      "        estimator fitted on the corresponding training set.\n",
      "        \n",
      "        Passing these predictions into an evaluation metric may not be a valid\n",
      "        way to measure generalization performance. Results can differ from\n",
      "        :func:`cross_validate` and :func:`cross_val_score` unless all tests sets\n",
      "        have equal size and the metric decomposes over samples.\n",
      "        \n",
      "        Read more in the :ref:`User Guide <cross_validation>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        estimator : estimator object implementing 'fit' and 'predict'\n",
      "            The object to use to fit the data.\n",
      "        \n",
      "        X : array-like of shape (n_samples, n_features)\n",
      "            The data to fit. Can be, for example a list, or an array at least 2d.\n",
      "        \n",
      "        y : array-like of shape (n_samples,) or (n_samples, n_outputs),             default=None\n",
      "            The target variable to try to predict in the case of\n",
      "            supervised learning.\n",
      "        \n",
      "        groups : array-like of shape (n_samples,), default=None\n",
      "            Group labels for the samples used while splitting the dataset into\n",
      "            train/test set. Only used in conjunction with a \"Group\" :term:`cv`\n",
      "            instance (e.g., :class:`GroupKFold`).\n",
      "        \n",
      "        cv : int, cross-validation generator or an iterable, default=None\n",
      "            Determines the cross-validation splitting strategy.\n",
      "            Possible inputs for cv are:\n",
      "        \n",
      "            - None, to use the default 5-fold cross validation,\n",
      "            - int, to specify the number of folds in a `(Stratified)KFold`,\n",
      "            - :term:`CV splitter`,\n",
      "            - An iterable yielding (train, test) splits as arrays of indices.\n",
      "        \n",
      "            For int/None inputs, if the estimator is a classifier and ``y`` is\n",
      "            either binary or multiclass, :class:`StratifiedKFold` is used. In all\n",
      "            other cases, :class:`KFold` is used.\n",
      "        \n",
      "            Refer :ref:`User Guide <cross_validation>` for the various\n",
      "            cross-validation strategies that can be used here.\n",
      "        \n",
      "            .. versionchanged:: 0.22\n",
      "                ``cv`` default value if None changed from 3-fold to 5-fold.\n",
      "        \n",
      "        n_jobs : int, default=None\n",
      "            The number of CPUs to use to do the computation.\n",
      "            ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
      "            ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
      "            for more details.\n",
      "        \n",
      "        verbose : int, default=0\n",
      "            The verbosity level.\n",
      "        \n",
      "        fit_params : dict, defualt=None\n",
      "            Parameters to pass to the fit method of the estimator.\n",
      "        \n",
      "        pre_dispatch : int or str, default='2*n_jobs'\n",
      "            Controls the number of jobs that get dispatched during parallel\n",
      "            execution. Reducing this number can be useful to avoid an\n",
      "            explosion of memory consumption when more jobs get dispatched\n",
      "            than CPUs can process. This parameter can be:\n",
      "        \n",
      "                - None, in which case all the jobs are immediately\n",
      "                  created and spawned. Use this for lightweight and\n",
      "                  fast-running jobs, to avoid delays due to on-demand\n",
      "                  spawning of the jobs\n",
      "        \n",
      "                - An int, giving the exact number of total jobs that are\n",
      "                  spawned\n",
      "        \n",
      "                - A str, giving an expression as a function of n_jobs,\n",
      "                  as in '2*n_jobs'\n",
      "        \n",
      "        method : str, default='predict'\n",
      "            Invokes the passed method name of the passed estimator. For\n",
      "            method='predict_proba', the columns correspond to the classes\n",
      "            in sorted order.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        predictions : ndarray\n",
      "            This is the result of calling ``method``\n",
      "        \n",
      "        See also\n",
      "        --------\n",
      "        cross_val_score : calculate score for each CV split\n",
      "        \n",
      "        cross_validate : calculate one or more scores and timings for each CV split\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        In the case that one or more classes are absent in a training portion, a\n",
      "        default score needs to be assigned to all instances for that class if\n",
      "        ``method`` produces columns per class, as in {'decision_function',\n",
      "        'predict_proba', 'predict_log_proba'}.  For ``predict_proba`` this value is\n",
      "        0.  In order to ensure finite output, we approximate negative infinity by\n",
      "        the minimum finite float value for the dtype in other cases.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from sklearn import datasets, linear_model\n",
      "        >>> from sklearn.model_selection import cross_val_predict\n",
      "        >>> diabetes = datasets.load_diabetes()\n",
      "        >>> X = diabetes.data[:150]\n",
      "        >>> y = diabetes.target[:150]\n",
      "        >>> lasso = linear_model.Lasso()\n",
      "        >>> y_pred = cross_val_predict(lasso, X, y, cv=3)\n",
      "    \n",
      "    cross_val_score(estimator, X, y=None, *, groups=None, scoring=None, cv=None, n_jobs=None, verbose=0, fit_params=None, pre_dispatch='2*n_jobs', error_score=nan)\n",
      "        Evaluate a score by cross-validation\n",
      "        \n",
      "        Read more in the :ref:`User Guide <cross_validation>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        estimator : estimator object implementing 'fit'\n",
      "            The object to use to fit the data.\n",
      "        \n",
      "        X : array-like of shape (n_samples, n_features)\n",
      "            The data to fit. Can be for example a list, or an array.\n",
      "        \n",
      "        y : array-like of shape (n_samples,) or (n_samples, n_outputs),             default=None\n",
      "            The target variable to try to predict in the case of\n",
      "            supervised learning.\n",
      "        \n",
      "        groups : array-like of shape (n_samples,), default=None\n",
      "            Group labels for the samples used while splitting the dataset into\n",
      "            train/test set. Only used in conjunction with a \"Group\" :term:`cv`\n",
      "            instance (e.g., :class:`GroupKFold`).\n",
      "        \n",
      "        scoring : str or callable, default=None\n",
      "            A str (see model evaluation documentation) or\n",
      "            a scorer callable object / function with signature\n",
      "            ``scorer(estimator, X, y)`` which should return only\n",
      "            a single value.\n",
      "        \n",
      "            Similar to :func:`cross_validate`\n",
      "            but only a single metric is permitted.\n",
      "        \n",
      "            If None, the estimator's default scorer (if available) is used.\n",
      "        \n",
      "        cv : int, cross-validation generator or an iterable, default=None\n",
      "            Determines the cross-validation splitting strategy.\n",
      "            Possible inputs for cv are:\n",
      "        \n",
      "            - None, to use the default 5-fold cross validation,\n",
      "            - int, to specify the number of folds in a `(Stratified)KFold`,\n",
      "            - :term:`CV splitter`,\n",
      "            - An iterable yielding (train, test) splits as arrays of indices.\n",
      "        \n",
      "            For int/None inputs, if the estimator is a classifier and ``y`` is\n",
      "            either binary or multiclass, :class:`StratifiedKFold` is used. In all\n",
      "            other cases, :class:`KFold` is used.\n",
      "        \n",
      "            Refer :ref:`User Guide <cross_validation>` for the various\n",
      "            cross-validation strategies that can be used here.\n",
      "        \n",
      "            .. versionchanged:: 0.22\n",
      "                ``cv`` default value if None changed from 3-fold to 5-fold.\n",
      "        \n",
      "        n_jobs : int, default=None\n",
      "            The number of CPUs to use to do the computation.\n",
      "            ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
      "            ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
      "            for more details.\n",
      "        \n",
      "        verbose : int, default=0\n",
      "            The verbosity level.\n",
      "        \n",
      "        fit_params : dict, default=None\n",
      "            Parameters to pass to the fit method of the estimator.\n",
      "        \n",
      "        pre_dispatch : int or str, default='2*n_jobs'\n",
      "            Controls the number of jobs that get dispatched during parallel\n",
      "            execution. Reducing this number can be useful to avoid an\n",
      "            explosion of memory consumption when more jobs get dispatched\n",
      "            than CPUs can process. This parameter can be:\n",
      "        \n",
      "                - None, in which case all the jobs are immediately\n",
      "                  created and spawned. Use this for lightweight and\n",
      "                  fast-running jobs, to avoid delays due to on-demand\n",
      "                  spawning of the jobs\n",
      "        \n",
      "                - An int, giving the exact number of total jobs that are\n",
      "                  spawned\n",
      "        \n",
      "                - A str, giving an expression as a function of n_jobs,\n",
      "                  as in '2*n_jobs'\n",
      "        \n",
      "        error_score : 'raise' or numeric, default=np.nan\n",
      "            Value to assign to the score if an error occurs in estimator fitting.\n",
      "            If set to 'raise', the error is raised.\n",
      "            If a numeric value is given, FitFailedWarning is raised. This parameter\n",
      "            does not affect the refit step, which will always raise the error.\n",
      "        \n",
      "            .. versionadded:: 0.20\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        scores : array of float, shape=(len(list(cv)),)\n",
      "            Array of scores of the estimator for each run of the cross validation.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from sklearn import datasets, linear_model\n",
      "        >>> from sklearn.model_selection import cross_val_score\n",
      "        >>> diabetes = datasets.load_diabetes()\n",
      "        >>> X = diabetes.data[:150]\n",
      "        >>> y = diabetes.target[:150]\n",
      "        >>> lasso = linear_model.Lasso()\n",
      "        >>> print(cross_val_score(lasso, X, y, cv=3))\n",
      "        [0.33150734 0.08022311 0.03531764]\n",
      "        \n",
      "        See Also\n",
      "        ---------\n",
      "        :func:`sklearn.model_selection.cross_validate`:\n",
      "            To run cross-validation on multiple metrics and also to return\n",
      "            train scores, fit times and score times.\n",
      "        \n",
      "        :func:`sklearn.model_selection.cross_val_predict`:\n",
      "            Get predictions from each split of cross-validation for diagnostic\n",
      "            purposes.\n",
      "        \n",
      "        :func:`sklearn.metrics.make_scorer`:\n",
      "            Make a scorer from a performance metric or loss function.\n",
      "    \n",
      "    cross_validate(estimator, X, y=None, *, groups=None, scoring=None, cv=None, n_jobs=None, verbose=0, fit_params=None, pre_dispatch='2*n_jobs', return_train_score=False, return_estimator=False, error_score=nan)\n",
      "        Evaluate metric(s) by cross-validation and also record fit/score times.\n",
      "        \n",
      "        Read more in the :ref:`User Guide <multimetric_cross_validation>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        estimator : estimator object implementing 'fit'\n",
      "            The object to use to fit the data.\n",
      "        \n",
      "        X : array-like of shape (n_samples, n_features)\n",
      "            The data to fit. Can be for example a list, or an array.\n",
      "        \n",
      "        y : array-like of shape (n_samples,) or (n_samples, n_outputs),             default=None\n",
      "            The target variable to try to predict in the case of\n",
      "            supervised learning.\n",
      "        \n",
      "        groups : array-like of shape (n_samples,), default=None\n",
      "            Group labels for the samples used while splitting the dataset into\n",
      "            train/test set. Only used in conjunction with a \"Group\" :term:`cv`\n",
      "            instance (e.g., :class:`GroupKFold`).\n",
      "        \n",
      "        scoring : str, callable, list/tuple, or dict, default=None\n",
      "            A single str (see :ref:`scoring_parameter`) or a callable\n",
      "            (see :ref:`scoring`) to evaluate the predictions on the test set.\n",
      "        \n",
      "            For evaluating multiple metrics, either give a list of (unique) strings\n",
      "            or a dict with names as keys and callables as values.\n",
      "        \n",
      "            NOTE that when using custom scorers, each scorer should return a single\n",
      "            value. Metric functions returning a list/array of values can be wrapped\n",
      "            into multiple scorers that return one value each.\n",
      "        \n",
      "            See :ref:`multimetric_grid_search` for an example.\n",
      "        \n",
      "            If None, the estimator's score method is used.\n",
      "        \n",
      "        cv : int, cross-validation generator or an iterable, default=None\n",
      "            Determines the cross-validation splitting strategy.\n",
      "            Possible inputs for cv are:\n",
      "        \n",
      "            - None, to use the default 5-fold cross validation,\n",
      "            - int, to specify the number of folds in a `(Stratified)KFold`,\n",
      "            - :term:`CV splitter`,\n",
      "            - An iterable yielding (train, test) splits as arrays of indices.\n",
      "        \n",
      "            For int/None inputs, if the estimator is a classifier and ``y`` is\n",
      "            either binary or multiclass, :class:`StratifiedKFold` is used. In all\n",
      "            other cases, :class:`KFold` is used.\n",
      "        \n",
      "            Refer :ref:`User Guide <cross_validation>` for the various\n",
      "            cross-validation strategies that can be used here.\n",
      "        \n",
      "            .. versionchanged:: 0.22\n",
      "                ``cv`` default value if None changed from 3-fold to 5-fold.\n",
      "        \n",
      "        n_jobs : int, default=None\n",
      "            The number of CPUs to use to do the computation.\n",
      "            ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
      "            ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
      "            for more details.\n",
      "        \n",
      "        verbose : int, default=0\n",
      "            The verbosity level.\n",
      "        \n",
      "        fit_params : dict, default=None\n",
      "            Parameters to pass to the fit method of the estimator.\n",
      "        \n",
      "        pre_dispatch : int or str, default='2*n_jobs'\n",
      "            Controls the number of jobs that get dispatched during parallel\n",
      "            execution. Reducing this number can be useful to avoid an\n",
      "            explosion of memory consumption when more jobs get dispatched\n",
      "            than CPUs can process. This parameter can be:\n",
      "        \n",
      "                - None, in which case all the jobs are immediately\n",
      "                  created and spawned. Use this for lightweight and\n",
      "                  fast-running jobs, to avoid delays due to on-demand\n",
      "                  spawning of the jobs\n",
      "        \n",
      "                - An int, giving the exact number of total jobs that are\n",
      "                  spawned\n",
      "        \n",
      "                - A str, giving an expression as a function of n_jobs,\n",
      "                  as in '2*n_jobs'\n",
      "        \n",
      "        return_train_score : bool, default=False\n",
      "            Whether to include train scores.\n",
      "            Computing training scores is used to get insights on how different\n",
      "            parameter settings impact the overfitting/underfitting trade-off.\n",
      "            However computing the scores on the training set can be computationally\n",
      "            expensive and is not strictly required to select the parameters that\n",
      "            yield the best generalization performance.\n",
      "        \n",
      "            .. versionadded:: 0.19\n",
      "        \n",
      "            .. versionchanged:: 0.21\n",
      "                Default value was changed from ``True`` to ``False``\n",
      "        \n",
      "        return_estimator : bool, default=False\n",
      "            Whether to return the estimators fitted on each split.\n",
      "        \n",
      "            .. versionadded:: 0.20\n",
      "        \n",
      "        error_score : 'raise' or numeric\n",
      "            Value to assign to the score if an error occurs in estimator fitting.\n",
      "            If set to 'raise', the error is raised.\n",
      "            If a numeric value is given, FitFailedWarning is raised. This parameter\n",
      "            does not affect the refit step, which will always raise the error.\n",
      "        \n",
      "            .. versionadded:: 0.20\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        scores : dict of float arrays of shape (n_splits,)\n",
      "            Array of scores of the estimator for each run of the cross validation.\n",
      "        \n",
      "            A dict of arrays containing the score/time arrays for each scorer is\n",
      "            returned. The possible keys for this ``dict`` are:\n",
      "        \n",
      "                ``test_score``\n",
      "                    The score array for test scores on each cv split.\n",
      "                    Suffix ``_score`` in ``test_score`` changes to a specific\n",
      "                    metric like ``test_r2`` or ``test_auc`` if there are\n",
      "                    multiple scoring metrics in the scoring parameter.\n",
      "                ``train_score``\n",
      "                    The score array for train scores on each cv split.\n",
      "                    Suffix ``_score`` in ``train_score`` changes to a specific\n",
      "                    metric like ``train_r2`` or ``train_auc`` if there are\n",
      "                    multiple scoring metrics in the scoring parameter.\n",
      "                    This is available only if ``return_train_score`` parameter\n",
      "                    is ``True``.\n",
      "                ``fit_time``\n",
      "                    The time for fitting the estimator on the train\n",
      "                    set for each cv split.\n",
      "                ``score_time``\n",
      "                    The time for scoring the estimator on the test set for each\n",
      "                    cv split. (Note time for scoring on the train set is not\n",
      "                    included even if ``return_train_score`` is set to ``True``\n",
      "                ``estimator``\n",
      "                    The estimator objects for each cv split.\n",
      "                    This is available only if ``return_estimator`` parameter\n",
      "                    is set to ``True``.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from sklearn import datasets, linear_model\n",
      "        >>> from sklearn.model_selection import cross_validate\n",
      "        >>> from sklearn.metrics import make_scorer\n",
      "        >>> from sklearn.metrics import confusion_matrix\n",
      "        >>> from sklearn.svm import LinearSVC\n",
      "        >>> diabetes = datasets.load_diabetes()\n",
      "        >>> X = diabetes.data[:150]\n",
      "        >>> y = diabetes.target[:150]\n",
      "        >>> lasso = linear_model.Lasso()\n",
      "        \n",
      "        Single metric evaluation using ``cross_validate``\n",
      "        \n",
      "        >>> cv_results = cross_validate(lasso, X, y, cv=3)\n",
      "        >>> sorted(cv_results.keys())\n",
      "        ['fit_time', 'score_time', 'test_score']\n",
      "        >>> cv_results['test_score']\n",
      "        array([0.33150734, 0.08022311, 0.03531764])\n",
      "        \n",
      "        Multiple metric evaluation using ``cross_validate``\n",
      "        (please refer the ``scoring`` parameter doc for more information)\n",
      "        \n",
      "        >>> scores = cross_validate(lasso, X, y, cv=3,\n",
      "        ...                         scoring=('r2', 'neg_mean_squared_error'),\n",
      "        ...                         return_train_score=True)\n",
      "        >>> print(scores['test_neg_mean_squared_error'])\n",
      "        [-3635.5... -3573.3... -6114.7...]\n",
      "        >>> print(scores['train_r2'])\n",
      "        [0.28010158 0.39088426 0.22784852]\n",
      "        \n",
      "        See Also\n",
      "        ---------\n",
      "        :func:`sklearn.model_selection.cross_val_score`:\n",
      "            Run cross-validation for single metric evaluation.\n",
      "        \n",
      "        :func:`sklearn.model_selection.cross_val_predict`:\n",
      "            Get predictions from each split of cross-validation for diagnostic\n",
      "            purposes.\n",
      "        \n",
      "        :func:`sklearn.metrics.make_scorer`:\n",
      "            Make a scorer from a performance metric or loss function.\n",
      "    \n",
      "    fit_grid_point(X, y, estimator, parameters, train, test, scorer, verbose, error_score=nan, **fit_params)\n",
      "        DEPRECATED: fit_grid_point is deprecated in version 0.23 and will be removed in version 0.25\n",
      "        \n",
      "        Run fit on one set of parameters.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        X : array-like, sparse matrix or list\n",
      "            Input data.\n",
      "        \n",
      "        y : array-like or None\n",
      "            Targets for input data.\n",
      "        \n",
      "        estimator : estimator object\n",
      "            A object of that type is instantiated for each grid point.\n",
      "            This is assumed to implement the scikit-learn estimator interface.\n",
      "            Either estimator needs to provide a ``score`` function,\n",
      "            or ``scoring`` must be passed.\n",
      "        \n",
      "        parameters : dict\n",
      "            Parameters to be set on estimator for this grid point.\n",
      "        \n",
      "        train : ndarray, dtype int or bool\n",
      "            Boolean mask or indices for training set.\n",
      "        \n",
      "        test : ndarray, dtype int or bool\n",
      "            Boolean mask or indices for test set.\n",
      "        \n",
      "        scorer : callable or None\n",
      "            The scorer callable object / function must have its signature as\n",
      "            ``scorer(estimator, X, y)``.\n",
      "        \n",
      "            If ``None`` the estimator's score method is used.\n",
      "        \n",
      "        verbose : int\n",
      "            Verbosity level.\n",
      "        \n",
      "        **fit_params : kwargs\n",
      "            Additional parameter passed to the fit function of the estimator.\n",
      "        \n",
      "        error_score : 'raise' or numeric, default=np.nan\n",
      "            Value to assign to the score if an error occurs in estimator fitting.\n",
      "            If set to 'raise', the error is raised. If a numeric value is given,\n",
      "            FitFailedWarning is raised. This parameter does not affect the refit\n",
      "            step, which will always raise the error.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        score : float\n",
      "             Score of this parameter setting on given test split.\n",
      "        \n",
      "        parameters : dict\n",
      "            The parameters that have been evaluated.\n",
      "        \n",
      "        n_samples_test : int\n",
      "            Number of test samples in this split.\n",
      "    \n",
      "    learning_curve(estimator, X, y, *, groups=None, train_sizes=array([0.1  , 0.325, 0.55 , 0.775, 1.   ]), cv=None, scoring=None, exploit_incremental_learning=False, n_jobs=None, pre_dispatch='all', verbose=0, shuffle=False, random_state=None, error_score=nan, return_times=False)\n",
      "        Learning curve.\n",
      "        \n",
      "        Determines cross-validated training and test scores for different training\n",
      "        set sizes.\n",
      "        \n",
      "        A cross-validation generator splits the whole dataset k times in training\n",
      "        and test data. Subsets of the training set with varying sizes will be used\n",
      "        to train the estimator and a score for each training subset size and the\n",
      "        test set will be computed. Afterwards, the scores will be averaged over\n",
      "        all k runs for each training subset size.\n",
      "        \n",
      "        Read more in the :ref:`User Guide <learning_curve>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        estimator : object type that implements the \"fit\" and \"predict\" methods\n",
      "            An object of that type which is cloned for each validation.\n",
      "        \n",
      "        X : array-like of shape (n_samples, n_features)\n",
      "            Training vector, where n_samples is the number of samples and\n",
      "            n_features is the number of features.\n",
      "        \n",
      "        y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      "            Target relative to X for classification or regression;\n",
      "            None for unsupervised learning.\n",
      "        \n",
      "        groups : array-like of  shape (n_samples,), default=None\n",
      "            Group labels for the samples used while splitting the dataset into\n",
      "            train/test set. Only used in conjunction with a \"Group\" :term:`cv`\n",
      "            instance (e.g., :class:`GroupKFold`).\n",
      "        \n",
      "        train_sizes : array-like of shape (n_ticks,),             default=np.linspace(0.1, 1.0, 5)\n",
      "            Relative or absolute numbers of training examples that will be used to\n",
      "            generate the learning curve. If the dtype is float, it is regarded as a\n",
      "            fraction of the maximum size of the training set (that is determined\n",
      "            by the selected validation method), i.e. it has to be within (0, 1].\n",
      "            Otherwise it is interpreted as absolute sizes of the training sets.\n",
      "            Note that for classification the number of samples usually have to\n",
      "            be big enough to contain at least one sample from each class.\n",
      "        \n",
      "        cv : int, cross-validation generator or an iterable, default=None\n",
      "            Determines the cross-validation splitting strategy.\n",
      "            Possible inputs for cv are:\n",
      "        \n",
      "            - None, to use the default 5-fold cross validation,\n",
      "            - int, to specify the number of folds in a `(Stratified)KFold`,\n",
      "            - :term:`CV splitter`,\n",
      "            - An iterable yielding (train, test) splits as arrays of indices.\n",
      "        \n",
      "            For int/None inputs, if the estimator is a classifier and ``y`` is\n",
      "            either binary or multiclass, :class:`StratifiedKFold` is used. In all\n",
      "            other cases, :class:`KFold` is used.\n",
      "        \n",
      "            Refer :ref:`User Guide <cross_validation>` for the various\n",
      "            cross-validation strategies that can be used here.\n",
      "        \n",
      "            .. versionchanged:: 0.22\n",
      "                ``cv`` default value if None changed from 3-fold to 5-fold.\n",
      "        \n",
      "        scoring : str or callable, default=None\n",
      "            A str (see model evaluation documentation) or\n",
      "            a scorer callable object / function with signature\n",
      "            ``scorer(estimator, X, y)``.\n",
      "        \n",
      "        exploit_incremental_learning : bool, default=False\n",
      "            If the estimator supports incremental learning, this will be\n",
      "            used to speed up fitting for different training set sizes.\n",
      "        \n",
      "        n_jobs : int, default=None\n",
      "            Number of jobs to run in parallel.\n",
      "            ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
      "            ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
      "            for more details.\n",
      "        \n",
      "        pre_dispatch : int or str, default='all'\n",
      "            Number of predispatched jobs for parallel execution (default is\n",
      "            all). The option can reduce the allocated memory. The str can\n",
      "            be an expression like '2*n_jobs'.\n",
      "        \n",
      "        verbose : int, default=0\n",
      "            Controls the verbosity: the higher, the more messages.\n",
      "        \n",
      "        shuffle : bool, default=False\n",
      "            Whether to shuffle training data before taking prefixes of it\n",
      "            based on``train_sizes``.\n",
      "        \n",
      "        random_state : int or RandomState instance, default=None\n",
      "            Used when ``shuffle`` is True. Pass an int for reproducible\n",
      "            output across multiple function calls.\n",
      "            See :term:`Glossary <random_state>`.\n",
      "        \n",
      "        error_score : 'raise' or numeric, default=np.nan\n",
      "            Value to assign to the score if an error occurs in estimator fitting.\n",
      "            If set to 'raise', the error is raised.\n",
      "            If a numeric value is given, FitFailedWarning is raised. This parameter\n",
      "            does not affect the refit step, which will always raise the error.\n",
      "        \n",
      "            .. versionadded:: 0.20\n",
      "        \n",
      "        return_times : bool, default=False\n",
      "            Whether to return the fit and score times.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        train_sizes_abs : array of shape (n_unique_ticks,)\n",
      "            Numbers of training examples that has been used to generate the\n",
      "            learning curve. Note that the number of ticks might be less\n",
      "            than n_ticks because duplicate entries will be removed.\n",
      "        \n",
      "        train_scores : array of shape (n_ticks, n_cv_folds)\n",
      "            Scores on training sets.\n",
      "        \n",
      "        test_scores : array of shape (n_ticks, n_cv_folds)\n",
      "            Scores on test set.\n",
      "        \n",
      "        fit_times : array of shape (n_ticks, n_cv_folds)\n",
      "            Times spent for fitting in seconds. Only present if ``return_times``\n",
      "            is True.\n",
      "        \n",
      "        score_times : array of shape (n_ticks, n_cv_folds)\n",
      "            Times spent for scoring in seconds. Only present if ``return_times``\n",
      "            is True.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        See :ref:`examples/model_selection/plot_learning_curve.py\n",
      "        <sphx_glr_auto_examples_model_selection_plot_learning_curve.py>`\n",
      "    \n",
      "    permutation_test_score(estimator, X, y, *, groups=None, cv=None, n_permutations=100, n_jobs=None, random_state=0, verbose=0, scoring=None)\n",
      "        Evaluate the significance of a cross-validated score with permutations\n",
      "        \n",
      "        Read more in the :ref:`User Guide <cross_validation>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        estimator : estimator object implementing 'fit'\n",
      "            The object to use to fit the data.\n",
      "        \n",
      "        X : array-like of shape at least 2D\n",
      "            The data to fit.\n",
      "        \n",
      "        y : array-like of shape (n_samples,) or (n_samples, n_outputs) or None\n",
      "            The target variable to try to predict in the case of\n",
      "            supervised learning.\n",
      "        \n",
      "        groups : array-like of shape (n_samples,), default=None\n",
      "            Labels to constrain permutation within groups, i.e. ``y`` values\n",
      "            are permuted among samples with the same group identifier.\n",
      "            When not specified, ``y`` values are permuted among all samples.\n",
      "        \n",
      "            When a grouped cross-validator is used, the group labels are\n",
      "            also passed on to the ``split`` method of the cross-validator. The\n",
      "            cross-validator uses them for grouping the samples  while splitting\n",
      "            the dataset into train/test set.\n",
      "        \n",
      "        scoring : str or callable, default=None\n",
      "            A single str (see :ref:`scoring_parameter`) or a callable\n",
      "            (see :ref:`scoring`) to evaluate the predictions on the test set.\n",
      "        \n",
      "            If None the estimator's score method is used.\n",
      "        \n",
      "        cv : int, cross-validation generator or an iterable, default=None\n",
      "            Determines the cross-validation splitting strategy.\n",
      "            Possible inputs for cv are:\n",
      "        \n",
      "            - None, to use the default 5-fold cross validation,\n",
      "            - int, to specify the number of folds in a `(Stratified)KFold`,\n",
      "            - :term:`CV splitter`,\n",
      "            - An iterable yielding (train, test) splits as arrays of indices.\n",
      "        \n",
      "            For int/None inputs, if the estimator is a classifier and ``y`` is\n",
      "            either binary or multiclass, :class:`StratifiedKFold` is used. In all\n",
      "            other cases, :class:`KFold` is used.\n",
      "        \n",
      "            Refer :ref:`User Guide <cross_validation>` for the various\n",
      "            cross-validation strategies that can be used here.\n",
      "        \n",
      "            .. versionchanged:: 0.22\n",
      "                ``cv`` default value if None changed from 3-fold to 5-fold.\n",
      "        \n",
      "        n_permutations : int, default=100\n",
      "            Number of times to permute ``y``.\n",
      "        \n",
      "        n_jobs : int, default=None\n",
      "            The number of CPUs to use to do the computation.\n",
      "            ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
      "            ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
      "            for more details.\n",
      "        \n",
      "        random_state : int, RandomState instance or None, default=0\n",
      "            Pass an int for reproducible output for permutation of\n",
      "            ``y`` values among samples. See :term:`Glossary <random_state>`.\n",
      "        \n",
      "        verbose : int, default=0\n",
      "            The verbosity level.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        score : float\n",
      "            The true score without permuting targets.\n",
      "        \n",
      "        permutation_scores : array of shape (n_permutations,)\n",
      "            The scores obtained for each permutations.\n",
      "        \n",
      "        pvalue : float\n",
      "            The p-value, which approximates the probability that the score would\n",
      "            be obtained by chance. This is calculated as:\n",
      "        \n",
      "            `(C + 1) / (n_permutations + 1)`\n",
      "        \n",
      "            Where C is the number of permutations whose score >= the true score.\n",
      "        \n",
      "            The best possible p-value is 1/(n_permutations + 1), the worst is 1.0.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        This function implements Test 1 in:\n",
      "        \n",
      "            Ojala and Garriga. Permutation Tests for Studying Classifier\n",
      "            Performance.  The Journal of Machine Learning Research (2010)\n",
      "            vol. 11\n",
      "            `[pdf] <http://www.jmlr.org/papers/volume11/ojala10a/ojala10a.pdf>`_.\n",
      "    \n",
      "    train_test_split(*arrays, **options)\n",
      "        Split arrays or matrices into random train and test subsets\n",
      "        \n",
      "        Quick utility that wraps input validation and\n",
      "        ``next(ShuffleSplit().split(X, y))`` and application to input data\n",
      "        into a single call for splitting (and optionally subsampling) data in a\n",
      "        oneliner.\n",
      "        \n",
      "        Read more in the :ref:`User Guide <cross_validation>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        *arrays : sequence of indexables with same length / shape[0]\n",
      "            Allowed inputs are lists, numpy arrays, scipy-sparse\n",
      "            matrices or pandas dataframes.\n",
      "        \n",
      "        test_size : float or int, default=None\n",
      "            If float, should be between 0.0 and 1.0 and represent the proportion\n",
      "            of the dataset to include in the test split. If int, represents the\n",
      "            absolute number of test samples. If None, the value is set to the\n",
      "            complement of the train size. If ``train_size`` is also None, it will\n",
      "            be set to 0.25.\n",
      "        \n",
      "        train_size : float or int, default=None\n",
      "            If float, should be between 0.0 and 1.0 and represent the\n",
      "            proportion of the dataset to include in the train split. If\n",
      "            int, represents the absolute number of train samples. If None,\n",
      "            the value is automatically set to the complement of the test size.\n",
      "        \n",
      "        random_state : int or RandomState instance, default=None\n",
      "            Controls the shuffling applied to the data before applying the split.\n",
      "            Pass an int for reproducible output across multiple function calls.\n",
      "            See :term:`Glossary <random_state>`.\n",
      "        \n",
      "        \n",
      "        shuffle : bool, default=True\n",
      "            Whether or not to shuffle the data before splitting. If shuffle=False\n",
      "            then stratify must be None.\n",
      "        \n",
      "        stratify : array-like, default=None\n",
      "            If not None, data is split in a stratified fashion, using this as\n",
      "            the class labels.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        splitting : list, length=2 * len(arrays)\n",
      "            List containing train-test split of inputs.\n",
      "        \n",
      "            .. versionadded:: 0.16\n",
      "                If the input is sparse, the output will be a\n",
      "                ``scipy.sparse.csr_matrix``. Else, output type is the same as the\n",
      "                input type.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> import numpy as np\n",
      "        >>> from sklearn.model_selection import train_test_split\n",
      "        >>> X, y = np.arange(10).reshape((5, 2)), range(5)\n",
      "        >>> X\n",
      "        array([[0, 1],\n",
      "               [2, 3],\n",
      "               [4, 5],\n",
      "               [6, 7],\n",
      "               [8, 9]])\n",
      "        >>> list(y)\n",
      "        [0, 1, 2, 3, 4]\n",
      "        \n",
      "        >>> X_train, X_test, y_train, y_test = train_test_split(\n",
      "        ...     X, y, test_size=0.33, random_state=42)\n",
      "        ...\n",
      "        >>> X_train\n",
      "        array([[4, 5],\n",
      "               [0, 1],\n",
      "               [6, 7]])\n",
      "        >>> y_train\n",
      "        [2, 0, 3]\n",
      "        >>> X_test\n",
      "        array([[2, 3],\n",
      "               [8, 9]])\n",
      "        >>> y_test\n",
      "        [1, 4]\n",
      "        \n",
      "        >>> train_test_split(y, shuffle=False)\n",
      "        [[0, 1, 2], [3, 4]]\n",
      "    \n",
      "    validation_curve(estimator, X, y, *, param_name, param_range, groups=None, cv=None, scoring=None, n_jobs=None, pre_dispatch='all', verbose=0, error_score=nan)\n",
      "        Validation curve.\n",
      "        \n",
      "        Determine training and test scores for varying parameter values.\n",
      "        \n",
      "        Compute scores for an estimator with different values of a specified\n",
      "        parameter. This is similar to grid search with one parameter. However, this\n",
      "        will also compute training scores and is merely a utility for plotting the\n",
      "        results.\n",
      "        \n",
      "        Read more in the :ref:`User Guide <validation_curve>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        estimator : object type that implements the \"fit\" and \"predict\" methods\n",
      "            An object of that type which is cloned for each validation.\n",
      "        \n",
      "        X : array-like of shape (n_samples, n_features)\n",
      "            Training vector, where n_samples is the number of samples and\n",
      "            n_features is the number of features.\n",
      "        \n",
      "        y : array-like of shape (n_samples,) or (n_samples, n_outputs) or None\n",
      "            Target relative to X for classification or regression;\n",
      "            None for unsupervised learning.\n",
      "        \n",
      "        param_name : str\n",
      "            Name of the parameter that will be varied.\n",
      "        \n",
      "        param_range : array-like of shape (n_values,)\n",
      "            The values of the parameter that will be evaluated.\n",
      "        \n",
      "        groups : array-like of shape (n_samples,), default=None\n",
      "            Group labels for the samples used while splitting the dataset into\n",
      "            train/test set. Only used in conjunction with a \"Group\" :term:`cv`\n",
      "            instance (e.g., :class:`GroupKFold`).\n",
      "        \n",
      "        cv : int, cross-validation generator or an iterable, default=None\n",
      "            Determines the cross-validation splitting strategy.\n",
      "            Possible inputs for cv are:\n",
      "        \n",
      "            - None, to use the default 5-fold cross validation,\n",
      "            - int, to specify the number of folds in a `(Stratified)KFold`,\n",
      "            - :term:`CV splitter`,\n",
      "            - An iterable yielding (train, test) splits as arrays of indices.\n",
      "        \n",
      "            For int/None inputs, if the estimator is a classifier and ``y`` is\n",
      "            either binary or multiclass, :class:`StratifiedKFold` is used. In all\n",
      "            other cases, :class:`KFold` is used.\n",
      "        \n",
      "            Refer :ref:`User Guide <cross_validation>` for the various\n",
      "            cross-validation strategies that can be used here.\n",
      "        \n",
      "            .. versionchanged:: 0.22\n",
      "                ``cv`` default value if None changed from 3-fold to 5-fold.\n",
      "        \n",
      "        scoring : str or callable, default=None\n",
      "            A str (see model evaluation documentation) or\n",
      "            a scorer callable object / function with signature\n",
      "            ``scorer(estimator, X, y)``.\n",
      "        \n",
      "        n_jobs : int, default=None\n",
      "            Number of jobs to run in parallel.\n",
      "            ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
      "            ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
      "            for more details.\n",
      "        \n",
      "        pre_dispatch : int or str, default='all'\n",
      "            Number of predispatched jobs for parallel execution (default is\n",
      "            all). The option can reduce the allocated memory. The str can\n",
      "            be an expression like '2*n_jobs'.\n",
      "        \n",
      "        verbose : int, default=0\n",
      "            Controls the verbosity: the higher, the more messages.\n",
      "        \n",
      "        error_score : 'raise' or numeric, default=np.nan\n",
      "            Value to assign to the score if an error occurs in estimator fitting.\n",
      "            If set to 'raise', the error is raised.\n",
      "            If a numeric value is given, FitFailedWarning is raised. This parameter\n",
      "            does not affect the refit step, which will always raise the error.\n",
      "        \n",
      "            .. versionadded:: 0.20\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        train_scores : array of shape (n_ticks, n_cv_folds)\n",
      "            Scores on training sets.\n",
      "        \n",
      "        test_scores : array of shape (n_ticks, n_cv_folds)\n",
      "            Scores on test set.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        See :ref:`sphx_glr_auto_examples_model_selection_plot_validation_curve.py`\n",
      "\n",
      "DATA\n",
      "    __all__ = ('BaseCrossValidator', 'GridSearchCV', 'TimeSeriesSplit', 'K...\n",
      "\n",
      "FILE\n",
      "    d:\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\__init__.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sklearn.model_selection\n",
    "help(sklearn.model_selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlsx = pd.ExcelFile('./Data/Outliers_out.xlsx')\n",
    "df = pd.read_excel(xlsx, '1x 5s')\n",
    "dataset= df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the 'sample' method takes a certain fraction randomly\n",
    "#Note that we use `random_state` to ensure the reproducibility of the examples.\n",
    "train_dataset = dataset.sample(frac=0.7, random_state=0)\n",
    "test_dataset = dataset.drop(train_dataset.index)\n",
    "\n",
    "\n",
    "\n",
    "# split datat into input and target\n",
    "\n",
    "train_input = train_dataset.copy()\n",
    "test_input = test_dataset.copy()\n",
    "\n",
    "train_target = train_input.pop('RHOB')\n",
    "test_target = test_input.pop('RHOB')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters\n",
    "#### Default parameters\n",
    "max_depth=3, learning_rate=0.1, n_estimators=100, verbosity=1, silent=None, objective='reg:squarederror', booster='gbtree', n_jobs=1, nthread=None, gamma=0, min_child_weight=1, max_delta_step=0, subsample=1, colsample_bytree=1, colsample_bylevel=1, colsample_bynode=1, reg_alpha=0, reg_lambda=1, scale_pos_weight=1, base_score=0.5, random_state=0, seed=None, missing=None, importance_type='gain'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explanation of relevant parameters for this kernel.\n",
    "\n",
    "* <strong>booster</strong>: Select the type of model to run at each iteration\n",
    "* <strong>gbtree</strong>: tree-based models\n",
    "* <strong>gblinear</strong>: linear models\n",
    "* <strong>nthread</strong>: default to maximum number of threads available if not set\n",
    "*<strong>objective</strong>: This defines the loss function to be minimized\n",
    "\n",
    "#### Parameters for controlling speed\n",
    "\n",
    "* <strong>subsample</strong>: Denotes the fraction of observations to be randomly samples for each tree\n",
    "* <strong>colsample_bytree</strong>: Subsample ratio of columns when constructing each tree.\n",
    "* <strong>n_estimators</strong>: Number of trees to fit.\n",
    "\n",
    "#### Important parameters which control overfiting\n",
    "\n",
    "* <strong>learning_rate</strong>: Makes the model more robust by shrinking the weights on each step\n",
    "* <strong>max_depth</strong>: The maximum depth of a tree.\n",
    "* <strong>min_child_weight</strong>: Defines the minimum sum of weights of all observations required in a child."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning the hyper-parameters\n",
    "\n",
    "## GridSearchCV params:\n",
    "\n",
    "* <strong> estimator</strong>: estimator object\n",
    "* <strong> param_grid </strong>: dict or list of dictionaries\n",
    "* <strong> scoring</strong>: A single string or a callable to evaluate the predictions on the test set. If None, the estimators score method is used.\n",
    "https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
    "* <strong>n_jobs</strong>: Number of jobs to run in parallel. None means. -1 means using all processors.\n",
    "*<strong>cv </strong>: cross-validation, None, to use the default 3-fold cross validation. Integer, to specify the number of folds in a (Stratified)KFold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomizedSearchCV params:\n",
    "* <strong>estimator</strong>:\n",
    "* <strong>param_distributions</strong>:\n",
    "* <strong>cv</strong>:\n",
    "* <strong>n_iter</strong>:\n",
    "* <strong>scoring</strong>:\n",
    "* <strong>n_jobs</strong>:\n",
    "* <strong>verbose</strong>:\n",
    "* <strong> return_train_score</strong>:\n",
    "* <strong>random_state</strong>:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hyper Parameter Optimization\n",
    "\n",
    "booster=['gbtree','gblinear']\n",
    "base_score=[0.25,0.5,0.75,1]\n",
    "objective = ['reg:squarederror']\n",
    "\n",
    "\n",
    "subsample = [0.5, 0.7]\n",
    "colsample_bytree= [0.5, 0.7]\n",
    "n_estimators = [100, 500, 900, 1100, 1500]\n",
    "\n",
    "learning_rate=[0.05,0.01,0.05, 0.08,0.095, 0.1,0.15,0.20]\n",
    "max_depth = [2, 3, 5, 10, 15 ]\n",
    "min_child_weight=[1,2,3,4,6,8,10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the grid of hyperparameters to search\n",
    "hyperparameter_grid = {\n",
    "    'n_estimators': n_estimators,\n",
    "    'max_depth':max_depth,\n",
    "    'learning_rate':learning_rate,\n",
    "    'min_child_weight':min_child_weight,\n",
    "    'booster':booster,\n",
    "    'base_score':base_score\n",
    "    }\n",
    "\n",
    "\n",
    "hyperparameter_grid2={\n",
    "    \n",
    "}\n",
    "\n",
    "param_tuning = {\n",
    "        'learning_rate': [0.01, 0.1],\n",
    "        'max_depth': [3, 5, 7, 10],\n",
    "        'min_child_weight': [1, 3, 5],\n",
    "        'subsample': [0.5, 0.7],\n",
    "        'colsample_bytree': [0.5, 0.7],\n",
    "        'n_estimators' : [100, 200, 500],\n",
    "        'objective': ['reg:squarederror']\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the random search with 4-fold cross validation\n",
    "import xgboost\n",
    "xgb_model1 =xgboost.XGBRegressor()\n",
    "\n",
    "xgb_model2 = XGBRegressor()\n",
    "\n",
    "random_cv = RandomizedSearchCV(estimator=xgb_model1,\n",
    "                                param_distributions=hyperparameter_grid,\n",
    "                                cv=5, \n",
    "                                n_iter=50,\n",
    "                                scoring = 'neg_mean_absolute_error',\n",
    "                                n_jobs = 4,\n",
    "                                verbose = 5, \n",
    "                                return_train_score = True,\n",
    "                                random_state=42)\n",
    "\n",
    "\n",
    "gsearch = GridSearchCV(estimator = xgb_model2,\n",
    "                        param_grid = param_tuning,                        \n",
    "                        #scoring = 'neg_mean_absolute_error', #MAE\n",
    "                        #scoring = 'neg_mean_squared_error',  #MSE\n",
    "                        cv = 5,\n",
    "                        n_jobs = -1,\n",
    "                        verbose = 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# help(RandomizedSearchCV)\n",
    "\n",
    "# help(GridSearchCV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "    xgb_model = XGBRegressor()\n",
    "    xgb_model.fit(train_input, train_target, early_stopping_rounds=10, eval_set=[(test_input, test_target)], verbose=False)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 288 candidates, totalling 1440 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:   12.0s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   58.6s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:  4.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:  6.8min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-rmse:1.56568\n",
      "[1]\tvalidation_0-rmse:1.41044\n",
      "[2]\tvalidation_0-rmse:1.27026\n",
      "[3]\tvalidation_0-rmse:1.14423\n",
      "[4]\tvalidation_0-rmse:1.03057\n",
      "[5]\tvalidation_0-rmse:0.92840\n",
      "[6]\tvalidation_0-rmse:0.83637\n",
      "[7]\tvalidation_0-rmse:0.75370\n",
      "[8]\tvalidation_0-rmse:0.67953\n",
      "[9]\tvalidation_0-rmse:0.61263\n",
      "[10]\tvalidation_0-rmse:0.55281\n",
      "[11]\tvalidation_0-rmse:0.49878\n",
      "[12]\tvalidation_0-rmse:0.45030\n",
      "[13]\tvalidation_0-rmse:0.40693\n",
      "[14]\tvalidation_0-rmse:0.36793\n",
      "[15]\tvalidation_0-rmse:0.33265\n",
      "[16]\tvalidation_0-rmse:0.30103\n",
      "[17]\tvalidation_0-rmse:0.27293\n",
      "[18]\tvalidation_0-rmse:0.24776\n",
      "[19]\tvalidation_0-rmse:0.22526\n",
      "[20]\tvalidation_0-rmse:0.20518\n",
      "[21]\tvalidation_0-rmse:0.18731\n",
      "[22]\tvalidation_0-rmse:0.17081\n",
      "[23]\tvalidation_0-rmse:0.15670\n",
      "[24]\tvalidation_0-rmse:0.14354\n",
      "[25]\tvalidation_0-rmse:0.13178\n",
      "[26]\tvalidation_0-rmse:0.12138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 1440 out of 1440 | elapsed:  8.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[27]\tvalidation_0-rmse:0.11214\n",
      "[28]\tvalidation_0-rmse:0.10391\n",
      "[29]\tvalidation_0-rmse:0.09663\n",
      "[30]\tvalidation_0-rmse:0.09023\n",
      "[31]\tvalidation_0-rmse:0.08471\n",
      "[32]\tvalidation_0-rmse:0.07980\n",
      "[33]\tvalidation_0-rmse:0.07580\n",
      "[34]\tvalidation_0-rmse:0.07180\n",
      "[35]\tvalidation_0-rmse:0.06881\n",
      "[36]\tvalidation_0-rmse:0.06592\n",
      "[37]\tvalidation_0-rmse:0.06355\n",
      "[38]\tvalidation_0-rmse:0.06161\n",
      "[39]\tvalidation_0-rmse:0.05954\n",
      "[40]\tvalidation_0-rmse:0.05812\n",
      "[41]\tvalidation_0-rmse:0.05661\n",
      "[42]\tvalidation_0-rmse:0.05563\n",
      "[43]\tvalidation_0-rmse:0.05461\n",
      "[44]\tvalidation_0-rmse:0.05385\n",
      "[45]\tvalidation_0-rmse:0.05318\n",
      "[46]\tvalidation_0-rmse:0.05224\n",
      "[47]\tvalidation_0-rmse:0.05168\n",
      "[48]\tvalidation_0-rmse:0.05102\n",
      "[49]\tvalidation_0-rmse:0.05038\n",
      "[50]\tvalidation_0-rmse:0.05007\n",
      "[51]\tvalidation_0-rmse:0.04985\n",
      "[52]\tvalidation_0-rmse:0.04953\n",
      "[53]\tvalidation_0-rmse:0.04922\n",
      "[54]\tvalidation_0-rmse:0.04898\n",
      "[55]\tvalidation_0-rmse:0.04889\n",
      "[56]\tvalidation_0-rmse:0.04864\n",
      "[57]\tvalidation_0-rmse:0.04836\n",
      "[58]\tvalidation_0-rmse:0.04813\n",
      "[59]\tvalidation_0-rmse:0.04805\n",
      "[60]\tvalidation_0-rmse:0.04793\n",
      "[61]\tvalidation_0-rmse:0.04756\n",
      "[62]\tvalidation_0-rmse:0.04737\n",
      "[63]\tvalidation_0-rmse:0.04718\n",
      "[64]\tvalidation_0-rmse:0.04693\n",
      "[65]\tvalidation_0-rmse:0.04675\n",
      "[66]\tvalidation_0-rmse:0.04663\n",
      "[67]\tvalidation_0-rmse:0.04655\n",
      "[68]\tvalidation_0-rmse:0.04632\n",
      "[69]\tvalidation_0-rmse:0.04616\n",
      "[70]\tvalidation_0-rmse:0.04602\n",
      "[71]\tvalidation_0-rmse:0.04601\n",
      "[72]\tvalidation_0-rmse:0.04596\n",
      "[73]\tvalidation_0-rmse:0.04582\n",
      "[74]\tvalidation_0-rmse:0.04574\n",
      "[75]\tvalidation_0-rmse:0.04559\n",
      "[76]\tvalidation_0-rmse:0.04558\n",
      "[77]\tvalidation_0-rmse:0.04559\n",
      "[78]\tvalidation_0-rmse:0.04560\n",
      "[79]\tvalidation_0-rmse:0.04555\n",
      "[80]\tvalidation_0-rmse:0.04552\n",
      "[81]\tvalidation_0-rmse:0.04544\n",
      "[82]\tvalidation_0-rmse:0.04543\n",
      "[83]\tvalidation_0-rmse:0.04529\n",
      "[84]\tvalidation_0-rmse:0.04521\n",
      "[85]\tvalidation_0-rmse:0.04521\n",
      "[86]\tvalidation_0-rmse:0.04514\n",
      "[87]\tvalidation_0-rmse:0.04503\n",
      "[88]\tvalidation_0-rmse:0.04498\n",
      "[89]\tvalidation_0-rmse:0.04474\n",
      "[90]\tvalidation_0-rmse:0.04467\n",
      "[91]\tvalidation_0-rmse:0.04464\n",
      "[92]\tvalidation_0-rmse:0.04450\n",
      "[93]\tvalidation_0-rmse:0.04448\n",
      "[94]\tvalidation_0-rmse:0.04441\n",
      "[95]\tvalidation_0-rmse:0.04438\n",
      "[96]\tvalidation_0-rmse:0.04438\n",
      "[97]\tvalidation_0-rmse:0.04437\n",
      "[98]\tvalidation_0-rmse:0.04437\n",
      "[99]\tvalidation_0-rmse:0.04427\n",
      "[100]\tvalidation_0-rmse:0.04422\n",
      "[101]\tvalidation_0-rmse:0.04417\n",
      "[102]\tvalidation_0-rmse:0.04415\n",
      "[103]\tvalidation_0-rmse:0.04410\n",
      "[104]\tvalidation_0-rmse:0.04406\n",
      "[105]\tvalidation_0-rmse:0.04405\n",
      "[106]\tvalidation_0-rmse:0.04397\n",
      "[107]\tvalidation_0-rmse:0.04395\n",
      "[108]\tvalidation_0-rmse:0.04390\n",
      "[109]\tvalidation_0-rmse:0.04389\n",
      "[110]\tvalidation_0-rmse:0.04389\n",
      "[111]\tvalidation_0-rmse:0.04378\n",
      "[112]\tvalidation_0-rmse:0.04381\n",
      "[113]\tvalidation_0-rmse:0.04378\n",
      "[114]\tvalidation_0-rmse:0.04367\n",
      "[115]\tvalidation_0-rmse:0.04367\n",
      "[116]\tvalidation_0-rmse:0.04358\n",
      "[117]\tvalidation_0-rmse:0.04356\n",
      "[118]\tvalidation_0-rmse:0.04355\n",
      "[119]\tvalidation_0-rmse:0.04356\n",
      "[120]\tvalidation_0-rmse:0.04346\n",
      "[121]\tvalidation_0-rmse:0.04342\n",
      "[122]\tvalidation_0-rmse:0.04339\n",
      "[123]\tvalidation_0-rmse:0.04328\n",
      "[124]\tvalidation_0-rmse:0.04328\n",
      "[125]\tvalidation_0-rmse:0.04328\n",
      "[126]\tvalidation_0-rmse:0.04328\n",
      "[127]\tvalidation_0-rmse:0.04331\n",
      "[128]\tvalidation_0-rmse:0.04326\n",
      "[129]\tvalidation_0-rmse:0.04323\n",
      "[130]\tvalidation_0-rmse:0.04313\n",
      "[131]\tvalidation_0-rmse:0.04312\n",
      "[132]\tvalidation_0-rmse:0.04310\n",
      "[133]\tvalidation_0-rmse:0.04309\n",
      "[134]\tvalidation_0-rmse:0.04311\n",
      "[135]\tvalidation_0-rmse:0.04312\n",
      "[136]\tvalidation_0-rmse:0.04310\n",
      "[137]\tvalidation_0-rmse:0.04309\n",
      "[138]\tvalidation_0-rmse:0.04306\n",
      "[139]\tvalidation_0-rmse:0.04306\n",
      "[140]\tvalidation_0-rmse:0.04302\n",
      "[141]\tvalidation_0-rmse:0.04299\n",
      "[142]\tvalidation_0-rmse:0.04297\n",
      "[143]\tvalidation_0-rmse:0.04295\n",
      "[144]\tvalidation_0-rmse:0.04290\n",
      "[145]\tvalidation_0-rmse:0.04288\n",
      "[146]\tvalidation_0-rmse:0.04285\n",
      "[147]\tvalidation_0-rmse:0.04283\n",
      "[148]\tvalidation_0-rmse:0.04281\n",
      "[149]\tvalidation_0-rmse:0.04278\n",
      "[150]\tvalidation_0-rmse:0.04275\n",
      "[151]\tvalidation_0-rmse:0.04274\n",
      "[152]\tvalidation_0-rmse:0.04273\n",
      "[153]\tvalidation_0-rmse:0.04268\n",
      "[154]\tvalidation_0-rmse:0.04268\n",
      "[155]\tvalidation_0-rmse:0.04265\n",
      "[156]\tvalidation_0-rmse:0.04261\n",
      "[157]\tvalidation_0-rmse:0.04259\n",
      "[158]\tvalidation_0-rmse:0.04258\n",
      "[159]\tvalidation_0-rmse:0.04256\n",
      "[160]\tvalidation_0-rmse:0.04256\n",
      "[161]\tvalidation_0-rmse:0.04257\n",
      "[162]\tvalidation_0-rmse:0.04256\n",
      "[163]\tvalidation_0-rmse:0.04255\n",
      "[164]\tvalidation_0-rmse:0.04254\n",
      "[165]\tvalidation_0-rmse:0.04253\n",
      "[166]\tvalidation_0-rmse:0.04254\n",
      "[167]\tvalidation_0-rmse:0.04253\n",
      "[168]\tvalidation_0-rmse:0.04254\n",
      "[169]\tvalidation_0-rmse:0.04252\n",
      "[170]\tvalidation_0-rmse:0.04249\n",
      "[171]\tvalidation_0-rmse:0.04247\n",
      "[172]\tvalidation_0-rmse:0.04246\n",
      "[173]\tvalidation_0-rmse:0.04244\n",
      "[174]\tvalidation_0-rmse:0.04243\n",
      "[175]\tvalidation_0-rmse:0.04242\n",
      "[176]\tvalidation_0-rmse:0.04240\n",
      "[177]\tvalidation_0-rmse:0.04241\n",
      "[178]\tvalidation_0-rmse:0.04238\n",
      "[179]\tvalidation_0-rmse:0.04237\n",
      "[180]\tvalidation_0-rmse:0.04236\n",
      "[181]\tvalidation_0-rmse:0.04236\n",
      "[182]\tvalidation_0-rmse:0.04234\n",
      "[183]\tvalidation_0-rmse:0.04232\n",
      "[184]\tvalidation_0-rmse:0.04230\n",
      "[185]\tvalidation_0-rmse:0.04231\n",
      "[186]\tvalidation_0-rmse:0.04229\n",
      "[187]\tvalidation_0-rmse:0.04227\n",
      "[188]\tvalidation_0-rmse:0.04222\n",
      "[189]\tvalidation_0-rmse:0.04222\n",
      "[190]\tvalidation_0-rmse:0.04218\n",
      "[191]\tvalidation_0-rmse:0.04219\n",
      "[192]\tvalidation_0-rmse:0.04217\n",
      "[193]\tvalidation_0-rmse:0.04216\n",
      "[194]\tvalidation_0-rmse:0.04212\n",
      "[195]\tvalidation_0-rmse:0.04211\n",
      "[196]\tvalidation_0-rmse:0.04211\n",
      "[197]\tvalidation_0-rmse:0.04210\n",
      "[198]\tvalidation_0-rmse:0.04210\n",
      "[199]\tvalidation_0-rmse:0.04206\n",
      "[200]\tvalidation_0-rmse:0.04206\n",
      "[201]\tvalidation_0-rmse:0.04206\n",
      "[202]\tvalidation_0-rmse:0.04208\n",
      "[203]\tvalidation_0-rmse:0.04208\n",
      "[204]\tvalidation_0-rmse:0.04207\n",
      "[205]\tvalidation_0-rmse:0.04207\n",
      "[206]\tvalidation_0-rmse:0.04207\n",
      "[207]\tvalidation_0-rmse:0.04206\n",
      "[208]\tvalidation_0-rmse:0.04204\n",
      "[209]\tvalidation_0-rmse:0.04205\n",
      "[210]\tvalidation_0-rmse:0.04204\n",
      "[211]\tvalidation_0-rmse:0.04203\n",
      "[212]\tvalidation_0-rmse:0.04201\n",
      "[213]\tvalidation_0-rmse:0.04201\n",
      "[214]\tvalidation_0-rmse:0.04198\n",
      "[215]\tvalidation_0-rmse:0.04198\n",
      "[216]\tvalidation_0-rmse:0.04197\n",
      "[217]\tvalidation_0-rmse:0.04197\n",
      "[218]\tvalidation_0-rmse:0.04196\n",
      "[219]\tvalidation_0-rmse:0.04195\n",
      "[220]\tvalidation_0-rmse:0.04195\n",
      "[221]\tvalidation_0-rmse:0.04191\n",
      "[222]\tvalidation_0-rmse:0.04190\n",
      "[223]\tvalidation_0-rmse:0.04190\n",
      "[224]\tvalidation_0-rmse:0.04188\n",
      "[225]\tvalidation_0-rmse:0.04187\n",
      "[226]\tvalidation_0-rmse:0.04186\n",
      "[227]\tvalidation_0-rmse:0.04186\n",
      "[228]\tvalidation_0-rmse:0.04186\n",
      "[229]\tvalidation_0-rmse:0.04183\n",
      "[230]\tvalidation_0-rmse:0.04181\n",
      "[231]\tvalidation_0-rmse:0.04180\n",
      "[232]\tvalidation_0-rmse:0.04179\n",
      "[233]\tvalidation_0-rmse:0.04180\n",
      "[234]\tvalidation_0-rmse:0.04178\n",
      "[235]\tvalidation_0-rmse:0.04176\n",
      "[236]\tvalidation_0-rmse:0.04175\n",
      "[237]\tvalidation_0-rmse:0.04173\n",
      "[238]\tvalidation_0-rmse:0.04173\n",
      "[239]\tvalidation_0-rmse:0.04173\n",
      "[240]\tvalidation_0-rmse:0.04173\n",
      "[241]\tvalidation_0-rmse:0.04171\n",
      "[242]\tvalidation_0-rmse:0.04170\n",
      "[243]\tvalidation_0-rmse:0.04169\n",
      "[244]\tvalidation_0-rmse:0.04167\n",
      "[245]\tvalidation_0-rmse:0.04165\n",
      "[246]\tvalidation_0-rmse:0.04164\n",
      "[247]\tvalidation_0-rmse:0.04164\n",
      "[248]\tvalidation_0-rmse:0.04165\n",
      "[249]\tvalidation_0-rmse:0.04163\n",
      "[250]\tvalidation_0-rmse:0.04161\n",
      "[251]\tvalidation_0-rmse:0.04161\n",
      "[252]\tvalidation_0-rmse:0.04161\n",
      "[253]\tvalidation_0-rmse:0.04159\n",
      "[254]\tvalidation_0-rmse:0.04160\n",
      "[255]\tvalidation_0-rmse:0.04158\n",
      "[256]\tvalidation_0-rmse:0.04158\n",
      "[257]\tvalidation_0-rmse:0.04158\n",
      "[258]\tvalidation_0-rmse:0.04157\n",
      "[259]\tvalidation_0-rmse:0.04157\n",
      "[260]\tvalidation_0-rmse:0.04157\n",
      "[261]\tvalidation_0-rmse:0.04157\n",
      "[262]\tvalidation_0-rmse:0.04155\n",
      "[263]\tvalidation_0-rmse:0.04154\n",
      "[264]\tvalidation_0-rmse:0.04155\n",
      "[265]\tvalidation_0-rmse:0.04154\n",
      "[266]\tvalidation_0-rmse:0.04154\n",
      "[267]\tvalidation_0-rmse:0.04153\n",
      "[268]\tvalidation_0-rmse:0.04153\n",
      "[269]\tvalidation_0-rmse:0.04152\n",
      "[270]\tvalidation_0-rmse:0.04151\n",
      "[271]\tvalidation_0-rmse:0.04150\n",
      "[272]\tvalidation_0-rmse:0.04149\n",
      "[273]\tvalidation_0-rmse:0.04149\n",
      "[274]\tvalidation_0-rmse:0.04149\n",
      "[275]\tvalidation_0-rmse:0.04148\n",
      "[276]\tvalidation_0-rmse:0.04148\n",
      "[277]\tvalidation_0-rmse:0.04147\n",
      "[278]\tvalidation_0-rmse:0.04145\n",
      "[279]\tvalidation_0-rmse:0.04145\n",
      "[280]\tvalidation_0-rmse:0.04144\n",
      "[281]\tvalidation_0-rmse:0.04141\n",
      "[282]\tvalidation_0-rmse:0.04141\n",
      "[283]\tvalidation_0-rmse:0.04140\n",
      "[284]\tvalidation_0-rmse:0.04139\n",
      "[285]\tvalidation_0-rmse:0.04139\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[286]\tvalidation_0-rmse:0.04136\n",
      "[287]\tvalidation_0-rmse:0.04136\n",
      "[288]\tvalidation_0-rmse:0.04134\n",
      "[289]\tvalidation_0-rmse:0.04133\n",
      "[290]\tvalidation_0-rmse:0.04132\n",
      "[291]\tvalidation_0-rmse:0.04130\n",
      "[292]\tvalidation_0-rmse:0.04130\n",
      "[293]\tvalidation_0-rmse:0.04130\n",
      "[294]\tvalidation_0-rmse:0.04130\n",
      "[295]\tvalidation_0-rmse:0.04129\n",
      "[296]\tvalidation_0-rmse:0.04129\n",
      "[297]\tvalidation_0-rmse:0.04129\n",
      "[298]\tvalidation_0-rmse:0.04128\n",
      "[299]\tvalidation_0-rmse:0.04128\n",
      "[300]\tvalidation_0-rmse:0.04126\n",
      "[301]\tvalidation_0-rmse:0.04126\n",
      "[302]\tvalidation_0-rmse:0.04125\n",
      "[303]\tvalidation_0-rmse:0.04125\n",
      "[304]\tvalidation_0-rmse:0.04124\n",
      "[305]\tvalidation_0-rmse:0.04124\n",
      "[306]\tvalidation_0-rmse:0.04124\n",
      "[307]\tvalidation_0-rmse:0.04123\n",
      "[308]\tvalidation_0-rmse:0.04123\n",
      "[309]\tvalidation_0-rmse:0.04124\n",
      "[310]\tvalidation_0-rmse:0.04122\n",
      "[311]\tvalidation_0-rmse:0.04122\n",
      "[312]\tvalidation_0-rmse:0.04121\n",
      "[313]\tvalidation_0-rmse:0.04121\n",
      "[314]\tvalidation_0-rmse:0.04120\n",
      "[315]\tvalidation_0-rmse:0.04120\n",
      "[316]\tvalidation_0-rmse:0.04120\n",
      "[317]\tvalidation_0-rmse:0.04120\n",
      "[318]\tvalidation_0-rmse:0.04120\n",
      "[319]\tvalidation_0-rmse:0.04118\n",
      "[320]\tvalidation_0-rmse:0.04118\n",
      "[321]\tvalidation_0-rmse:0.04118\n",
      "[322]\tvalidation_0-rmse:0.04118\n",
      "[323]\tvalidation_0-rmse:0.04117\n",
      "[324]\tvalidation_0-rmse:0.04117\n",
      "[325]\tvalidation_0-rmse:0.04117\n",
      "[326]\tvalidation_0-rmse:0.04116\n",
      "[327]\tvalidation_0-rmse:0.04116\n",
      "[328]\tvalidation_0-rmse:0.04115\n",
      "[329]\tvalidation_0-rmse:0.04115\n",
      "[330]\tvalidation_0-rmse:0.04115\n",
      "[331]\tvalidation_0-rmse:0.04114\n",
      "[332]\tvalidation_0-rmse:0.04113\n",
      "[333]\tvalidation_0-rmse:0.04112\n",
      "[334]\tvalidation_0-rmse:0.04111\n",
      "[335]\tvalidation_0-rmse:0.04111\n",
      "[336]\tvalidation_0-rmse:0.04111\n",
      "[337]\tvalidation_0-rmse:0.04111\n",
      "[338]\tvalidation_0-rmse:0.04111\n",
      "[339]\tvalidation_0-rmse:0.04110\n",
      "[340]\tvalidation_0-rmse:0.04110\n",
      "[341]\tvalidation_0-rmse:0.04110\n",
      "[342]\tvalidation_0-rmse:0.04110\n",
      "[343]\tvalidation_0-rmse:0.04110\n",
      "[344]\tvalidation_0-rmse:0.04110\n",
      "[345]\tvalidation_0-rmse:0.04110\n",
      "[346]\tvalidation_0-rmse:0.04110\n",
      "[347]\tvalidation_0-rmse:0.04110\n",
      "[348]\tvalidation_0-rmse:0.04109\n",
      "[349]\tvalidation_0-rmse:0.04109\n",
      "[350]\tvalidation_0-rmse:0.04109\n",
      "[351]\tvalidation_0-rmse:0.04108\n",
      "[352]\tvalidation_0-rmse:0.04107\n",
      "[353]\tvalidation_0-rmse:0.04107\n",
      "[354]\tvalidation_0-rmse:0.04106\n",
      "[355]\tvalidation_0-rmse:0.04106\n",
      "[356]\tvalidation_0-rmse:0.04106\n",
      "[357]\tvalidation_0-rmse:0.04106\n",
      "[358]\tvalidation_0-rmse:0.04105\n",
      "[359]\tvalidation_0-rmse:0.04105\n",
      "[360]\tvalidation_0-rmse:0.04105\n",
      "[361]\tvalidation_0-rmse:0.04105\n",
      "[362]\tvalidation_0-rmse:0.04106\n",
      "[363]\tvalidation_0-rmse:0.04106\n",
      "[364]\tvalidation_0-rmse:0.04105\n",
      "[365]\tvalidation_0-rmse:0.04105\n",
      "[366]\tvalidation_0-rmse:0.04105\n",
      "[367]\tvalidation_0-rmse:0.04105\n",
      "[368]\tvalidation_0-rmse:0.04105\n",
      "[369]\tvalidation_0-rmse:0.04105\n",
      "[370]\tvalidation_0-rmse:0.04104\n",
      "[371]\tvalidation_0-rmse:0.04104\n",
      "[372]\tvalidation_0-rmse:0.04104\n",
      "[373]\tvalidation_0-rmse:0.04104\n",
      "[374]\tvalidation_0-rmse:0.04104\n",
      "[375]\tvalidation_0-rmse:0.04103\n",
      "[376]\tvalidation_0-rmse:0.04103\n",
      "[377]\tvalidation_0-rmse:0.04103\n",
      "[378]\tvalidation_0-rmse:0.04102\n",
      "[379]\tvalidation_0-rmse:0.04102\n",
      "[380]\tvalidation_0-rmse:0.04102\n",
      "[381]\tvalidation_0-rmse:0.04103\n",
      "[382]\tvalidation_0-rmse:0.04103\n",
      "[383]\tvalidation_0-rmse:0.04103\n",
      "[384]\tvalidation_0-rmse:0.04103\n",
      "[385]\tvalidation_0-rmse:0.04103\n",
      "[386]\tvalidation_0-rmse:0.04103\n",
      "[387]\tvalidation_0-rmse:0.04102\n",
      "[388]\tvalidation_0-rmse:0.04102\n",
      "[389]\tvalidation_0-rmse:0.04102\n",
      "[390]\tvalidation_0-rmse:0.04101\n",
      "[391]\tvalidation_0-rmse:0.04101\n",
      "[392]\tvalidation_0-rmse:0.04101\n",
      "[393]\tvalidation_0-rmse:0.04101\n",
      "[394]\tvalidation_0-rmse:0.04101\n",
      "[395]\tvalidation_0-rmse:0.04101\n",
      "[396]\tvalidation_0-rmse:0.04101\n",
      "[397]\tvalidation_0-rmse:0.04100\n",
      "[398]\tvalidation_0-rmse:0.04100\n",
      "[399]\tvalidation_0-rmse:0.04100\n",
      "[400]\tvalidation_0-rmse:0.04099\n",
      "[401]\tvalidation_0-rmse:0.04099\n",
      "[402]\tvalidation_0-rmse:0.04099\n",
      "[403]\tvalidation_0-rmse:0.04099\n",
      "[404]\tvalidation_0-rmse:0.04099\n",
      "[405]\tvalidation_0-rmse:0.04099\n",
      "[406]\tvalidation_0-rmse:0.04099\n",
      "[407]\tvalidation_0-rmse:0.04098\n",
      "[408]\tvalidation_0-rmse:0.04098\n",
      "[409]\tvalidation_0-rmse:0.04098\n",
      "[410]\tvalidation_0-rmse:0.04098\n",
      "[411]\tvalidation_0-rmse:0.04098\n",
      "[412]\tvalidation_0-rmse:0.04097\n",
      "[413]\tvalidation_0-rmse:0.04097\n",
      "[414]\tvalidation_0-rmse:0.04098\n",
      "[415]\tvalidation_0-rmse:0.04097\n",
      "[416]\tvalidation_0-rmse:0.04097\n",
      "[417]\tvalidation_0-rmse:0.04097\n",
      "[418]\tvalidation_0-rmse:0.04097\n",
      "[419]\tvalidation_0-rmse:0.04096\n",
      "[420]\tvalidation_0-rmse:0.04096\n",
      "[421]\tvalidation_0-rmse:0.04096\n",
      "[422]\tvalidation_0-rmse:0.04096\n",
      "[423]\tvalidation_0-rmse:0.04096\n",
      "[424]\tvalidation_0-rmse:0.04096\n",
      "[425]\tvalidation_0-rmse:0.04095\n",
      "[426]\tvalidation_0-rmse:0.04095\n",
      "[427]\tvalidation_0-rmse:0.04095\n",
      "[428]\tvalidation_0-rmse:0.04095\n",
      "[429]\tvalidation_0-rmse:0.04095\n",
      "[430]\tvalidation_0-rmse:0.04095\n",
      "[431]\tvalidation_0-rmse:0.04095\n",
      "[432]\tvalidation_0-rmse:0.04095\n",
      "[433]\tvalidation_0-rmse:0.04094\n",
      "[434]\tvalidation_0-rmse:0.04094\n",
      "[435]\tvalidation_0-rmse:0.04094\n",
      "[436]\tvalidation_0-rmse:0.04094\n",
      "[437]\tvalidation_0-rmse:0.04093\n",
      "[438]\tvalidation_0-rmse:0.04093\n",
      "[439]\tvalidation_0-rmse:0.04093\n",
      "[440]\tvalidation_0-rmse:0.04093\n",
      "[441]\tvalidation_0-rmse:0.04093\n",
      "[442]\tvalidation_0-rmse:0.04093\n",
      "[443]\tvalidation_0-rmse:0.04093\n",
      "[444]\tvalidation_0-rmse:0.04092\n",
      "[445]\tvalidation_0-rmse:0.04092\n",
      "[446]\tvalidation_0-rmse:0.04092\n",
      "[447]\tvalidation_0-rmse:0.04092\n",
      "[448]\tvalidation_0-rmse:0.04092\n",
      "[449]\tvalidation_0-rmse:0.04092\n",
      "[450]\tvalidation_0-rmse:0.04092\n",
      "[451]\tvalidation_0-rmse:0.04092\n",
      "[452]\tvalidation_0-rmse:0.04092\n",
      "[453]\tvalidation_0-rmse:0.04092\n",
      "[454]\tvalidation_0-rmse:0.04092\n",
      "[455]\tvalidation_0-rmse:0.04092\n",
      "[456]\tvalidation_0-rmse:0.04092\n",
      "[457]\tvalidation_0-rmse:0.04092\n",
      "[458]\tvalidation_0-rmse:0.04092\n",
      "[459]\tvalidation_0-rmse:0.04091\n",
      "[460]\tvalidation_0-rmse:0.04091\n",
      "[461]\tvalidation_0-rmse:0.04091\n",
      "[462]\tvalidation_0-rmse:0.04091\n",
      "[463]\tvalidation_0-rmse:0.04091\n",
      "[464]\tvalidation_0-rmse:0.04090\n",
      "[465]\tvalidation_0-rmse:0.04090\n",
      "[466]\tvalidation_0-rmse:0.04090\n",
      "[467]\tvalidation_0-rmse:0.04090\n",
      "[468]\tvalidation_0-rmse:0.04089\n",
      "[469]\tvalidation_0-rmse:0.04089\n",
      "[470]\tvalidation_0-rmse:0.04089\n",
      "[471]\tvalidation_0-rmse:0.04089\n",
      "[472]\tvalidation_0-rmse:0.04090\n",
      "[473]\tvalidation_0-rmse:0.04089\n",
      "[474]\tvalidation_0-rmse:0.04089\n",
      "[475]\tvalidation_0-rmse:0.04089\n",
      "[476]\tvalidation_0-rmse:0.04089\n",
      "[477]\tvalidation_0-rmse:0.04089\n",
      "[478]\tvalidation_0-rmse:0.04089\n",
      "[479]\tvalidation_0-rmse:0.04089\n",
      "[480]\tvalidation_0-rmse:0.04089\n",
      "[481]\tvalidation_0-rmse:0.04088\n",
      "[482]\tvalidation_0-rmse:0.04088\n",
      "[483]\tvalidation_0-rmse:0.04088\n",
      "[484]\tvalidation_0-rmse:0.04088\n",
      "[485]\tvalidation_0-rmse:0.04088\n",
      "[486]\tvalidation_0-rmse:0.04088\n",
      "[487]\tvalidation_0-rmse:0.04088\n",
      "[488]\tvalidation_0-rmse:0.04087\n",
      "[489]\tvalidation_0-rmse:0.04087\n",
      "[490]\tvalidation_0-rmse:0.04087\n",
      "[491]\tvalidation_0-rmse:0.04087\n",
      "[492]\tvalidation_0-rmse:0.04087\n",
      "[493]\tvalidation_0-rmse:0.04087\n",
      "[494]\tvalidation_0-rmse:0.04087\n",
      "[495]\tvalidation_0-rmse:0.04087\n",
      "[496]\tvalidation_0-rmse:0.04087\n",
      "[497]\tvalidation_0-rmse:0.04086\n",
      "[498]\tvalidation_0-rmse:0.04086\n",
      "[499]\tvalidation_0-rmse:0.04086\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                    colsample_bylevel=None,\n",
       "                                    colsample_bynode=None,\n",
       "                                    colsample_bytree=None, gamma=None,\n",
       "                                    gpu_id=None, importance_type='gain',\n",
       "                                    interaction_constraints=None,\n",
       "                                    learning_rate=None, max_delta_step=None,\n",
       "                                    max_depth=None, min_child_weight=None,\n",
       "                                    missing=nan, monotone_constraints=None,\n",
       "                                    n_estimators=100, n_jobs=...\n",
       "                                    num_parallel_tree=None, random_state=None,\n",
       "                                    reg_alpha=None, reg_lambda=None,\n",
       "                                    scale_pos_weight=None, subsample=None,\n",
       "                                    tree_method=None, validate_parameters=None,\n",
       "                                    verbosity=None),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'colsample_bytree': [0.5, 0.7],\n",
       "                         'learning_rate': [0.01, 0.1],\n",
       "                         'max_depth': [3, 5, 7, 10],\n",
       "                         'min_child_weight': [1, 3, 5],\n",
       "                         'n_estimators': [100, 200, 500],\n",
       "                         'objective': ['reg:squarederror'],\n",
       "                         'subsample': [0.5, 0.7]},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    gsearch.fit(train_input, train_target,\n",
    "                eval_set=[(test_input, test_target)],\n",
    "               early_stopping_rounds=10\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.7,\n",
       " 'learning_rate': 0.1,\n",
       " 'max_depth': 10,\n",
       " 'min_child_weight': 1,\n",
       " 'n_estimators': 500,\n",
       " 'objective': 'reg:squarederror',\n",
       " 'subsample': 0.7}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best params\n",
    "gsearch.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  10 tasks      | elapsed:    4.3s\n",
      "[Parallel(n_jobs=4)]: Done  64 tasks      | elapsed:   26.4s\n",
      "[Parallel(n_jobs=4)]: Done 154 tasks      | elapsed:  1.0min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-rmse:1.19481\n",
      "[1]\tvalidation_0-rmse:0.95741\n",
      "[2]\tvalidation_0-rmse:0.76778\n",
      "[3]\tvalidation_0-rmse:0.61646\n",
      "[4]\tvalidation_0-rmse:0.49555\n",
      "[5]\tvalidation_0-rmse:0.39901\n",
      "[6]\tvalidation_0-rmse:0.32223\n",
      "[7]\tvalidation_0-rmse:0.26095\n",
      "[8]\tvalidation_0-rmse:0.21232\n",
      "[9]\tvalidation_0-rmse:0.17414\n",
      "[10]\tvalidation_0-rmse:0.14389\n",
      "[11]\tvalidation_0-rmse:0.12030\n",
      "[12]\tvalidation_0-rmse:0.10247\n",
      "[13]\tvalidation_0-rmse:0.08852\n",
      "[14]\tvalidation_0-rmse:0.07805\n",
      "[15]\tvalidation_0-rmse:0.07002\n",
      "[16]\tvalidation_0-rmse:0.06442\n",
      "[17]\tvalidation_0-rmse:0.06005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done 250 out of 250 | elapsed:  2.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18]\tvalidation_0-rmse:0.05715\n",
      "[19]\tvalidation_0-rmse:0.05438\n",
      "[20]\tvalidation_0-rmse:0.05251\n",
      "[21]\tvalidation_0-rmse:0.05144\n",
      "[22]\tvalidation_0-rmse:0.05040\n",
      "[23]\tvalidation_0-rmse:0.04948\n",
      "[24]\tvalidation_0-rmse:0.04895\n",
      "[25]\tvalidation_0-rmse:0.04859\n",
      "[26]\tvalidation_0-rmse:0.04840\n",
      "[27]\tvalidation_0-rmse:0.04802\n",
      "[28]\tvalidation_0-rmse:0.04788\n",
      "[29]\tvalidation_0-rmse:0.04773\n",
      "[30]\tvalidation_0-rmse:0.04764\n",
      "[31]\tvalidation_0-rmse:0.04761\n",
      "[32]\tvalidation_0-rmse:0.04748\n",
      "[33]\tvalidation_0-rmse:0.04738\n",
      "[34]\tvalidation_0-rmse:0.04732\n",
      "[35]\tvalidation_0-rmse:0.04703\n",
      "[36]\tvalidation_0-rmse:0.04683\n",
      "[37]\tvalidation_0-rmse:0.04677\n",
      "[38]\tvalidation_0-rmse:0.04672\n",
      "[39]\tvalidation_0-rmse:0.04650\n",
      "[40]\tvalidation_0-rmse:0.04644\n",
      "[41]\tvalidation_0-rmse:0.04644\n",
      "[42]\tvalidation_0-rmse:0.04611\n",
      "[43]\tvalidation_0-rmse:0.04595\n",
      "[44]\tvalidation_0-rmse:0.04595\n",
      "[45]\tvalidation_0-rmse:0.04580\n",
      "[46]\tvalidation_0-rmse:0.04558\n",
      "[47]\tvalidation_0-rmse:0.04538\n",
      "[48]\tvalidation_0-rmse:0.04525\n",
      "[49]\tvalidation_0-rmse:0.04488\n",
      "[50]\tvalidation_0-rmse:0.04487\n",
      "[51]\tvalidation_0-rmse:0.04480\n",
      "[52]\tvalidation_0-rmse:0.04469\n",
      "[53]\tvalidation_0-rmse:0.04462\n",
      "[54]\tvalidation_0-rmse:0.04460\n",
      "[55]\tvalidation_0-rmse:0.04443\n",
      "[56]\tvalidation_0-rmse:0.04437\n",
      "[57]\tvalidation_0-rmse:0.04434\n",
      "[58]\tvalidation_0-rmse:0.04436\n",
      "[59]\tvalidation_0-rmse:0.04429\n",
      "[60]\tvalidation_0-rmse:0.04418\n",
      "[61]\tvalidation_0-rmse:0.04418\n",
      "[62]\tvalidation_0-rmse:0.04417\n",
      "[63]\tvalidation_0-rmse:0.04408\n",
      "[64]\tvalidation_0-rmse:0.04401\n",
      "[65]\tvalidation_0-rmse:0.04400\n",
      "[66]\tvalidation_0-rmse:0.04390\n",
      "[67]\tvalidation_0-rmse:0.04387\n",
      "[68]\tvalidation_0-rmse:0.04378\n",
      "[69]\tvalidation_0-rmse:0.04372\n",
      "[70]\tvalidation_0-rmse:0.04362\n",
      "[71]\tvalidation_0-rmse:0.04357\n",
      "[72]\tvalidation_0-rmse:0.04360\n",
      "[73]\tvalidation_0-rmse:0.04359\n",
      "[74]\tvalidation_0-rmse:0.04350\n",
      "[75]\tvalidation_0-rmse:0.04345\n",
      "[76]\tvalidation_0-rmse:0.04333\n",
      "[77]\tvalidation_0-rmse:0.04328\n",
      "[78]\tvalidation_0-rmse:0.04326\n",
      "[79]\tvalidation_0-rmse:0.04325\n",
      "[80]\tvalidation_0-rmse:0.04316\n",
      "[81]\tvalidation_0-rmse:0.04310\n",
      "[82]\tvalidation_0-rmse:0.04309\n",
      "[83]\tvalidation_0-rmse:0.04301\n",
      "[84]\tvalidation_0-rmse:0.04299\n",
      "[85]\tvalidation_0-rmse:0.04298\n",
      "[86]\tvalidation_0-rmse:0.04296\n",
      "[87]\tvalidation_0-rmse:0.04287\n",
      "[88]\tvalidation_0-rmse:0.04286\n",
      "[89]\tvalidation_0-rmse:0.04287\n",
      "[90]\tvalidation_0-rmse:0.04287\n",
      "[91]\tvalidation_0-rmse:0.04287\n",
      "[92]\tvalidation_0-rmse:0.04286\n",
      "[93]\tvalidation_0-rmse:0.04285\n",
      "[94]\tvalidation_0-rmse:0.04280\n",
      "[95]\tvalidation_0-rmse:0.04275\n",
      "[96]\tvalidation_0-rmse:0.04275\n",
      "[97]\tvalidation_0-rmse:0.04274\n",
      "[98]\tvalidation_0-rmse:0.04266\n",
      "[99]\tvalidation_0-rmse:0.04262\n",
      "[100]\tvalidation_0-rmse:0.04263\n",
      "[101]\tvalidation_0-rmse:0.04259\n",
      "[102]\tvalidation_0-rmse:0.04256\n",
      "[103]\tvalidation_0-rmse:0.04256\n",
      "[104]\tvalidation_0-rmse:0.04254\n",
      "[105]\tvalidation_0-rmse:0.04250\n",
      "[106]\tvalidation_0-rmse:0.04249\n",
      "[107]\tvalidation_0-rmse:0.04246\n",
      "[108]\tvalidation_0-rmse:0.04245\n",
      "[109]\tvalidation_0-rmse:0.04243\n",
      "[110]\tvalidation_0-rmse:0.04244\n",
      "[111]\tvalidation_0-rmse:0.04240\n",
      "[112]\tvalidation_0-rmse:0.04236\n",
      "[113]\tvalidation_0-rmse:0.04237\n",
      "[114]\tvalidation_0-rmse:0.04235\n",
      "[115]\tvalidation_0-rmse:0.04233\n",
      "[116]\tvalidation_0-rmse:0.04232\n",
      "[117]\tvalidation_0-rmse:0.04233\n",
      "[118]\tvalidation_0-rmse:0.04233\n",
      "[119]\tvalidation_0-rmse:0.04229\n",
      "[120]\tvalidation_0-rmse:0.04227\n",
      "[121]\tvalidation_0-rmse:0.04222\n",
      "[122]\tvalidation_0-rmse:0.04221\n",
      "[123]\tvalidation_0-rmse:0.04216\n",
      "[124]\tvalidation_0-rmse:0.04217\n",
      "[125]\tvalidation_0-rmse:0.04216\n",
      "[126]\tvalidation_0-rmse:0.04216\n",
      "[127]\tvalidation_0-rmse:0.04216\n",
      "[128]\tvalidation_0-rmse:0.04216\n",
      "[129]\tvalidation_0-rmse:0.04215\n",
      "[130]\tvalidation_0-rmse:0.04216\n",
      "[131]\tvalidation_0-rmse:0.04215\n",
      "[132]\tvalidation_0-rmse:0.04215\n",
      "[133]\tvalidation_0-rmse:0.04214\n",
      "[134]\tvalidation_0-rmse:0.04213\n",
      "[135]\tvalidation_0-rmse:0.04212\n",
      "[136]\tvalidation_0-rmse:0.04213\n",
      "[137]\tvalidation_0-rmse:0.04212\n",
      "[138]\tvalidation_0-rmse:0.04211\n",
      "[139]\tvalidation_0-rmse:0.04210\n",
      "[140]\tvalidation_0-rmse:0.04209\n",
      "[141]\tvalidation_0-rmse:0.04208\n",
      "[142]\tvalidation_0-rmse:0.04208\n",
      "[143]\tvalidation_0-rmse:0.04206\n",
      "[144]\tvalidation_0-rmse:0.04206\n",
      "[145]\tvalidation_0-rmse:0.04206\n",
      "[146]\tvalidation_0-rmse:0.04204\n",
      "[147]\tvalidation_0-rmse:0.04204\n",
      "[148]\tvalidation_0-rmse:0.04203\n",
      "[149]\tvalidation_0-rmse:0.04202\n",
      "[150]\tvalidation_0-rmse:0.04199\n",
      "[151]\tvalidation_0-rmse:0.04200\n",
      "[152]\tvalidation_0-rmse:0.04200\n",
      "[153]\tvalidation_0-rmse:0.04198\n",
      "[154]\tvalidation_0-rmse:0.04199\n",
      "[155]\tvalidation_0-rmse:0.04199\n",
      "[156]\tvalidation_0-rmse:0.04197\n",
      "[157]\tvalidation_0-rmse:0.04197\n",
      "[158]\tvalidation_0-rmse:0.04197\n",
      "[159]\tvalidation_0-rmse:0.04197\n",
      "[160]\tvalidation_0-rmse:0.04196\n",
      "[161]\tvalidation_0-rmse:0.04196\n",
      "[162]\tvalidation_0-rmse:0.04197\n",
      "[163]\tvalidation_0-rmse:0.04196\n",
      "[164]\tvalidation_0-rmse:0.04196\n",
      "[165]\tvalidation_0-rmse:0.04195\n",
      "[166]\tvalidation_0-rmse:0.04195\n",
      "[167]\tvalidation_0-rmse:0.04195\n",
      "[168]\tvalidation_0-rmse:0.04193\n",
      "[169]\tvalidation_0-rmse:0.04193\n",
      "[170]\tvalidation_0-rmse:0.04192\n",
      "[171]\tvalidation_0-rmse:0.04192\n",
      "[172]\tvalidation_0-rmse:0.04192\n",
      "[173]\tvalidation_0-rmse:0.04192\n",
      "[174]\tvalidation_0-rmse:0.04193\n",
      "[175]\tvalidation_0-rmse:0.04194\n",
      "[176]\tvalidation_0-rmse:0.04195\n",
      "[177]\tvalidation_0-rmse:0.04195\n",
      "[178]\tvalidation_0-rmse:0.04194\n",
      "[179]\tvalidation_0-rmse:0.04194\n",
      "[180]\tvalidation_0-rmse:0.04194\n",
      "[181]\tvalidation_0-rmse:0.04194\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                          colsample_bylevel=None,\n",
       "                                          colsample_bynode=None,\n",
       "                                          colsample_bytree=None, gamma=None,\n",
       "                                          gpu_id=None, importance_type='gain',\n",
       "                                          interaction_constraints=None,\n",
       "                                          learning_rate=None,\n",
       "                                          max_delta_step=None, max_depth=None,\n",
       "                                          min_child_weight=None, missing=nan,\n",
       "                                          monotone_constraints=None,\n",
       "                                          n_estimators=100, n...\n",
       "                                          validate_parameters=None,\n",
       "                                          verbosity=None),\n",
       "                   n_iter=50, n_jobs=4,\n",
       "                   param_distributions={'base_score': [0.25, 0.5, 0.75, 1],\n",
       "                                        'booster': ['gbtree', 'gblinear'],\n",
       "                                        'learning_rate': [0.05, 0.01, 0.1, 0.15,\n",
       "                                                          0.2],\n",
       "                                        'max_depth': [2, 3, 5, 10, 15],\n",
       "                                        'min_child_weight': [1, 2, 3, 4],\n",
       "                                        'n_estimators': [100, 500, 900, 1100,\n",
       "                                                         1500]},\n",
       "                   random_state=42, return_train_score=True,\n",
       "                   scoring='neg_mean_absolute_error', verbose=5)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_cv.fit(train_input, train_target,\n",
    "                eval_set=[(test_input, test_target)],\n",
    "               early_stopping_rounds=10\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.75, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "             importance_type='gain', interaction_constraints='',\n",
       "             learning_rate=0.2, max_delta_step=0, max_depth=10,\n",
       "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "             n_estimators=1500, n_jobs=12, num_parallel_tree=1, random_state=0,\n",
       "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "             tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best params\n",
    "random_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 288 candidates, totalling 1440 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    8.4s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   40.1s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:  5.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1440 out of 1440 | elapsed:  6.5min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.7,\n",
       " 'learning_rate': 0.1,\n",
       " 'max_depth': 10,\n",
       " 'min_child_weight': 1,\n",
       " 'n_estimators': 500,\n",
       " 'objective': 'reg:squarederror',\n",
       " 'subsample': 0.7}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Run only in the first run of the kernel.\n",
    "hyperParameterTuning(train_input, train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Best Params\n",
    "{'colsample_bytree': 0.7, 'learning_rate': 0.01, 'max_depth': 10, 'min_child_weight': 5, 'n_estimators': 500, 'subsample': 0.5}\n",
    "\n",
    "\n",
    "{'colsample_bytree': 0.7, 'learning_rate': 0.01, 'max_depth': 10, 'min_child_weight': 1, 'n_estimators': 500, 'subsample': 0.7}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=0.7, gamma=0, gpu_id=-1,\n",
       "             importance_type='gain', interaction_constraints='',\n",
       "             learning_rate=0.1, max_delta_step=0, max_depth=10,\n",
       "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "             n_estimators=500, n_jobs=12, num_parallel_tree=1, random_state=0,\n",
       "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=0.7,\n",
       "             tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# %time xgb_model.fit(train_input, train_target, early_stopping_rounds=10, eval_set=[(test_input, test_target)], verbose=False)\n",
    "\n",
    "\n",
    "model_Test = XGBRegressor(booster='gbtree',\n",
    "                        objective = 'reg:squarederror',\n",
    "                        colsample_bytree = 0.7,\n",
    "                        learning_rate = 0.1,\n",
    "                        max_depth = 10,\n",
    "                        min_child_weight = 1,\n",
    "                        n_estimators = 500,\n",
    "                        subsample = 0.7\n",
    "                        \n",
    "                        )\n",
    "model_Test.fit(train_input, train_target,\n",
    "              early_stopping_rounds=10, eval_set=[(test_input, test_target)], verbose=False\n",
    "              )\n",
    "\n",
    "\n",
    "\n",
    "# y_pred_xgb = xgb_model.predict(X_val)\n",
    "\n",
    "# mae_xgb = mean_absolute_error(y_val, y_pred_xgb)\n",
    "\n",
    "# print(\"MAE: \", mae_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.75, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "             importance_type='gain', interaction_constraints='',\n",
       "             learning_rate=0.2, max_delta_step=0, max_depth=10,\n",
       "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "             n_estimators=1500, n_jobs=12, num_parallel_tree=1, random_state=0,\n",
       "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "             tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_Test2= XGBRegressor(base_score=0.75, booster='gbtree', colsample_bylevel=1,\n",
    "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
    "             importance_type='gain', interaction_constraints='',\n",
    "             learning_rate=0.2, max_delta_step=0, max_depth=10,\n",
    "             min_child_weight=1, monotone_constraints='()',\n",
    "             n_estimators=1500, n_jobs=12, num_parallel_tree=1, random_state=0,\n",
    "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
    "             tree_method='exact', validate_parameters=1, verbosity=None)\n",
    "\n",
    "\n",
    "model_Test2.fit(train_input, train_target,\n",
    "              early_stopping_rounds=10, eval_set=[(test_input, test_target)], verbose=False\n",
    "              )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Predicted')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "predicted = model_Test2.predict(test_input)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(test_target, predicted, alpha=0.5)\n",
    "\n",
    "ax.set_xlabel('True Values')\n",
    "ax.set_ylabel('Predicted')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# #Plot Real vs Predict\n",
    "# plt.scatter(X_val['GrLivArea'] * 0.092903, y_val,          color='blue', label='Real',    alpha=0.5)\n",
    "# plt.scatter(X_val['GrLivArea'] * 0.092903, y_pred_xgb,  color='red' , label='Predict', alpha=0.5)\n",
    "# plt.title(\"Real vs Predict\")\n",
    "# plt.legend(loc='best')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 score: 0.9633023566594353\n",
      "mse: 0.0017571954456677282\n",
      "rmse: 0.041918915129899634\n",
      "mae: 0.027588463736446252\n"
     ]
    }
   ],
   "source": [
    "print(\"r2 score: {}\".format(metrics.r2_score(test_target, predicted)))\n",
    "print(\"mse: {}\".format(metrics.mean_squared_error(test_target, predicted)))\n",
    "print(\"rmse: {}\".format(np.sqrt(metrics.mean_squared_error(test_target, predicted))))\n",
    "print(\"mae: {}\".format(metrics.mean_absolute_error(test_target, predicted)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict from diff well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlsx = pd.ExcelFile('./Data/Outliers_out.xlsx')\n",
    "df2 = pd.read_excel(xlsx, '1x 4s')\n",
    "dataset2= df2.copy()\n",
    "\n",
    "\n",
    "# split datat into input and target\n",
    "\n",
    "inputs2 = dataset2.copy()\n",
    "target2 = inputs2.pop('RHOB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'predicted')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# predicted = model.predict(test_input)\n",
    "\n",
    "predicted2 = model_Test2.predict(inputs2)\n",
    "fig, ax= plt.subplots()\n",
    "ax.scatter(target2,predicted2, alpha=0.5)\n",
    "ax.set_xlabel(\"True\")\n",
    "ax.set_ylabel(\"predicted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 score: 0.4211295504957051\n",
      "mse: 0.013707021846683471\n",
      "rmse: 0.1170769911070637\n",
      "mae: 0.08187839208980338\n"
     ]
    }
   ],
   "source": [
    "print(\"r2 score: {}\".format(metrics.r2_score( target2, predicted2)))\n",
    "print(\"mse: {}\".format(metrics.mean_squared_error( target2, predicted2)))\n",
    "print(\"rmse: {}\".format(np.sqrt(metrics.mean_squared_error( target2, predicted2))))\n",
    "print(\"mae: {}\".format(metrics.mean_absolute_error( target2, predicted2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predic Test & Submission\n",
    "\n",
    "X_test = test_005\n",
    "\n",
    "# Use the model to make predictions\n",
    "y_pred_test = xgb_model.predict(X_test)\n",
    "\n",
    "submission = pd.DataFrame({'Id':test_id,'SalePrice':y_pred_test})\n",
    "\n",
    "# Save results\n",
    "submission.to_csv(\"submission.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
